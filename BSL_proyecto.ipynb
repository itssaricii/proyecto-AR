{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install python3.8 python3.8-venv"
      ],
      "metadata": {
        "id": "HpvZK0akZzhq",
        "outputId": "5b4e62a3-c8d0-4912-8700-ed284ce55921",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8-distutils\n",
            "  python3.8-lib2to3 python3.8-minimal\n",
            "Suggested packages:\n",
            "  binfmt-support\n",
            "The following NEW packages will be installed:\n",
            "  libpython3.8-minimal libpython3.8-stdlib python3.8 python3.8-distutils\n",
            "  python3.8-lib2to3 python3.8-minimal python3.8-venv\n",
            "0 upgraded, 7 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 8,013 kB of archives.\n",
            "After this operation, 22.9 MB of additional disk space will be used.\n",
            "Get:1 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-minimal amd64 3.8.20-1+jammy1 [796 kB]\n",
            "Get:2 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-minimal amd64 3.8.20-1+jammy1 [2,023 kB]\n",
            "Get:3 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 libpython3.8-stdlib amd64 3.8.20-1+jammy1 [1,817 kB]\n",
            "Get:4 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8 amd64 3.8.20-1+jammy1 [440 kB]\n",
            "Get:5 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-lib2to3 all 3.8.20-1+jammy1 [126 kB]\n",
            "Get:6 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-distutils all 3.8.20-1+jammy1 [193 kB]\n",
            "Get:7 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 python3.8-venv amd64 3.8.20-1+jammy1 [2,618 kB]\n",
            "Fetched 8,013 kB in 16s (491 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 7.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libpython3.8-minimal:amd64.\n",
            "(Reading database ... 126111 files and directories currently installed.)\n",
            "Preparing to unpack .../0-libpython3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-minimal.\n",
            "Preparing to unpack .../1-python3.8-minimal_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package libpython3.8-stdlib:amd64.\n",
            "Preparing to unpack .../2-libpython3.8-stdlib_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8.\n",
            "Preparing to unpack .../3-python3.8_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-lib2to3.\n",
            "Preparing to unpack .../4-python3.8-lib2to3_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-distutils.\n",
            "Preparing to unpack .../5-python3.8-distutils_3.8.20-1+jammy1_all.deb ...\n",
            "Unpacking python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Selecting previously unselected package python3.8-venv.\n",
            "Preparing to unpack .../6-python3.8-venv_3.8.20-1+jammy1_amd64.deb ...\n",
            "Unpacking python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-minimal:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-lib2to3 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-minimal (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-distutils (3.8.20-1+jammy1) ...\n",
            "Setting up libpython3.8-stdlib:amd64 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8 (3.8.20-1+jammy1) ...\n",
            "Setting up python3.8-venv (3.8.20-1+jammy1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for mailcap (3.70+nmu1ubuntu1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3.8 -m venv rl-env"
      ],
      "metadata": {
        "id": "IUopRNrxZ-H7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!source rl-env/bin/activate"
      ],
      "metadata": {
        "id": "kTEEJggdZXB8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ipykernel"
      ],
      "metadata": {
        "id": "YKfjeSCSaNBL",
        "outputId": "d6b3b8d8-1463-438c-c197-ededbfd46658",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.11/dist-packages (6.17.1)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (1.8.0)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (6.1.12)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (0.1.7)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.11/dist-packages (from ipykernel) (1.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from ipykernel) (24.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from ipykernel) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (24.0.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (6.4.2)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.11/dist-packages (from ipykernel) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (75.2.0)\n",
            "Collecting jedi>=0.16 (from ipython>=7.23.1->ipykernel)\n",
            "  Downloading jedi-0.19.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (3.0.51)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (2.19.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.11/dist-packages (from ipython>=7.23.1->ipykernel) (4.9.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel) (5.8.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.11/dist-packages (from jupyter-client>=6.1.12->ipykernel) (2.9.0.post0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.11/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel) (0.8.4)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.11/dist-packages (from jupyter-core>=4.6.0->jupyter-client>=6.1.12->ipykernel) (4.3.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.11/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel) (0.2.13)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.1->jupyter-client>=6.1.12->ipykernel) (1.17.0)\n",
            "Downloading jedi-0.19.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: jedi\n",
            "Successfully installed jedi-0.19.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m ipykernel install --user --name=rl-env --display-name \"Python 3.8 (rl-env)\""
      ],
      "metadata": {
        "id": "TMqTdOvbaS_f",
        "outputId": "95167e15-a56f-42d5-d50e-24f4d1f48656",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.00s - Debugger warning: It seems that frozen modules are being used, which may\n",
            "0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n",
            "0.00s - to python to disable frozen modules.\n",
            "0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n",
            "Installed kernelspec rl-env in /root/.local/share/jupyter/kernels/rl-env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUehXgCyIRdq"
      },
      "source": [
        "# Actividad - Proyecto práctico\n",
        "\n",
        "\n",
        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
        "*   Alumno 1: de Antón Santiago, Sara\n",
        "*   Alumno 2:\n",
        "*   Alumno 3:\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwpYlnjWJhS9"
      },
      "source": [
        "---\n",
        "## **PARTE 1** - Instalación y requisitos previos\n",
        "\n",
        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2BPrK2JkP0"
      },
      "source": [
        "---\n",
        "### 1.1. Preparar enviroment (solo local)\n",
        "\n",
        "\n",
        "\n",
        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
        "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
        "2. Instalar Anaconda\n",
        "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name miar_rl python=3.8\n",
        "conda activate miar_rl\n",
        "cd \"PATH_TO_FOLDER\"\n",
        "conda install git\n",
        "pip install jupyter\n",
        "```\n",
        "\n",
        "\n",
        "4. Abrir la notebook con *jupyter-notebook*.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "jupyter-notebook\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kixNPiJqTc"
      },
      "source": [
        "---\n",
        "### 1.2. Localizar entorno de trabajo: Google colab o local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_YDFwZ-JscI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dp_a1iBJ0tf"
      },
      "source": [
        "---\n",
        "### 1.3. Montar carpeta de datos local (solo Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6n7MIefJ21i",
        "tags": [],
        "outputId": "e0fc649d-29fa-4866-9bab-5fa9255c7b09"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archivos en el directorio: \n",
            "['.git', 'proyecto.ipynb', 'README.txt', '.ipynb_checkpoints', 'proyecto_SARA.ipynb']\n"
          ]
        }
      ],
      "source": [
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  if IN_COLAB:\n",
        "    # Mount the Google Drive at mount\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "      os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "# Verify we're in the correct working directory\n",
        "%pwd\n",
        "print(\"Archivos en el directorio: \")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ZSL5bpJ560"
      },
      "source": [
        "---\n",
        "### 1.4. Instalar librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UbVRjvHCJ8UF",
        "tags": [],
        "outputId": "a272cd91-c7be-4740-e1d7-a46c68135f6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 5.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting scipy\n",
            "  Downloading scipy-1.13.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.6 MB 83.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting numpy>=1.10.4\n",
            "  Downloading numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.5 MB 72.3 MB/s eta 0:00:01��███████████████████████████▋  | 18.1 MB 72.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting pyglet<=1.5.0,>=1.4.0\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 61.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cloudpickle<1.7.0,>=1.2.0\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Collecting future\n",
            "  Downloading future-1.0.0-py3-none-any.whl (491 kB)\n",
            "\u001b[K     |████████████████████████████████| 491 kB 71.3 MB/s eta 0:00:01\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654618 sha256=6a318785c18771ad6001f7c82964d873f72542aff0fd8d4a0f48e96b1ac32eb3\n",
            "  Stored in directory: /home/studio-lab-user/.cache/pip/wheels/5d/06/a4/57a926b2e87a5e1f21551577750549206dde639e19a5ac72d5\n",
            "Successfully built gym\n",
            "Installing collected packages: numpy, future, scipy, pyglet, cloudpickle, gym\n",
            "Successfully installed cloudpickle-1.6.0 future-1.0.0 gym-0.17.3 numpy-2.0.2 pyglet-1.5.0 scipy-1.13.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting git+https://github.com/Kojoley/atari-py.git\n",
            "  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-xnr5xbxy\n",
            "  Running command git clone -q https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-xnr5xbxy\n",
            "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
            "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from atari-py==1.2.2) (2.0.2)\n",
            "Building wheels for collected packages: atari-py\n",
            "  Building wheel for atari-py (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for atari-py: filename=atari_py-1.2.2-cp39-cp39-linux_x86_64.whl size=880311 sha256=e1f03dc643b7cbd2dfa206303d1be67e80c441d84f6e319f014bc100418d189b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-gip4j4ur/wheels/e9/1e/8a/f78f3c126cf46f574d8db9893b7345bc835c2016c29533f5db\n",
            "Successfully built atari-py\n",
            "Installing collected packages: atari-py\n",
            "Successfully installed atari-py-1.2.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: pyglet==1.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.5.0)\n",
            "Requirement already satisfied: future in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyglet==1.5.0) (1.0.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting h5py==3.1.0\n",
            "  Downloading h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.4 MB 5.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from h5py==3.1.0) (2.0.2)\n",
            "Installing collected packages: h5py\n",
            "Successfully installed h5py-3.1.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting Pillow==9.5.0\n",
            "  Downloading Pillow-9.5.0-cp39-cp39-manylinux_2_28_x86_64.whl (3.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.9 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: Pillow\n",
            "Successfully installed Pillow-9.5.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting keras-rl2==1.0.5\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.3 MB/s eta 0:00:011\n",
            "\u001b[?25hCollecting tensorflow\n",
            "  Downloading tensorflow-2.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
            "\u001b[K     |██████████████████▌             | 372.5 MB 128.6 MB/s eta 0:00:03   |██▏                             | 43.9 MB 10.8 MB/s eta 0:00:56     |███▍                            | 69.1 MB 10.8 MB/s eta 0:00:54 | 367.3 MB 128.6 MB/s eta 0:00:03"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |█████████████████████████████▎  | 589.8 MB 105.2 MB/s eta 0:00:01    |█████████████████████████████   | 584.0 MB 105.2 MB/s eta 0:00:01"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 644.8 MB 3.9 kB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 404 kB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.1 MB 40.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting h5py>=3.11.0\n",
            "  Downloading h5py-3.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.6 MB 57.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting keras>=3.5.0\n",
            "  Downloading keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 84.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
            "  Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
            "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (2.0.2)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Downloading absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
            "\u001b[K     |████████████████████████████████| 135 kB 84.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (1.16.0)\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (2.32.3)\n",
            "Collecting libclang>=13.0.0\n",
            "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.5 MB 78.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.17.2-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 2.5 MB/s  eta 0:00:01\n",
            "\u001b[?25hCollecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 14.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting ml-dtypes<1.0.0,>=0.5.1\n",
            "  Downloading ml_dtypes-0.5.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.7 MB 86.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (70.0.0)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3\n",
            "  Downloading protobuf-5.29.5-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[K     |████████████████████████████████| 319 kB 86.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard~=2.19.0\n",
            "  Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 84.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.6.6 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (4.11.0)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.73.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 85.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->keras-rl2==1.0.5) (24.0)\n",
            "Collecting flatbuffers>=24.3.25\n",
            "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from astunparse>=1.6.0->tensorflow->keras-rl2==1.0.5) (0.43.0)\n",
            "Collecting namex\n",
            "  Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
            "Collecting rich\n",
            "  Downloading rich-14.0.0-py3-none-any.whl (243 kB)\n",
            "\u001b[K     |████████████████████████████████| 243 kB 73.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting optree\n",
            "  Downloading optree-0.16.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (405 kB)\n",
            "\u001b[K     |████████████████████████████████| 405 kB 89.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2024.2.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.3.2)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 61.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting markdown>=2.6.8\n",
            "  Downloading markdown-3.8-py3-none-any.whl (106 kB)\n",
            "\u001b[K     |████████████████████████████████| 106 kB 99.0 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1\n",
            "  Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
            "\u001b[K     |████████████████████████████████| 224 kB 79.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata>=4.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow->keras-rl2==1.0.5) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow->keras-rl2==1.0.5) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->keras-rl2==1.0.5) (2.1.5)\n",
            "Collecting markdown-it-py>=2.2.0\n",
            "  Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "\u001b[K     |████████████████████████████████| 87 kB 15.8 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (2.18.0)\n",
            "Collecting mdurl~=0.1\n",
            "  Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: mdurl, markdown-it-py, werkzeug, tensorboard-data-server, rich, protobuf, optree, namex, ml-dtypes, markdown, h5py, grpcio, absl-py, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorboard, opt-einsum, libclang, keras, google-pasta, gast, flatbuffers, astunparse, tensorflow, keras-rl2\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed absl-py-2.3.0 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.73.0 h5py-3.14.0 keras-3.10.0 keras-rl2-1.0.5 libclang-18.1.1 markdown-3.8 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.5.1 namex-0.1.0 opt-einsum-3.4.0 optree-0.16.0 protobuf-5.29.5 rich-14.0.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.17.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting Keras==2.2.4\n",
            "  Downloading Keras-2.2.4-py2.py3-none-any.whl (312 kB)\n",
            "\u001b[K     |████████████████████████████████| 312 kB 6.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: six>=1.9.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Keras==2.2.4) (1.16.0)\n",
            "Requirement already satisfied: pyyaml in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Keras==2.2.4) (6.0.1)\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[K     |████████████████████████████████| 42 kB 2.2 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.9.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Keras==2.2.4) (2.0.2)\n",
            "Requirement already satisfied: h5py in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Keras==2.2.4) (3.14.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from Keras==2.2.4) (1.13.1)\n",
            "Collecting keras-applications>=1.0.6\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[K     |████████████████████████████████| 50 kB 11.5 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: keras-preprocessing, keras-applications, Keras\n",
            "  Attempting uninstall: Keras\n",
            "    Found existing installation: keras 3.10.0\n",
            "    Uninstalling keras-3.10.0:\n",
            "      Successfully uninstalled keras-3.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.19.0 requires keras>=3.5.0, but you have keras 2.2.4 which is incompatible.\u001b[0m\n",
            "Successfully installed Keras-2.2.4 keras-applications-1.0.8 keras-preprocessing-1.1.2\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting tensorflow==2.5.3\n",
            "  Downloading tensorflow-2.5.3-cp39-cp39-manylinux2010_x86_64.whl (460.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 460.4 MB 13 kB/s  eta 0:00:01   |▌                               | 7.4 MB 6.7 MB/s eta 0:01:08��█████████████████       | 359.1 MB 5.7 MB/s eta 0:00:18��███████████████████▏   | 405.5 MB 5.7 MB/s eta 0:00:10\n",
            "\u001b[?25hRequirement already satisfied: astunparse~=1.6.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (1.6.3)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp39-cp39-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 72.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting flatbuffers~=1.12.0\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting termcolor~=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 84.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting six~=1.15.0\n",
            "  Downloading six-1.15.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: wheel~=0.35 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (0.43.0)\n",
            "Collecting absl-py~=0.10\n",
            "  Downloading absl_py-0.15.0-py3-none-any.whl (132 kB)\n",
            "\u001b[K     |████████████████████████████████| 132 kB 80.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting opt-einsum~=3.3.0\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[K     |████████████████████████████████| 65 kB 10.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting h5py~=3.1.0\n",
            "  Using cached h5py-3.1.0-cp39-cp39-manylinux1_x86_64.whl (4.4 MB)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (2.19.0)\n",
            "Collecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 82.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.9.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (5.29.5)\n",
            "Collecting wrapt~=1.12.1\n",
            "  Downloading wrapt-1.12.1.tar.gz (27 kB)\n",
            "Collecting numpy~=1.19.2\n",
            "  Downloading numpy-1.19.5-cp39-cp39-manylinux2010_x86_64.whl (14.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9 MB 62.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting typing-extensions~=3.7.4\n",
            "  Downloading typing_extensions-3.7.4.3-py3-none-any.whl (22 kB)\n",
            "Collecting gast==0.4.0\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow==2.5.3) (0.2.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.1.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (70.0.0)\n",
            "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (24.0)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 38.4 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.17.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 65.2 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.17.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 38.7 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.16.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 53.6 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.16.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 86.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tf-keras>=2.15.0\n",
            "  Downloading tf_keras-2.19.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 37.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.16.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 46.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tf-keras-nightly\n",
            "  Downloading tf_keras_nightly-2.20.0.dev2025061209-py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 66.5 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 80.0 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (2.32.3)\n",
            "Collecting google-auth-oauthlib<2,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.2.2-py3-none-any.whl (19 kB)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 63.6 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.15.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 64.7 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.14.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 70.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth-oauthlib<1.1,>=0.5\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Collecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.14.0-py3-none-any.whl (5.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.5 MB 70.9 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 76.9 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 43.7 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.12.2-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 83.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[K     |████████████████████████████████| 781 kB 68.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.12.1-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 71.6 MB/s eta 0:00:01\n",
            "\u001b[?25h  Downloading tensorboard-2.12.0-py3-none-any.whl (5.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.6 MB 53.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting google-auth<3,>=1.6.3\n",
            "  Downloading google_auth-2.40.3-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[K     |████████████████████████████████| 216 kB 89.4 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard~=2.5\n",
            "  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 73.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 100.1 MB/s eta 0:00:01             | 266 kB 100.1 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting protobuf>=3.9.2\n",
            "  Downloading protobuf-3.20.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 76.9 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: markdown>=2.6.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.5->tensorflow==2.5.3) (3.8)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Downloading pyasn1_modules-0.4.2-py3-none-any.whl (181 kB)\n",
            "\u001b[K     |████████████████████████████████| 181 kB 63.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4\n",
            "  Downloading rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5.3) (3.17.0)\n",
            "Collecting pyasn1<0.7.0,>=0.6.1\n",
            "  Downloading pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "\u001b[K     |████████████████████████████████| 83 kB 4.0 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2.2.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5.3) (3.7)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[K     |████████████████████████████████| 151 kB 89.3 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.5->tensorflow==2.5.3) (2.1.5)\n",
            "Building wheels for collected packages: termcolor, wrapt\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for termcolor: filename=termcolor-1.1.0-py3-none-any.whl size=4832 sha256=09b98c673007d5a124823c14daaeb61eab692f5c17e67462a65fd825caa9dcfd\n",
            "  Stored in directory: /home/studio-lab-user/.cache/pip/wheels/b6/0d/90/0d1bbd99855f99cb2f6c2e5ff96f8023fad8ec367695f7d72d\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for wrapt: filename=wrapt-1.12.1-cp39-cp39-linux_x86_64.whl size=36980 sha256=f62360c5b5435eb9cd850f1eba923552bfe3a73068da3eb8a19e003c9f91770b\n",
            "  Stored in directory: /home/studio-lab-user/.cache/pip/wheels/98/23/68/efe259aaca055e93b08e74fbe512819c69a2155c11ba3c0f10\n",
            "Successfully built termcolor wrapt\n",
            "Installing collected packages: pyasn1, rsa, pyasn1-modules, oauthlib, cachetools, six, requests-oauthlib, google-auth, tensorboard-plugin-wit, tensorboard-data-server, protobuf, numpy, grpcio, google-auth-oauthlib, absl-py, wrapt, typing-extensions, termcolor, tensorflow-estimator, tensorboard, opt-einsum, keras-nightly, h5py, gast, flatbuffers, tensorflow\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.16.0\n",
            "    Uninstalling six-1.16.0:\n",
            "      Successfully uninstalled six-1.16.0\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.7.2\n",
            "    Uninstalling tensorboard-data-server-0.7.2:\n",
            "      Successfully uninstalled tensorboard-data-server-0.7.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.73.0\n",
            "    Uninstalling grpcio-1.73.0:\n",
            "      Successfully uninstalled grpcio-1.73.0\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 2.3.0\n",
            "    Uninstalling absl-py-2.3.0:\n",
            "      Successfully uninstalled absl-py-2.3.0\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 4.11.0\n",
            "    Uninstalling typing-extensions-4.11.0:\n",
            "      Successfully uninstalled typing-extensions-4.11.0\n",
            "  Attempting uninstall: termcolor\n",
            "    Found existing installation: termcolor 3.1.0\n",
            "    Uninstalling termcolor-3.1.0:\n",
            "      Successfully uninstalled termcolor-3.1.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.19.0\n",
            "    Uninstalling tensorboard-2.19.0:\n",
            "      Successfully uninstalled tensorboard-2.19.0\n",
            "  Attempting uninstall: opt-einsum\n",
            "    Found existing installation: opt-einsum 3.4.0\n",
            "    Uninstalling opt-einsum-3.4.0:\n",
            "      Successfully uninstalled opt-einsum-3.4.0\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.14.0\n",
            "    Uninstalling h5py-3.14.0:\n",
            "      Successfully uninstalled h5py-3.14.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 25.2.10\n",
            "    Uninstalling flatbuffers-25.2.10:\n",
            "      Successfully uninstalled flatbuffers-25.2.10\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.19.0\n",
            "    Uninstalling tensorflow-2.19.0:\n",
            "      Successfully uninstalled tensorflow-2.19.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "scipy 1.13.1 requires numpy<2.3,>=1.22.4, but you have numpy 1.19.5 which is incompatible.\n",
            "rich 14.0.0 requires typing-extensions<5.0,>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "optree 0.16.0 requires typing-extensions>=4.6.0, but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "ml-dtypes 0.5.1 requires numpy>=1.21, but you have numpy 1.19.5 which is incompatible.\n",
            "async-lru 2.0.4 requires typing-extensions>=4.0.0; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\n",
            "anyio 4.3.0 requires typing-extensions>=4.1; python_version < \"3.11\", but you have typing-extensions 3.7.4.3 which is incompatible.\u001b[0m\n",
            "Successfully installed absl-py-0.15.0 cachetools-5.5.2 flatbuffers-1.12 gast-0.4.0 google-auth-2.40.3 google-auth-oauthlib-0.4.6 grpcio-1.34.1 h5py-3.1.0 keras-nightly-2.5.0.dev2021032900 numpy-1.19.5 oauthlib-3.2.2 opt-einsum-3.3.0 protobuf-3.20.3 pyasn1-0.6.1 pyasn1-modules-0.4.2 requests-oauthlib-2.0.0 rsa-4.9.1 six-1.15.0 tensorboard-2.11.2 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.5.3 tensorflow-estimator-2.5.0 termcolor-1.1.0 typing-extensions-3.7.4.3 wrapt-1.12.1\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting torch==2.0.1\n",
            "  Downloading torch-2.0.1-cp39-cp39-manylinux1_x86_64.whl (619.9 MB)\n",
            "\u001b[K     |████████████████▏               | 313.5 MB 88.0 MB/s eta 0:00:0447 MB 5.9 MB/s eta 0:01:36:00:04"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |███████████████████████████████▉| 616.8 MB 103.7 MB/s eta 0:00:01��████████     | 524.0 MB 108.7 MB/s eta 0:00:01MB 108.7 MB/s eta 0:00:01"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 619.9 MB 8.4 kB/s \n",
            "\u001b[?25hCollecting nvidia-cufft-cu11==10.9.0.58\n",
            "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux2014_x86_64.whl (168.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 168.4 MB 129 kB/s  eta 0:00:01�████▏                     | 53.6 MB 82.6 MB/s eta 0:00:02\n",
            "\u001b[?25hCollecting nvidia-cuda-nvrtc-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 21.0 MB 61.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu11==11.7.91\n",
            "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
            "\u001b[K     |████████████████████████████████| 98 kB 10.9 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting sympy\n",
            "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 58.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-curand-cu11==10.2.10.91\n",
            "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 54.6 MB 96 kB/s s eta 0:00:01��█████████████████████          | 37.7 MB 93.2 MB/s eta 0:00:01███████▏| 53.3 MB 93.2 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting triton==2.0.0\n",
            "  Downloading triton-2.0.0-1-cp39-cp39-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 63.3 MB 72 kB/s s eta 0:00:01\n",
            "\u001b[?25hCollecting networkx\n",
            "  Downloading networkx-3.2.1-py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 65.8 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-nccl-cu11==2.14.3\n",
            "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 177.1 MB 40 kB/s s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu11==11.4.0.1\n",
            "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 102.6 MB 94.3 MB/s eta 0:00:01   |                                | 174 kB 78.0 MB/s eta 0:00:02\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu11==8.5.0.96\n",
            "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
            "\u001b[K     |█████████████████▋              | 307.0 MB 94.5 MB/s eta 0:00:03MB/s eta 0:00:07"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 557.1 MB 8.1 kB/s s eta 0:00:01\n",
            "\u001b[?25hCollecting filelock\n",
            "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
            "Collecting nvidia-cuda-cupti-cu11==11.7.101\n",
            "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8 MB 69.6 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-cublas-cu11==11.10.3.66\n",
            "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
            "\u001b[K     |█████████████████████████████   | 287.4 MB 137.5 MB/s eta 0:00:01                     | 24.5 MB 62.4 MB/s eta 0:00:05        | 136.7 MB 10.8 MB/s eta 0:00:17"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "IOPub data rate exceeded.\n",
            "The Jupyter server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--ServerApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "ServerApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 317.1 MB 28 kB/s \n",
            "\u001b[?25hCollecting nvidia-cusparse-cu11==11.7.4.91\n",
            "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 173.2 MB 48 kB/s /s eta 0:00:01       | 30.3 MB 58.2 MB/s eta 0:00:03████▍         | 121.4 MB 111.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu11==11.7.99\n",
            "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
            "\u001b[K     |████████████████████████████████| 849 kB 79.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==2.0.1) (3.7.4.3)\n",
            "Requirement already satisfied: jinja2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from torch==2.0.1) (3.1.4)\n",
            "Requirement already satisfied: wheel in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (0.43.0)\n",
            "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.1) (70.0.0)\n",
            "Collecting lit\n",
            "  Downloading lit-18.1.8-py3-none-any.whl (96 kB)\n",
            "\u001b[K     |████████████████████████████████| 96 kB 14.7 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting cmake\n",
            "  Downloading cmake-4.0.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (27.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.9 MB 87.2 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from jinja2->torch==2.0.1) (2.1.5)\n",
            "Collecting mpmath<1.4,>=1.1.0\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[K     |████████████████████████████████| 536 kB 84.4 MB/s eta 0:00:01\n",
            "\u001b[?25hInstalling collected packages: nvidia-cublas-cu11, mpmath, lit, filelock, cmake, triton, sympy, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-cusolver-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cudnn-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, networkx, torch\n",
            "Successfully installed cmake-4.0.2 filelock-3.18.0 lit-18.1.8 mpmath-1.3.0 networkx-3.2.1 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 sympy-1.14.0 torch-2.0.1 triton-2.0.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Collecting agents==1.4.0\n",
            "  Downloading agents-1.4.0.tar.gz (37 kB)\n",
            "Requirement already satisfied: tensorflow in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from agents==1.4.0) (2.5.3)\n",
            "Requirement already satisfied: gym in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from agents==1.4.0) (0.17.3)\n",
            "Collecting ruamel.yaml\n",
            "  Downloading ruamel.yaml-0.18.14-py3-none-any.whl (118 kB)\n",
            "\u001b[K     |████████████████████████████████| 118 kB 9.5 MB/s eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gym->agents==1.4.0) (1.13.1)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gym->agents==1.4.0) (1.5.0)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gym->agents==1.4.0) (1.6.0)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from gym->agents==1.4.0) (1.19.5)\n",
            "Requirement already satisfied: future in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pyglet<=1.5.0,>=1.4.0->gym->agents==1.4.0) (1.0.0)\n",
            "Collecting ruamel.yaml.clib>=0.2.7\n",
            "  Downloading ruamel.yaml.clib-0.2.12-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (724 kB)\n",
            "\u001b[K     |████████████████████████████████| 724 kB 46.3 MB/s eta 0:00:01\n",
            "\u001b[?25hCollecting numpy>=1.10.4\n",
            "  Using cached numpy-2.0.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.5 MB)\n",
            "Requirement already satisfied: grpcio~=1.34.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (1.34.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (0.4.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (0.15.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (1.12.1)\n",
            "Requirement already satisfied: six~=1.15.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (0.2.0)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (2.11.2)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (3.7.4.3)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (3.3.0)\n",
            "Collecting tensorflow\n",
            "  Using cached tensorflow-2.19.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (644.8 MB)\n",
            "Collecting tensorboard~=2.19.0\n",
            "  Using cached tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (0.5.1)\n",
            "Collecting flatbuffers>=24.3.25\n",
            "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (0.37.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (2.32.3)\n",
            "Collecting h5py>=3.11.0\n",
            "  Using cached h5py-3.14.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (18.1.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (70.0.0)\n",
            "Requirement already satisfied: packaging in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (24.0)\n",
            "Collecting absl-py>=1.0.0\n",
            "  Using cached absl_py-2.3.0-py3-none-any.whl (135 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorflow->agents==1.4.0) (1.1.0)\n",
            "Collecting keras>=3.5.0\n",
            "  Using cached keras-3.10.0-py3-none-any.whl (1.4 MB)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from astunparse~=1.6.3->tensorflow->agents==1.4.0) (0.43.0)\n",
            "Requirement already satisfied: rich in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow->agents==1.4.0) (14.0.0)\n",
            "Requirement already satisfied: namex in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow->agents==1.4.0) (0.1.0)\n",
            "Requirement already satisfied: optree in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from keras>=3.5.0->tensorflow->agents==1.4.0) (0.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->agents==1.4.0) (2.2.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->agents==1.4.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->agents==1.4.0) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from requests<3,>=2.21.0->tensorflow->agents==1.4.0) (2024.2.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.19.0->tensorflow->agents==1.4.0) (3.1.3)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Using cached grpcio-1.73.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from tensorboard~=2.19.0->tensorflow->agents==1.4.0) (3.8)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
            "  Using cached tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown>=2.6.8->tensorboard~=2.19.0->tensorflow->agents==1.4.0) (7.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard~=2.19.0->tensorflow->agents==1.4.0) (3.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow->agents==1.4.0) (2.1.5)\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.14.0-py3-none-any.whl (43 kB)\n",
            "\u001b[K     |████████████████████████████████| 43 kB 2.9 MB/s  eta 0:00:01\n",
            "\u001b[?25hRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow->agents==1.4.0) (2.18.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from rich->keras>=3.5.0->tensorflow->agents==1.4.0) (3.0.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->agents==1.4.0) (0.1.2)\n",
            "Building wheels for collected packages: agents\n",
            "  Building wheel for agents (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for agents: filename=agents-1.4.0-py3-none-any.whl size=62711 sha256=0965205e78bec84a4e3752b73d395746975e880ca31f3e117175443b3c0b70f5\n",
            "  Stored in directory: /home/studio-lab-user/.cache/pip/wheels/63/25/af/6928b344ba299dfccdce6d4c26d8922af7d4f4c27c5ba38614\n",
            "Successfully built agents\n",
            "Installing collected packages: typing-extensions, numpy, tensorboard-data-server, h5py, grpcio, absl-py, tensorboard, ruamel.yaml.clib, keras, flatbuffers, tensorflow, ruamel.yaml, agents\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing-extensions 3.7.4.3\n",
            "    Uninstalling typing-extensions-3.7.4.3:\n",
            "      Successfully uninstalled typing-extensions-3.7.4.3\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: tensorboard-data-server\n",
            "    Found existing installation: tensorboard-data-server 0.6.1\n",
            "    Uninstalling tensorboard-data-server-0.6.1:\n",
            "      Successfully uninstalled tensorboard-data-server-0.6.1\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.34.1\n",
            "    Uninstalling grpcio-1.34.1:\n",
            "      Successfully uninstalled grpcio-1.34.1\n",
            "  Attempting uninstall: absl-py\n",
            "    Found existing installation: absl-py 0.15.0\n",
            "    Uninstalling absl-py-0.15.0:\n",
            "      Successfully uninstalled absl-py-0.15.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.11.2\n",
            "    Uninstalling tensorboard-2.11.2:\n",
            "      Successfully uninstalled tensorboard-2.11.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: Keras 2.2.4\n",
            "    Uninstalling Keras-2.2.4:\n",
            "      Successfully uninstalled Keras-2.2.4\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.5.3\n",
            "    Uninstalling tensorflow-2.5.3:\n",
            "      Successfully uninstalled tensorflow-2.5.3\n",
            "Successfully installed absl-py-2.3.0 agents-1.4.0 flatbuffers-25.2.10 grpcio-1.73.0 h5py-3.14.0 keras-3.10.0 numpy-2.0.2 ruamel.yaml-0.18.14 ruamel.yaml.clib-0.2.12 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 typing-extensions-4.14.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "if IN_COLAB:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install tensorflow==2.8\n",
        "else:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install pyglet==1.5.0\n",
        "  %pip install h5py==3.1.0\n",
        "  %pip install Pillow==9.5.0\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install Keras==2.2.4\n",
        "  %pip install tensorflow==2.5.3\n",
        "  %pip install torch==2.0.1\n",
        "  %pip install agents==1.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hzP_5ZuGb2X"
      },
      "source": [
        "---\n",
        "## **PARTE 2**. Enunciado\n",
        "\n",
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
        "\n",
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "1.   Implementar la red neuronal que se usará en la solución\n",
        "2.   Implementar las distintas piezas de la solución DQN\n",
        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
        "\n",
        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
        "\n",
        "IMPORTANTE:\n",
        "\n",
        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
        "* Cada alumno deberá de subir la solución de forma individual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_b3mzw8IzJP"
      },
      "source": [
        "---\n",
        "## **PARTE 3**. Desarrollo y preguntas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duPmUNOVGb2a"
      },
      "source": [
        "#### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j3eRhgI-Gb2a",
        "tags": [],
        "outputId": "d8094968-ff3b-4178-8f17-8c20ef94cb72"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025-06-12 20:37:23.380527: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-12 20:37:23.385062: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
            "2025-06-12 20:37:23.396439: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1749760643.416103     438 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1749760643.421901     438 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1749760643.437995     438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749760643.438024     438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749760643.438026     438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1749760643.438028     438 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2025-06-12 20:37:23.443307: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "ename": "ImportError",
          "evalue": "cannot import name 'MobileNetV3Large' from 'keras.applications.mobilenet_v3' (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/applications/mobilenet_v3/__init__.py)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_438/4193694462.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgym\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mConvolution2D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPermute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/api/_v2/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_v2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/api/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msys\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_sys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mdel\u001b[0m \u001b[0m_print_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/api/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mapplications\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.conda/envs/default/lib/python3.9/site-packages/keras/api/keras/applications/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetV2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetV3Large\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmobilenet_v3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMobileNetV3Small\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapplications\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnasnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNASNetLarge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'MobileNetV3Large' from 'keras.applications.mobilenet_v3' (/home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages/keras/applications/mobilenet_v3/__init__.py)"
          ]
        }
      ],
      "source": [
        "from __future__ import division\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4jgQjzoGb2a"
      },
      "source": [
        "#### Configuración base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jwOE6I_KGb2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jGEZUcpGb2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yitXTADGb2b"
      },
      "source": [
        "1. Implementación de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O4GKrfWSGb2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9-_5HPGb2b"
      },
      "source": [
        "2. Implementación de la solución DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "foSlxWH1Gb2b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OHYryKd1Gb2b",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Testing part to calculate the mean reward\n",
        "weights_filename = 'dqn_{}_weights.h5f'.format(env_name)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env, nb_episodes=10, visualize=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-NAlu8b1Gb2b"
      },
      "source": [
        "3. Justificación de los parámetros seleccionados y de los resultados obtenidos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANFQiicXK3sO"
      },
      "source": [
        "---"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8 (rl-env)",
      "name": "rl-env"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}