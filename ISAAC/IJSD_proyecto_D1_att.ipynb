{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUehXgCyIRdq"
      },
      "source": [
        "# Actividad - Proyecto práctico\n",
        "\n",
        "\n",
        "> La actividad se desarrollará en grupos pre-definidos de 2-3 alumnos. Se debe indicar los nombres en orden alfabético (de apellidos). Recordad que esta actividad se corresponde con un 30% de la nota final de la asignatura. Se debe entregar entregar el trabajo en la presente notebook.\n",
        "*   Alumno 1: de Antón Santiago, Sara\n",
        "*   Alumno 2: Sánchez La O, Benjamín C.\n",
        "*   Alumno 3: Sánchez Díaz, Isaac José\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwpYlnjWJhS9"
      },
      "source": [
        "---\n",
        "## **PARTE 1** - Instalación y requisitos previos\n",
        "\n",
        "> Las prácticas han sido preparadas para poder realizarse en el entorno de trabajo de Google Colab. Sin embargo, esta plataforma presenta ciertas incompatibilidades a la hora de visualizar la renderización en gym. Por ello, para obtener estas visualizaciones, se deberá trasladar el entorno de trabajo a local. Por ello, el presente dosier presenta instrucciones para poder trabajar en ambos entornos. Siga los siguientes pasos para un correcto funcionamiento:\n",
        "1.   **LOCAL:** Preparar el enviroment, siguiendo las intrucciones detalladas en la sección *1.1.Preparar enviroment*.\n",
        "2.  **AMBOS:** Modificar las variables \"mount\" y \"drive_mount\" a la carpeta de trabajo en drive en el caso de estar en Colab, y ejecturar la celda *1.2.Localizar entorno de trabajo*.\n",
        "3. **COLAB:** se deberá ejecutar las celdas correspondientes al montaje de la carpeta de trabajo en Drive. Esta corresponde a la sección *1.3.Montar carpeta de datos local*.\n",
        "4.  **AMBOS:** Instalar las librerías necesarias, siguiendo la sección *1.4.Instalar librerías necesarias*.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RU2BPrK2JkP0"
      },
      "source": [
        "---\n",
        "### 1.1. Preparar enviroment (solo local)\n",
        "\n",
        "\n",
        "\n",
        "> Para preparar el entorno de trabajo en local, se han seguido los siguientes pasos:\n",
        "1. En Windows, puede ser necesario instalar las C++ Build Tools. Para ello, siga los siguientes pasos: https://towardsdatascience.com/how-to-install-openai-gym-in-a-windows-environment-338969e24d30.\n",
        "2. Instalar Anaconda\n",
        "3. Siguiendo el código que se presenta comentado en la próxima celda: Crear un enviroment, cambiar la ruta de trabajo, e instalar librerías básicas.\n",
        "\n",
        "\n",
        "```\n",
        "conda create --name miar_rl python=3.8\n",
        "conda activate miar_rl\n",
        "cd \"PATH_TO_FOLDER\"\n",
        "conda install git\n",
        "pip install jupyter\n",
        "```\n",
        "\n",
        "\n",
        "4. Abrir la notebook con *jupyter-notebook*.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "jupyter-notebook\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-kixNPiJqTc"
      },
      "source": [
        "---\n",
        "### 1.2. Localizar entorno de trabajo: Google colab o local"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "S_YDFwZ-JscI",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# ATENCIÓN!! Modificar ruta relativa a la práctica si es distinta (drive_root)\n",
        "mount='/content/gdrive'\n",
        "drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
        "\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Dp_a1iBJ0tf"
      },
      "source": [
        "---\n",
        "### 1.3. Montar carpeta de datos local (solo Colab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I6n7MIefJ21i",
        "outputId": "bce44695-c427-4ed6-b1c1-a0df92594a1d",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We're running Colab\n",
            "Colab: mounting Google drive on  /content/gdrive\n",
            "Mounted at /content/gdrive\n",
            "\n",
            "Colab: making sure  /content/gdrive/My Drive/08_MIAR/actividades/proyecto practico  exists.\n",
            "\n",
            "Colab: Changing directory to  /content/gdrive/My Drive/08_MIAR/actividades/proyecto practico\n",
            "/content/gdrive/My Drive/08_MIAR/actividades/proyecto practico\n",
            "Archivos en el directorio: \n",
            "['models']\n"
          ]
        }
      ],
      "source": [
        "# Switch to the directory on the Google Drive that you want to use\n",
        "import os\n",
        "if IN_COLAB:\n",
        "  print(\"We're running Colab\")\n",
        "\n",
        "  if IN_COLAB:\n",
        "    # Mount the Google Drive at mount\n",
        "    print(\"Colab: mounting Google drive on \", mount)\n",
        "\n",
        "    drive.mount(mount)\n",
        "\n",
        "    # Create drive_root if it doesn't exist\n",
        "    create_drive_root = True\n",
        "    if create_drive_root:\n",
        "      print(\"\\nColab: making sure \", drive_root, \" exists.\")\n",
        "      os.makedirs(drive_root, exist_ok=True)\n",
        "\n",
        "    # Change to the directory\n",
        "    print(\"\\nColab: Changing directory to \", drive_root)\n",
        "    %cd $drive_root\n",
        "# Verify we're in the correct working directory\n",
        "%pwd\n",
        "print(\"Archivos en el directorio: \")\n",
        "print(os.listdir())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1ZSL5bpJ560"
      },
      "source": [
        "---\n",
        "### 1.4. Instalar librerías necesarias"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UbVRjvHCJ8UF",
        "outputId": "8bee6aeb-0bde-457b-dd3a-0761bb830498",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting gym==0.17.3\n",
            "  Downloading gym-0.17.3.tar.gz (1.6 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.6 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/1.6 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (1.15.3)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.11/dist-packages (from gym==0.17.3) (2.0.2)\n",
            "Collecting pyglet<=1.5.0,>=1.4.0 (from gym==0.17.3)\n",
            "  Downloading pyglet-1.5.0-py2.py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting cloudpickle<1.7.0,>=1.2.0 (from gym==0.17.3)\n",
            "  Downloading cloudpickle-1.6.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.11/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym==0.17.3) (1.0.0)\n",
            "Downloading cloudpickle-1.6.0-py3-none-any.whl (23 kB)\n",
            "Downloading pyglet-1.5.0-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m43.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: gym\n",
            "  Building wheel for gym (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.17.3-py3-none-any.whl size=1654617 sha256=ca109cf0abb6f7bb0aa1926f17659222e2863f152c8cccbe192ff3a74399b8b6\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/8b/b7/570cb90b10f17e85ccb291ba1f04af41ec697745104a2263eb\n",
            "Successfully built gym\n",
            "Installing collected packages: pyglet, cloudpickle, gym\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 3.1.1\n",
            "    Uninstalling cloudpickle-3.1.1:\n",
            "      Successfully uninstalled cloudpickle-3.1.1\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "distributed 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "bigframes 2.6.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "dask 2024.12.1 requires cloudpickle>=3.0.0, but you have cloudpickle 1.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed cloudpickle-1.6.0 gym-0.17.3 pyglet-1.5.0\n",
            "Collecting git+https://github.com/Kojoley/atari-py.git\n",
            "  Cloning https://github.com/Kojoley/atari-py.git to /tmp/pip-req-build-ip_kiwml\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/Kojoley/atari-py.git /tmp/pip-req-build-ip_kiwml\n",
            "  Resolved https://github.com/Kojoley/atari-py.git to commit 86a1e05c0a95e9e6233c3a413521fdb34ca8a089\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from atari-py==1.2.2) (2.0.2)\n",
            "Building wheels for collected packages: atari-py\n",
            "  Building wheel for atari-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for atari-py: filename=atari_py-1.2.2-cp311-cp311-linux_x86_64.whl size=4738734 sha256=433fdc30a4117f9973381b18ce3bdbf12a664dbd6c7183816c836a5a5b847b8c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-70y04z4m/wheels/1a/58/b3/3baab9d1509939ecce2dfd9ca349c222b7ee6590f4bd6097a1\n",
            "Successfully built atari-py\n",
            "Installing collected packages: atari-py\n",
            "Successfully installed atari-py-1.2.2\n",
            "Collecting keras-rl2==1.0.5\n",
            "  Downloading keras_rl2-1.0.5-py3-none-any.whl.metadata (304 bytes)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.11/dist-packages (from keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (25.2.10)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (5.29.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (4.14.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (1.73.0)\n",
            "Requirement already satisfied: tensorboard<2.19,>=2.18 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.18.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.8.0)\n",
            "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (2.0.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (3.14.0)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.4.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow->keras-rl2==1.0.5) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow->keras-rl2==1.0.5) (0.45.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.0)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.11/dist-packages (from keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorflow->keras-rl2==1.0.5) (2025.6.15)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.1.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow->keras-rl2==1.0.5) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow->keras-rl2==1.0.5) (0.1.2)\n",
            "Downloading keras_rl2-1.0.5-py3-none-any.whl (52 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.1/52.1 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: keras-rl2\n",
            "Successfully installed keras-rl2-1.0.5\n",
            "Collecting tensorflow==2.12\n",
            "  Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (25.2.10)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.12)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.73.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.14.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.5.2)\n",
            "Collecting keras<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading keras-2.12.0-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (18.1.1)\n",
            "Collecting numpy<1.24,>=1.22 (from tensorflow==2.12)\n",
            "  Downloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (24.2)\n",
            "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.12)\n",
            "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (75.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (1.17.0)\n",
            "Collecting tensorboard<2.13,>=2.12 (from tensorflow==2.12)\n",
            "  Downloading tensorboard-2.12.3-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting tensorflow-estimator<2.13,>=2.12.0 (from tensorflow==2.12)\n",
            "  Downloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (4.14.0)\n",
            "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.12)\n",
            "  Downloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.11/dist-packages (from tensorflow==2.12) (0.37.1)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from astunparse>=1.6.0->tensorflow==2.12) (0.45.1)\n",
            "Requirement already satisfied: jaxlib<=0.5.2,>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.5.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (0.4.1)\n",
            "INFO: pip is looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.2-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.2,>=0.6.2 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.2-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.3 kB)\n",
            "Collecting ml_dtypes>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading ml_dtypes-0.5.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (21 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.1-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting jaxlib<=0.6.1,>=0.6.1 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.1-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.6.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.6.0,>=0.6.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.6.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.3-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.3,>=0.5.3 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.3-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.2 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.5.1-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.5.0-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.5.0,>=0.5.0 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.5.0-cp311-cp311-manylinux2014_x86_64.whl.metadata (978 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.38-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.38,>=0.4.38 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.38-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "INFO: pip is still looking at multiple versions of jax to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.37-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.37,>=0.4.36 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.36-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.36-py3-none-any.whl.metadata (22 kB)\n",
            "  Downloading jax-0.4.35-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.35,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.35-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.34-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.34,>=0.4.34 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.34-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.33-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.33,>=0.4.33 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.33-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.31-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.31,>=0.4.30 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.31-cp311-cp311-manylinux2014_x86_64.whl.metadata (983 bytes)\n",
            "Collecting jax>=0.3.15 (from tensorflow==2.12)\n",
            "  Downloading jax-0.4.30-py3-none-any.whl.metadata (22 kB)\n",
            "Collecting jaxlib<=0.4.30,>=0.4.27 (from jax>=0.3.15->tensorflow==2.12)\n",
            "  Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: scipy>=1.9 in /usr/local/lib/python3.11/dist-packages (from jax>=0.3.15->tensorflow==2.12) (1.15.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.38.0)\n",
            "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.13,>=2.12->tensorflow==2.12)\n",
            "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.8)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (2.32.3)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard<2.13,>=2.12->tensorflow==2.12) (3.1.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.0.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow==2.12) (2025.6.15)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.0.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow==2.12) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow==2.12) (3.2.2)\n",
            "Downloading tensorflow-2.12.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (586.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m586.0/586.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Downloading jax-0.4.30-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m44.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading keras-2.12.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.23.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m59.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorboard-2.12.3-py3-none-any.whl (5.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m64.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tensorflow_estimator-2.12.0-py2.py3-none-any.whl (440 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m440.7/440.7 kB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wrapt-1.14.1-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
            "Downloading jaxlib-0.4.30-cp311-cp311-manylinux2014_x86_64.whl (79.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.6/79.6 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wrapt, tensorflow-estimator, protobuf, numpy, keras, gast, jaxlib, google-auth-oauthlib, tensorboard, jax, tensorflow\n",
            "  Attempting uninstall: wrapt\n",
            "    Found existing installation: wrapt 1.17.2\n",
            "    Uninstalling wrapt-1.17.2:\n",
            "      Successfully uninstalled wrapt-1.17.2\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 5.29.5\n",
            "    Uninstalling protobuf-5.29.5:\n",
            "      Successfully uninstalled protobuf-5.29.5\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 3.8.0\n",
            "    Uninstalling keras-3.8.0:\n",
            "      Successfully uninstalled keras-3.8.0\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.6.0\n",
            "    Uninstalling gast-0.6.0:\n",
            "      Successfully uninstalled gast-0.6.0\n",
            "  Attempting uninstall: jaxlib\n",
            "    Found existing installation: jaxlib 0.5.1\n",
            "    Uninstalling jaxlib-0.5.1:\n",
            "      Successfully uninstalled jaxlib-0.5.1\n",
            "  Attempting uninstall: google-auth-oauthlib\n",
            "    Found existing installation: google-auth-oauthlib 1.2.2\n",
            "    Uninstalling google-auth-oauthlib-1.2.2:\n",
            "      Successfully uninstalled google-auth-oauthlib-1.2.2\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.18.0\n",
            "    Uninstalling tensorboard-2.18.0:\n",
            "      Successfully uninstalled tensorboard-2.18.0\n",
            "  Attempting uninstall: jax\n",
            "    Found existing installation: jax 0.5.2\n",
            "    Uninstalling jax-0.5.2:\n",
            "      Successfully uninstalled jax-0.5.2\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.18.0\n",
            "    Uninstalling tensorflow-2.18.0:\n",
            "      Successfully uninstalled tensorflow-2.18.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc 5.23.0 requires numpy>=1.25.0, but you have numpy 1.23.5 which is incompatible.\n",
            "albucore 0.0.24 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "grpcio-status 1.71.0 requires protobuf<6.0dev,>=5.26.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "xarray-einstats 0.9.0 requires numpy>=1.25, but you have numpy 1.23.5 which is incompatible.\n",
            "albumentations 2.0.8 requires numpy>=1.24.4, but you have numpy 1.23.5 which is incompatible.\n",
            "flax 0.10.6 requires jax>=0.5.1, but you have jax 0.4.30 which is incompatible.\n",
            "chex 0.1.89 requires numpy>=1.24.1, but you have numpy 1.23.5 which is incompatible.\n",
            "db-dtypes 1.4.3 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "tensorflow-decision-forests 1.11.0 requires tensorflow==2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "tensorflow-text 2.18.1 requires tensorflow<2.19,>=2.18.0, but you have tensorflow 2.12.0 which is incompatible.\n",
            "orbax-checkpoint 0.11.15 requires jax>=0.5.0, but you have jax 0.4.30 which is incompatible.\n",
            "bigframes 2.6.0 requires cloudpickle>=2.0.0, but you have cloudpickle 1.6.0 which is incompatible.\n",
            "bigframes 2.6.0 requires numpy>=1.24.0, but you have numpy 1.23.5 which is incompatible.\n",
            "xarray 2025.3.1 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "treescope 0.1.9 requires numpy>=1.25.2, but you have numpy 1.23.5 which is incompatible.\n",
            "blosc2 3.4.0 requires numpy>=1.26, but you have numpy 1.23.5 which is incompatible.\n",
            "tf-keras 2.18.0 requires tensorflow<2.19,>=2.18, but you have tensorflow 2.12.0 which is incompatible.\n",
            "ydf 0.12.0 requires protobuf<6.0.0,>=5.29.1, but you have protobuf 4.25.8 which is incompatible.\n",
            "scikit-image 0.25.2 requires numpy>=1.24, but you have numpy 1.23.5 which is incompatible.\n",
            "imbalanced-learn 0.13.0 requires numpy<3,>=1.24.3, but you have numpy 1.23.5 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.23.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed gast-0.4.0 google-auth-oauthlib-1.0.0 jax-0.4.30 jaxlib-0.4.30 keras-2.12.0 numpy-1.23.5 protobuf-4.25.8 tensorboard-2.12.3 tensorflow-2.12.0 tensorflow-estimator-2.12.0 wrapt-1.14.1\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "465c88e2998345eaacd8b679612498ea",
              "pip_warning": {
                "packages": [
                  "google",
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# NO EJECUTAR EN SAGEMAKER (MIRAR EL README PARA CONFIGURAR EL ENTORNO)\n",
        "# AUNQUE DE FALLOS DE INSTALACIÓN LOS IMPORTS FUNCIONAN\n",
        "if IN_COLAB:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install tensorflow==2.12  #2.8\n",
        "else:\n",
        "  %pip install gym==0.17.3\n",
        "  %pip install git+https://github.com/Kojoley/atari-py.git\n",
        "  %pip install pyglet==1.5.0\n",
        "  %pip install h5py==3.1.0\n",
        "  %pip install Pillow==9.5.0\n",
        "  %pip install keras-rl2==1.0.5\n",
        "  %pip install Keras==2.2.4\n",
        "  %pip install tensorflow==2.5.3\n",
        "  %pip install torch==2.0.1\n",
        "  %pip install agents==1.4.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hzP_5ZuGb2X"
      },
      "source": [
        "---\n",
        "## **PARTE 2**. Enunciado\n",
        "\n",
        "Consideraciones a tener en cuenta:\n",
        "\n",
        "- El entorno sobre el que trabajaremos será _SpaceInvaders-v0_ y el algoritmo que usaremos será _DQN_.\n",
        "\n",
        "- Para nuestro ejercicio, el requisito mínimo será alcanzado cuando el agente consiga una **media de recompensa por encima de 20 puntos en modo test**. Por ello, esta media de la recompensa se calculará a partir del código de test en la última celda del notebook.\n",
        "\n",
        "Este proyecto práctico consta de tres partes:\n",
        "\n",
        "1.   Implementar la red neuronal que se usará en la solución\n",
        "2.   Implementar las distintas piezas de la solución DQN\n",
        "3.   Justificar la respuesta en relación a los resultados obtenidos\n",
        "\n",
        "**Rúbrica**: Se valorará la originalidad en la solución aportada, así como la capacidad de discutir los resultados de forma detallada. El requisito mínimo servirá para aprobar la actividad, bajo premisa de que la discusión del resultado sera apropiada.\n",
        "\n",
        "IMPORTANTE:\n",
        "\n",
        "* Si no se consigue una puntuación óptima, responder sobre la mejor puntuación obtenida.\n",
        "* Para entrenamientos largos, recordad que podéis usar checkpoints de vuestros modelos para retomar los entrenamientos. En este caso, recordad cambiar los parámetros adecuadamente (sobre todo los relacionados con el proceso de exploración).\n",
        "* Se deberá entregar unicamente el notebook y los pesos del mejor modelo en un fichero .zip, de forma organizada.\n",
        "* Cada alumno deberá de subir la solución de forma individual."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_b3mzw8IzJP"
      },
      "source": [
        "---\n",
        "## **PARTE 3**. Desarrollo y preguntas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "45BPUdIoB41o",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# DEFINIR AL PRINCIPIO\n",
        "try:\n",
        "  from google.colab import drive\n",
        "  IN_COLAB=True\n",
        "except:\n",
        "  IN_COLAB=False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duPmUNOVGb2a"
      },
      "source": [
        "#### Importar librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "j3eRhgI-Gb2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "from __future__ import division\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import gym\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Flatten, Convolution2D, Permute, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow.keras.backend as K\n",
        "\n",
        "from rl.agents.dqn import DQNAgent\n",
        "from rl.policy import LinearAnnealedPolicy, BoltzmannQPolicy, EpsGreedyQPolicy\n",
        "from rl.memory import SequentialMemory\n",
        "from rl.core import Processor\n",
        "from rl.callbacks import FileLogger, ModelIntervalCheckpoint\n",
        "\n",
        "# AÑADIDO\n",
        "from tensorflow.keras.layers import Lambda, BatchNormalization\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "import json\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import pickle\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f4jgQjzoGb2a"
      },
      "source": [
        "#### Configuración base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "jwOE6I_KGb2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "INPUT_SHAPE = (84, 84)\n",
        "WINDOW_LENGTH = 4\n",
        "\n",
        "env_name = 'SpaceInvaders-v0'\n",
        "env = gym.make(env_name)\n",
        "\n",
        "\n",
        "class FrameSkipWrapper(gym.Wrapper):\n",
        "    def __init__(self, env, skip=4):\n",
        "        super().__init__(env)\n",
        "        self.skip = skip\n",
        "\n",
        "    def step(self, action):\n",
        "        total_reward = 0.0\n",
        "        done = False\n",
        "        for _ in range(self.skip):\n",
        "            obs, reward, done, info = self.env.step(action)\n",
        "            total_reward += reward\n",
        "            if done:\n",
        "                break\n",
        "        return obs, total_reward, done, info\n",
        "\n",
        "env = FrameSkipWrapper(env, skip=4)\n",
        "\n",
        "np.random.seed(123)\n",
        "env.seed(123)\n",
        "nb_actions = env.action_space.n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "9jGEZUcpGb2a",
        "tags": []
      },
      "outputs": [],
      "source": [
        "class AtariProcessor(Processor):\n",
        "    def process_observation(self, observation):\n",
        "        assert observation.ndim == 3  # (height, width, channel)\n",
        "        img = Image.fromarray(observation)\n",
        "        img = img.resize(INPUT_SHAPE).convert('L')\n",
        "        processed_observation = np.array(img)\n",
        "        assert processed_observation.shape == INPUT_SHAPE\n",
        "        return processed_observation.astype('uint8')\n",
        "    \n",
        "# Añade pequeña recompensa por disparar cerca de enemigos\n",
        "class CustomProcessor(AtariProcessor):\n",
        "\n",
        "    def process_state_batch(self, batch):\n",
        "        processed_batch = batch.astype('float32') / 255.\n",
        "        return processed_batch\n",
        "\n",
        "    def process_reward(self, reward):\n",
        "        return np.clip(reward, -1., 1.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "hiperparametros = {\n",
        "    \"MEMORY_SIZE\": 500000,        # 50% más grande que antes\n",
        "    \"WARMUP_STEPS\": 100000,       # Más exploración inicial (10% de TRAIN_STEPS)\n",
        "    \"SCHEDULER_STEPS\": 3000000,   # Decaimiento lento de ε (exploración)\n",
        "    \"MODEL_CHECKPOINT_STEPS\": 30000,\n",
        "    \"GAMMA\": 0.95,                # Balance recompensas inmediatas\n",
        "    \"MODEL_UPDATE\": 2000,         # Target network se actualiza más frecuente\n",
        "    \"LEARNING_RATE\": 0.0001,      # LR más bajo para fine-tuning\n",
        "    \"TRAIN_STEPS\": 4000000,       # 4M pasos (2x tu versión anterior)\n",
        "    \"LOG_INTERVAL\": 10000,\n",
        "    \"DELTA_CLIP\": 0.5,\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "WRL-ixOyPIo7"
      },
      "outputs": [],
      "source": [
        "# ROOT PATH PARA LOS MODELOS Y SUS PESOS\n",
        "if IN_COLAB:\n",
        "  mount='/content/gdrive'\n",
        "  drive_root = mount + \"/My Drive/08_MIAR/actividades/proyecto practico\"\n",
        "  MODELS_DIR=drive_root+\"/models\"\n",
        "else:\n",
        "  MODELS_DIR=\"./models\"\n",
        "\n",
        "def get_dirs(model_name=\"modelo1\"):\n",
        "    WEIGHTS_DIR = os.path.join(MODELS_DIR, model_name, \"weights\")\n",
        "    CHECKPOINTS_DIR = os.path.join(MODELS_DIR, model_name, \"checkpoints\")\n",
        "    MODEL_DIR = os.path.join(MODELS_DIR, model_name)\n",
        "    os.makedirs(WEIGHTS_DIR, exist_ok=True)\n",
        "    os.makedirs(CHECKPOINTS_DIR, exist_ok=True)\n",
        "    return MODEL_DIR, WEIGHTS_DIR, CHECKPOINTS_DIR\n",
        "\n",
        "def save_hyperparams(modelo):\n",
        "    \"\"\"\n",
        "    Guarda los hiperparámetros actuales en el fichero JSON.\n",
        "    \"\"\"\n",
        "    hyper_file = os.path.join(MODELS_DIR, modelo, modelo + '.json')\n",
        "    with open(hyper_file, 'w') as f:\n",
        "        json.dump(hiperparametros, f, indent=4)\n",
        "    print(f\"[INFO] Hiperparámetros guardados en {hyper_file}\")\n",
        "\n",
        "\n",
        "def load_hyperparams(modelo):\n",
        "    \"\"\"\n",
        "    Actualiza los hiperparámetros definidos en memoria a los del fichero cargado.\n",
        "    Si el fichero no existe, lo crea con los valores por defecto (hiperparametros).\n",
        "    \"\"\"\n",
        "    hyper_file = os.path.join(MODELS_DIR, modelo, modelo + '.json')\n",
        "\n",
        "    # Crear el directorio del modelo si no existe\n",
        "    os.makedirs(os.path.dirname(hyper_file), exist_ok=True)\n",
        "\n",
        "    if not os.path.exists(hyper_file):\n",
        "        # Guardar el fichero con los hiperparámetros por defecto\n",
        "        with open(hyper_file, 'w') as f:\n",
        "            json.dump(hiperparametros, f, indent=4)\n",
        "\n",
        "        print(f\"[INFO] Fichero de hiperparámetros no encontrado. Creado por defecto en: {hyper_file}\")\n",
        "        params = hiperparametros\n",
        "    else:\n",
        "        # El fichero existe: lo leemos\n",
        "        with open(hyper_file, 'r') as f:\n",
        "            params = json.load(f)\n",
        "\n",
        "    # Asignar dinámicamente los valores\n",
        "    for key, value in params.items():\n",
        "        globals()[key] = value\n",
        "        hiperparametros[key] = value  # Actualiza el diccionario en memoria\n",
        "\n",
        "    print(f\"[INFO] Hiperparámetros cargados desde {hyper_file}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9KxgJ090eku"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN PARA PLOTEAR LOGS DEL TRAINING *** SARA ***\n",
        "'''\n",
        "def graph_training_csv(csv_path, model_dir, model_name, save_clean_csv=False):\n",
        "    if not os.path.isfile(csv_path):\n",
        "        print(f\"[ERROR] El archivo '{csv_path}' no existe.\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, usecols=[0, 1, 2])  # Usa encabezados del archivo\n",
        "        df.columns = ['episode_jump', 'episode_reward', 'nb_steps']\n",
        "    except Exception as e:\n",
        "        print(f\"[ERROR] No se pudo leer el CSV: {e}\")\n",
        "        return\n",
        "\n",
        "    # Ignorar la primera fila de datos (por ejemplo, episodio 1)\n",
        "    df = df.iloc[1:].reset_index(drop=True)\n",
        "\n",
        "    # Convertir nb_steps a entero seguro\n",
        "    df['nb_steps'] = pd.to_numeric(df['nb_steps'], errors='coerce')\n",
        "    df = df.dropna(subset=['nb_steps'])\n",
        "    df['nb_steps'] = df['nb_steps'].astype(int)\n",
        "\n",
        "    fixed_steps = []\n",
        "    accumulated_steps = 0\n",
        "    previous_step = df['nb_steps'].iloc[0]\n",
        "\n",
        "    for s in df['nb_steps']:\n",
        "      if s < previous_step:\n",
        "          accumulated_steps += previous_step\n",
        "          value= s + accumulated_steps\n",
        "      else:\n",
        "          if accumulated_steps == 0:\n",
        "              value = s\n",
        "          else:\n",
        "              value = s+ accumulated_steps\n",
        "      previous_step = s\n",
        "      fixed_steps.append(value)\n",
        "\n",
        "\n",
        "    df['fixed_steps'] = fixed_steps\n",
        "    print(f\"[INFO] Último valor en 'fixed_steps': {fixed_steps[-1]}\")\n",
        "\n",
        "    # Graficar\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(df['fixed_steps'], df['episode_reward'])\n",
        "    plt.title(f\"{model_name}: Episode Reward vs Steps\")\n",
        "    plt.xlabel(\"Steps\")\n",
        "    plt.ylabel(\"Episode Reward\")\n",
        "    plt.grid(True)\n",
        "\n",
        "    output_path = os.path.join(model_dir, f\"{model_name}_episode_reward_fixed_steps.png\")\n",
        "    plt.savefig(output_path)\n",
        "    print(f\"[INFO] Gráfica guardada en: {output_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    if save_clean_csv:\n",
        "        clean_csv_path = os.path.join(model_dir, f\"{model_name}_cleaned_log_fixed.csv\")\n",
        "        df.to_csv(clean_csv_path, index=False)\n",
        "        print(f\"[INFO] CSV corregido guardado en: {clean_csv_path}\")\n",
        "  '''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "Gd1JuAi9rCqr"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN PARA PLOTEAR LOGS DEL TRAINING *** BENJAMIN ***\n",
        "def analyze_training(model_name, window_size):\n",
        "    \"\"\"\n",
        "    Analiza el log de entrenamiento de un modelo de RL, genera gráficos de evolución\n",
        "    de métricas y un informe textual. Incluye un informe de métricas globales y otro\n",
        "    centrado en las métricas después de los window_size ultimos episodios.\n",
        "    Los graficos y datos son guardados en MODEL_DIR/graphs por fecha.\n",
        "\n",
        "    Args:\n",
        "        model_name (str): El nombre del modelo.\n",
        "        window_size (int): Tamaño de la ventana para la media móvil.\n",
        "    \"\"\"\n",
        "    MODEL_DIR = os.path.join(\"./models\", model_name)\n",
        "    log_csv_path = os.path.join(MODEL_DIR, f'{model_name}_training_log.csv')\n",
        "\n",
        "    if not os.path.exists(log_csv_path):\n",
        "        print(f\"Error: El archivo de log '{log_csv_path}' no se encontró.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(log_csv_path)\n",
        "\n",
        "    if df.empty:\n",
        "        print(\"El DataFrame está vacío, no se puede continuar.\")\n",
        "        return\n",
        "\n",
        "    # Calcular medias móviles\n",
        "    df['reward_smooth'] = df['episode_reward'].rolling(window=window_size).mean()\n",
        "    df['loss_smooth'] = df['loss'].rolling(window=window_size).mean()\n",
        "    df['q_smooth'] = df['mean_q'].rolling(window=window_size).mean()\n",
        "    df['eps_smooth'] = df['mean_eps'].rolling(window=window_size).mean()\n",
        "\n",
        "    # Generar gráficos\n",
        "    _plot_metrics(df, model_name, window_size, MODEL_DIR)\n",
        "\n",
        "    # Informe global\n",
        "    print(\"\\nINFORME DEL TRAINING (Todas las métricas)\\n\" + \"-\" * 40)\n",
        "    _print_report(df)\n",
        "\n",
        "    # Informe últimos episodios\n",
        "    _analyze_training_last(df, model_name, window_size, MODEL_DIR)\n",
        "\n",
        "def _plot_metrics(df, model_name, window_size, model_dir):\n",
        "    sns.set(style=\"darkgrid\", font_scale=1.2)\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
        "\n",
        "    plots_info = [\n",
        "        ('episode_reward', 'reward_smooth', 'Recompensa por episodio', 'Recompensa', axes[0, 0]),\n",
        "        ('loss', 'loss_smooth', 'Pérdida (loss) por episodio', 'Loss', axes[0, 1]),\n",
        "        ('mean_q', 'q_smooth', 'Q medio por episodio', 'Mean Q', axes[1, 0]),\n",
        "        ('mean_eps', 'eps_smooth', 'Epsilon medio por episodio', 'Mean Eps', axes[1, 1]),\n",
        "    ]\n",
        "\n",
        "    for orig_col, smooth_col, title, ylabel, ax in plots_info:\n",
        "        sns.lineplot(x='episode', y=orig_col, data=df, marker='o', markersize=4, label='Original', ax=ax)\n",
        "        sns.lineplot(x='episode', y=smooth_col, data=df, color='red', linewidth=2, label=f'Media móvil ({window_size})', ax=ax)\n",
        "        ax.set_title(title)\n",
        "        ax.set_xlabel('Episodio')\n",
        "        ax.set_ylabel(ylabel)\n",
        "        ax.grid(True, linestyle='--', alpha=0.7)\n",
        "\n",
        "        handles, labels = ax.get_legend_handles_labels()\n",
        "        unique = dict(zip(labels, handles))\n",
        "        ax.legend(unique.values(), unique.keys(), loc='best')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    graphs_dir = os.path.join(model_dir, \"graphs\")\n",
        "    os.makedirs(graphs_dir, exist_ok=True)\n",
        "\n",
        "    datetime_stamp = pd.to_datetime('today').strftime('%Y%m%d%H%M%S')\n",
        "    graph_path = os.path.join(graphs_dir, f'{datetime_stamp}_{model_name}_training_analyze_graph.png')\n",
        "    csv_path = os.path.join(graphs_dir, f'{datetime_stamp}_{model_name}_training_analyze_log.csv')\n",
        "\n",
        "    plt.savefig(graph_path, dpi=300)\n",
        "    df.to_csv(csv_path, index=False)\n",
        "    plt.show()\n",
        "\n",
        "    print(f\"Gráfico guardado en: {graph_path}\")\n",
        "    print(f\"CSV de informe guardado en: {csv_path}\")\n",
        "\n",
        "def _print_report(df):\n",
        "    print(f\"Episodios totales: {df['episode'].max()}\")\n",
        "    print(f\"Recompensa media: {df['episode_reward'].mean():.2f}\")\n",
        "    print(f\"Recompensa máxima: {df['episode_reward'].max()}\")\n",
        "    print(f\"Recompensa mínima: {df['episode_reward'].min()}\")\n",
        "    print(f\"Loss medio: {df['loss'].mean(skipna=True):.6f}\")\n",
        "    print(f\"Mean Q medio: {df['mean_q'].mean(skipna=True):.6f}\")\n",
        "    print(f\"Epsilon medio: {df['mean_eps'].mean(skipna=True):.6f}\")\n",
        "    print(f\"Pasos medios por episodio: {df['nb_steps'].mean():.2f}\")\n",
        "\n",
        "    if len(df) > 1:\n",
        "        reward_diff = df['episode_reward'].iloc[-1] - df['episode_reward'].iloc[0]\n",
        "        if reward_diff > 0:\n",
        "            print(f\"La recompensa final ({df['episode_reward'].iloc[-1]:.2f}) es mayor que la inicial ({df['episode_reward'].iloc[0]:.2f}), indicando una mejora.\")\n",
        "        else:\n",
        "            print(f\"La recompensa final ({df['episode_reward'].iloc[-1]:.2f}) no ha mejorado significativamente respecto a la inicial ({df['episode_reward'].iloc[0]:.2f}).\")\n",
        "    else:\n",
        "        print(\"No hay suficientes episodios para evaluar la evolución de la recompensa global.\")\n",
        "\n",
        "def _analyze_training_last(df_full, model_name, window_size, model_dir):\n",
        "    latest_log_path = _get_latest_log_file(model_dir, model_name)\n",
        "    if not latest_log_path:\n",
        "        print(\"No se encontró un CSV de análisis previo para los últimos episodios.\")\n",
        "        return\n",
        "\n",
        "    df = pd.read_csv(latest_log_path)\n",
        "    if df.empty:\n",
        "        print(\"El DataFrame de los últimos episodios está vacío.\")\n",
        "        return\n",
        "\n",
        "    df = df.tail(window_size + 1).iloc[:-1]\n",
        "\n",
        "    print(f\"\\nINFORME DEL TRAINING (últimos {window_size} episodios completados {df['episode'].min()} al {df['episode'].max()})\\n\" + \"-\" * 40)\n",
        "    _print_report(df)\n",
        "\n",
        "def _get_latest_log_file(model_dir, model_name):\n",
        "    pattern = os.path.join(model_dir, \"graphs\", f'*_{model_name}_training_analyze_log.csv')\n",
        "    files = glob.glob(pattern)\n",
        "    if not files:\n",
        "        return None\n",
        "    return max(files, key=os.path.basename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "qUOajl31fsW7"
      },
      "outputs": [],
      "source": [
        "# CALLBACK CUSTOM DEL LOGGER PARA PODER GUARDAR TODA LA INFO EN UN MISMO FICHERO YA QUE ANTES SE SOBREESCRIBÍA\n",
        "# BSL: AÑADIDAS NUEVAS MÉTRICAS AL LOGGER\n",
        "class EpisodeLoggerCSV(Callback):\n",
        "    def __init__(self, filepath, verbose=False):\n",
        "        super().__init__()\n",
        "        self.filepath = filepath\n",
        "        self.verbose = verbose\n",
        "        self.fields = [\n",
        "            'episode', 'episode_reward', 'nb_steps', 'duration',\n",
        "            'loss', 'mae', 'mean_q', 'mean_eps', 'ale.lives',\n",
        "            'reward_min', 'reward_max'\n",
        "        ]\n",
        "        self.episode_count = 0\n",
        "        self.file = None\n",
        "        self.writer = None\n",
        "        # Acumuladores por episodio\n",
        "        self._reset_episode_stats()\n",
        "\n",
        "    def _reset_episode_stats(self):\n",
        "        self.losses = []\n",
        "        self.q_values = []\n",
        "        self.maes = []\n",
        "        self.epsilons = []\n",
        "        self.lives = []\n",
        "        self.reward_values = []\n",
        "\n",
        "    def on_train_begin(self, logs=None):\n",
        "        file_exists = os.path.exists(self.filepath)\n",
        "        self.file = open(self.filepath, mode='a', newline='')\n",
        "        self.writer = csv.DictWriter(self.file, fieldnames=self.fields)\n",
        "        if not file_exists:\n",
        "            self.writer.writeheader()\n",
        "\n",
        "    def on_step_end(self, step, logs=None):\n",
        "        logs = logs or {}\n",
        "        if 'metrics' in logs and logs['metrics'] is not None:\n",
        "            metrics = logs['metrics']\n",
        "            if len(metrics) >= 4:\n",
        "                loss, mae, mean_q, mean_eps = metrics\n",
        "                if not np.isnan(loss):\n",
        "                    self.losses.append(loss)\n",
        "                if not np.isnan(mae):\n",
        "                    self.maes.append(mae)\n",
        "                if not np.isnan(mean_q):\n",
        "                    self.q_values.append(mean_q)\n",
        "                if not np.isnan(mean_eps):\n",
        "                    self.epsilons.append(mean_eps)\n",
        "        if 'reward' in logs:\n",
        "            self.reward_values.append(logs['reward'])\n",
        "        if 'info' in logs and 'ale.lives' in logs['info']:\n",
        "            self.lives.append(float(logs['info']['ale.lives']))\n",
        "\n",
        "    def on_episode_end(self, episode, logs=None):\n",
        "        self.episode_count += 1\n",
        "        logs = logs or {}\n",
        "\n",
        "        row = {\n",
        "            'episode': self.episode_count,\n",
        "            'episode_reward': logs.get('episode_reward'),\n",
        "            'nb_steps': logs.get('nb_steps'),\n",
        "            'duration': logs.get('duration'),\n",
        "            'loss': np.mean(self.losses) if self.losses else None,\n",
        "            'mae': np.mean(self.maes) if self.maes else None,\n",
        "            'mean_q': np.mean(self.q_values) if self.q_values else None,\n",
        "            'mean_eps': np.mean(self.epsilons) if self.epsilons else None,\n",
        "            'ale.lives': np.mean(self.lives) if self.lives else None,\n",
        "            'reward_min': np.min(self.reward_values) if self.reward_values else None,\n",
        "            'reward_max': np.max(self.reward_values) if self.reward_values else None\n",
        "        }\n",
        "\n",
        "        self.writer.writerow(row)\n",
        "        self.file.flush()\n",
        "\n",
        "        if self.verbose:\n",
        "            print(f\"[Log CSV] Episodio {row['episode']} - Recompensa: {row['episode_reward']} - \"\n",
        "                  f\"Loss: {row['loss']}, MAE: {row['mae']}, Mean Q: {row['mean_q']}\")\n",
        "\n",
        "        self._reset_episode_stats()\n",
        "\n",
        "    def on_train_end(self, logs=None):\n",
        "        if self.file:\n",
        "            self.file.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "jqpjeC-6J9xP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# CALLBACK CUSTOM PARA GUARDAR LOS CHECKPOINTS CON EL NOMBRE BIEN CUANDO SE REINICIA EL ENTRENAMIENTO Y LA MEMORIA\n",
        "class AccumulatedCheckpoint(Callback):\n",
        "    def __init__(self, base_path, env_name, interval, initial_step=0):\n",
        "        super().__init__()\n",
        "        self.base_path = base_path\n",
        "        self.weights_path = os.path.join(base_path, f'dqn_{env_name}_weights_{{step}}.h5f')\n",
        "        self.memory_path= os.path.join(base_path,'memory.pkl')\n",
        "        self.policy_state_path = os.path.join(base_path, 'policy.json')\n",
        "        self.interval = interval\n",
        "        self.total_steps = initial_step\n",
        "        print(f\"Callback iniciado desde paso {self.total_steps}\")\n",
        "\n",
        "    def on_step_end(self, step, logs={}):\n",
        "        self.total_steps += 1\n",
        "        if self.total_steps % self.interval == 0:\n",
        "            base = self.base_path.format(step=self.total_steps)\n",
        "\n",
        "            # Guardar pesos del modelo\n",
        "            weights_path = self.weights_path\n",
        "            weights_path = self.weights_path.format(step=self.total_steps)\n",
        "            self.model.save_weights(weights_path, overwrite=True)\n",
        "            print(f\"\\n[Checkpoint] Pesos guardados en: {weights_path}\")\n",
        "\n",
        "            # Guardar memoria de repetición\n",
        "            memory_path = self.memory_path\n",
        "            temp_path = memory_path + \".tmp\"\n",
        "\n",
        "            with open(temp_path, \"wb\") as f:\n",
        "                pickle.dump(self.model.memory, f)\n",
        "\n",
        "            # Solo si guardar ha ido bien\n",
        "            os.replace(temp_path, memory_path)\n",
        "            print(f\"\\n[Checkpoint] Memoria guardada de forma segura en: {memory_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QEeBZCr1J9xP",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN PARA CARGAR EL ÚLTMO CHECKPOINT DETECTADO\n",
        "def load_last_checkpoint(dqn):\n",
        "  # Buscar todos los checkpoints por su archivo .index\n",
        "  pattern = os.path.join(CHECKPOINTS_DIR, f'dqn_{env_name}_weights_*.h5f.index')\n",
        "  checkpoints = glob.glob(pattern)\n",
        "\n",
        "  # Valor por defecto si no se encuentra checkpoint\n",
        "  last_checkpoint_steps = 0\n",
        "\n",
        "  if checkpoints:\n",
        "      # Extraer el número de paso del nombre\n",
        "      def extract_step(filename):\n",
        "          try:\n",
        "              name = os.path.basename(filename)\n",
        "              step_part = name.split('_weights_')[1].replace('.h5f.index', '')\n",
        "              return int(step_part)\n",
        "          except:\n",
        "              return -1\n",
        "\n",
        "      # Seleccionar el checkpoint con mayor número de pasos\n",
        "      latest_index = max(checkpoints, key=extract_step)\n",
        "\n",
        "      # Quitar la extensión .index para obtener el nombre base\n",
        "      latest_checkpoint = latest_index.replace('.index', '')\n",
        "\n",
        "      print(f\"[DQN] Cargando último checkpoint: {latest_checkpoint}\")\n",
        "      dqn.load_weights(latest_checkpoint)\n",
        "\n",
        "      # Aquí extraemos los pasos acumulados\n",
        "      last_checkpoint_steps = extract_step(latest_index)\n",
        "  else:\n",
        "      print(\"[DQN] No se encontró ningún checkpoint, entrenamiento desde cero.\")\n",
        "  return dqn, last_checkpoint_steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "o2PywN6Wsef_"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN QUE PERMITE AJUSTAR LOS PARÁMETROS DE LA POLICY PARA QUE EL ENTRENAMIENTO SE REAUNDE POR DONDE TOCA\n",
        "# SI NO POR DEFECTO COMENZARÍA EN EL VALOR MÁXIMO DE EPSILON\n",
        "def adjust_policy_params(scheduler_steps, train_steps, current_step, value_max=1.0, value_min=0.01):\n",
        "    \"\"\"\n",
        "    Ajusta dinámicamente los parámetros de LinearAnnealedPolicy para reanudar la exploración desde el punto correcto.\n",
        "\n",
        "    Args:\n",
        "        scheduler_steps (int): Número de pasos que define la duración del decaimiento de eps.\n",
        "        train_steps (int): Número total de pasos planeados para el entrenamiento.\n",
        "        current_step (int): Paso actual o recuperado del checkpoint.\n",
        "        value_max (float): Valor inicial deseado de eps.\n",
        "        value_min (float): Valor mínimo deseado de eps.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (value_max_ajustado, value_min, scheduler_steps_restantes)\n",
        "    \"\"\"\n",
        "    if current_step >= scheduler_steps:\n",
        "        # Ya se alcanzó el mínimo, mantenerlo constante\n",
        "        return value_min, value_min, 1  # eps se queda fijo\n",
        "\n",
        "    # Calcular epsilon actual desde el punto alcanzado\n",
        "    frac = current_step / scheduler_steps\n",
        "    current_eps = value_max - (value_max - value_min) * frac\n",
        "\n",
        "    # Pasos restantes para completar el scheduler\n",
        "    steps_remaining = scheduler_steps - current_step\n",
        "    return current_eps, value_min, steps_remaining"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "88T-Q17-t1cw"
      },
      "outputs": [],
      "source": [
        "# FUNCIÓN PARA CARGAR LA MEMORIA Y EL NÚMERO DE PASOS DEL MODELO\n",
        "def get_memory_and_last_steps():\n",
        "  pattern = os.path.join(CHECKPOINTS_DIR, f'dqn_{env_name}_weights_*.h5f.index')\n",
        "  checkpoints = glob.glob(pattern)\n",
        "  last_checkpoint_steps = 0\n",
        "  memory = None\n",
        "\n",
        "  if checkpoints:\n",
        "      def extract_step(filename):\n",
        "          try:\n",
        "              name = os.path.basename(filename)\n",
        "              step_part = name.split('_weights_')[1].replace('.h5f.index', '')\n",
        "              return int(step_part)\n",
        "          except:\n",
        "              return -1\n",
        "\n",
        "      # Encontrar el último checkpoint\n",
        "      latest_index = max(checkpoints, key=extract_step)\n",
        "      latest_checkpoint = latest_index.replace('.index', '')\n",
        "      last_checkpoint_steps = extract_step(latest_index)\n",
        "      print(f\"Último step de checkpoint: {last_checkpoint_steps}\")\n",
        "\n",
        "      # Cargar memoria\n",
        "      memory_path = os.path.join(CHECKPOINTS_DIR, \"memory.pkl\")\n",
        "      if os.path.exists(memory_path):\n",
        "          with open(memory_path, \"rb\") as f:\n",
        "              memory = pickle.load(f)\n",
        "          print(f\"Memoria cargada desde: {memory_path}\")\n",
        "      else:\n",
        "          print(\"No se encontró memoria para este checkpoint.\")\n",
        "\n",
        "  else:\n",
        "      print(\"No se encontró ningún checkpoint, entrenamiento desde cero.\")\n",
        "  return memory, last_checkpoint_steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpVqx7bnJLKg",
        "tags": []
      },
      "source": [
        "# MODELO D1 att"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8uEMcNQ45ISB"
      },
      "source": [
        "Aquí se presenta una variante del modelo D1\n",
        "\n",
        "Gaussian Noise en input:\n",
        "\n",
        "Mejora generalización simulando variaciones en pixels\n",
        "\n",
        "SpatialDropout2D:\n",
        "\n",
        "Mejor que Dropout para capas convolucionales (elimina canales completos)\n",
        "\n",
        "Mecanismo de Attention simple:\n",
        "\n",
        "Ayuda al modelo a enfocarse en enemigos y proyectiles\n",
        "\n",
        "Inicialización He Normal:\n",
        "\n",
        "Optimizada para LeakyReLU (mejor flujo de gradientes)\n",
        "\n",
        "Hiperparámetros ajustados:\n",
        "\n",
        "GAMMA=0.96: Prioriza disparar enemigos (recompensa inmediata) sin descuidar supervivencia\n",
        "\n",
        "MODEL_UPDATE=3000: Más estabilidad en aprendizaje profundo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HT45Y6y25ISB"
      },
      "source": [
        "## DQN\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yitXTADGb2b"
      },
      "source": [
        "1. Implementación de la red neuronal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBvHXcEe6eF0",
        "outputId": "7e2f800a-aaef-47f5-e758-bab84eac6303"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            [(None, 4, 84, 84)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "permute_2 (Permute)             (None, 84, 84, 4)    0           input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_2 (Lambda)               (None, 84, 84, 4)    0           permute_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gaussian_noise_2 (GaussianNoise (None, 84, 84, 4)    0           lambda_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 21, 21, 64)   16448       gaussian_noise_2[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 21, 21, 64)   256         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_10 (LeakyReLU)      (None, 21, 21, 64)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_4 (SpatialDro (None, 21, 21, 64)   0           leaky_re_lu_10[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 11, 11, 128)  131200      spatial_dropout2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 11, 11, 128)  512         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_11 (LeakyReLU)      (None, 11, 11, 128)  0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 11, 11, 256)  295168      leaky_re_lu_11[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 11, 11, 256)  1024        conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_12 (LeakyReLU)      (None, 11, 11, 256)  0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "spatial_dropout2d_5 (SpatialDro (None, 11, 11, 256)  0           leaky_re_lu_12[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 11, 11, 1)    257         spatial_dropout2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "multiply_2 (Multiply)           (None, 11, 11, 256)  0           spatial_dropout2d_5[0][0]        \n",
            "                                                                 conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "flatten_2 (Flatten)             (None, 30976)        0           multiply_2[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 512)          15860224    flatten_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_13 (LeakyReLU)      (None, 512)          0           dense_6[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_2 (Dropout)             (None, 512)          0           leaky_re_lu_13[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_7 (Dense)                 (None, 256)          131328      dropout_2[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_14 (LeakyReLU)      (None, 256)          0           dense_7[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_8 (Dense)                 (None, 6)            1542        leaky_re_lu_14[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 16,437,959\n",
            "Trainable params: 16,437,063\n",
            "Non-trainable params: 896\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.layers import LeakyReLU, GaussianNoise, SpatialDropout2D\n",
        "from tensorflow.keras.layers import Dropout, Conv2D, Multiply\n",
        "from tensorflow.keras.initializers import he_normal, glorot_uniform\n",
        "\n",
        "\n",
        "# 1. Definición del modelo con Attention\n",
        "model_name = \"modelo_D1_Attention_enhancedhyperparams\"\n",
        "input_shape = (WINDOW_LENGTH,) + INPUT_SHAPE\n",
        "\n",
        "# Capa de entrada\n",
        "inputs = Input(shape=input_shape)\n",
        "\n",
        "# Preprocesamiento\n",
        "x = Permute((2, 3, 1))(inputs) if K.image_data_format() == 'channels_last' else Permute((1, 2, 3))(inputs)\n",
        "x = Lambda(lambda x: x / 255.0)(x)\n",
        "x = GaussianNoise(0.01)(x)\n",
        "\n",
        "# Bloques convolucionales\n",
        "x = Conv2D(64, (8, 8), strides=(4, 4), padding='same', kernel_initializer=he_normal())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = SpatialDropout2D(0.1)(x)\n",
        "\n",
        "x = Conv2D(128, (4, 4), strides=(2, 2), padding='same', kernel_initializer=he_normal())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "x = Conv2D(256, (3, 3), strides=(1, 1), padding='same', kernel_initializer=he_normal())(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = SpatialDropout2D(0.1)(x)\n",
        "\n",
        "# Mecanismo de atención\n",
        "attention = Conv2D(1, (1, 1), activation='sigmoid')(x)  # Mapa de atención (0 a 1)\n",
        "x = Multiply()([x, attention])  # Aplicar atención\n",
        "\n",
        "# Capas densas\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, kernel_initializer=he_normal())(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "x = Dropout(0.3)(x)\n",
        "\n",
        "x = Dense(256, kernel_initializer=he_normal())(x)\n",
        "x = LeakyReLU(alpha=0.1)(x)\n",
        "\n",
        "# Salida\n",
        "outputs = Dense(nb_actions, kernel_initializer=glorot_uniform(), activation='linear')(x)\n",
        "\n",
        "# Crear modelo\n",
        "model = Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Num GPUs Available: 1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"Num GPUs Available:\", len(tf.config.list_physical_devices('GPU')))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OB9-_5HPGb2b"
      },
      "source": [
        "2. Implementación de la solución DQN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JxBLemXQQam3",
        "outputId": "d93f440f-33b4-492c-a056-bd0362ced1f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[INFO] Fichero de hiperparámetros no encontrado. Creado por defecto en: ./models\\modelo_D1_Attention_enhancedhyperparams\\modelo_D1_Attention_enhancedhyperparams.json\n",
            "[INFO] Hiperparámetros cargados desde ./models\\modelo_D1_Attention_enhancedhyperparams\\modelo_D1_Attention_enhancedhyperparams.json\n"
          ]
        }
      ],
      "source": [
        "# GENERACIÓN O CARGA MODELO\n",
        "MODEL_DIR, WEIGHTS_DIR, CHECKPOINTS_DIR = get_dirs(model_name)\n",
        "# save_hyperparams(HYPERPARAMETERS_DIR, filename=model_name+\".json\")\n",
        "load_hyperparams(model_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "foSlxWH1Gb2b",
        "outputId": "79fca2b4-2b67-4bce-f0e9-602bca9f2597",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No se encontró ningún checkpoint, entrenamiento desde cero.\n",
            "Memoria inicializada de 0\n",
            "Valores de la policy: value_min=0.01, value_max=1.0, scheduler_steps=3000000\n"
          ]
        }
      ],
      "source": [
        "# DEFINICIÓN DE LA POLICY\n",
        "\n",
        "memory, last_checkpoint_steps=get_memory_and_last_steps()\n",
        "\n",
        "value_max, value_min, new_scheduler_steps = adjust_policy_params(\n",
        "    scheduler_steps=SCHEDULER_STEPS,\n",
        "    train_steps=TRAIN_STEPS,\n",
        "    current_step=last_checkpoint_steps\n",
        ")\n",
        "if not memory:\n",
        "  memory = SequentialMemory(limit=MEMORY_SIZE, window_length=WINDOW_LENGTH)\n",
        "  print(\"Memoria inicializada de 0\")\n",
        "\n",
        "print(f\"Valores de la policy: value_min={value_min}, value_max={value_max}, scheduler_steps={new_scheduler_steps}\")\n",
        "\n",
        "processor = CustomProcessor()\n",
        "\n",
        "policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "                              value_max=value_max, value_min=value_min,\n",
        "                              value_test=.05,\n",
        "                              nb_steps=new_scheduler_steps)\n",
        "#policy = LinearAnnealedPolicy(EpsGreedyQPolicy(), attr='eps',\n",
        "#                              value_max=1., value_min=.1,\n",
        "#                              value_test=.05,\n",
        "#                              nb_steps=SCHEDULER_STEPS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "G6mWUNNi5ISE",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# CREACIÓN DEL AGENTE DQN\n",
        "dqn = DQNAgent(model=model,\n",
        "               nb_actions=nb_actions,\n",
        "               policy=policy,\n",
        "               memory=memory,\n",
        "               processor=processor,\n",
        "               nb_steps_warmup=WARMUP_STEPS,\n",
        "               gamma=GAMMA,\n",
        "               target_model_update=MODEL_UPDATE,\n",
        "               train_interval=4,\n",
        "               delta_clip=DELTA_CLIP)\n",
        "\n",
        "if IN_COLAB:\n",
        "    # Parche para evitar el error 'get_updates' que ya no existe\n",
        "    def patched_get_updates(self, loss, params):\n",
        "        return []\n",
        "    Adam.get_updates = patched_get_updates\n",
        "\n",
        "dqn.compile(Adam(learning_rate=LEARNING_RATE), metrics=['mae'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "TxfFDyGzS3_K"
      },
      "outputs": [],
      "source": [
        "# DEFINICIÓN DE LOS NOMBRES DE FICHEROS DE SALIDA\n",
        "weights_filename = os.path.join(WEIGHTS_DIR, 'dqn_{}_weights_{}.h5f'.format(env_name, model_name))\n",
        "checkpoint_weights_filename = os.path.join(CHECKPOINTS_DIR, 'dqn_' + env_name + '_weights_{step}.h5f')\n",
        "log_filename =os.path.join(MODEL_DIR, 'dqn_{}_log_{}.json'.format(env_name, model_name))\n",
        "log_csv_path = os.path.join(MODEL_DIR, f'{model_name}_training_log.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgEZ4q9OB41r",
        "outputId": "3aafb8d1-291a-4430-d5d7-4aa0089759b9",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[DQN] No se encontró ningún checkpoint, entrenamiento desde cero.\n",
            "Callback iniciado desde paso 0\n"
          ]
        }
      ],
      "source": [
        "# CARGAR PESOS DEL ÚLTIMO CHECKPOINT SI EXISTE\n",
        "dqn, last_checkpoint_steps = load_last_checkpoint(dqn)\n",
        "# CREAR CALLBACKS CUSTOMIZADOS QUE GUARDAN BIEN LOS CHECKPOINTS Y LOGS DEL TRAINING\n",
        "checkpoint_callback = AccumulatedCheckpoint(\n",
        "      base_path=CHECKPOINTS_DIR,\n",
        "      env_name=env_name,\n",
        "      interval=MODEL_CHECKPOINT_STEPS,\n",
        "      initial_step=last_checkpoint_steps\n",
        "  )\n",
        "callbacks = [checkpoint_callback]\n",
        "dqn.step = last_checkpoint_steps\n",
        "callbacks += [EpisodeLoggerCSV(log_csv_path)]\n",
        "#callbacks =  [ModelIntervalCheckpoint(checkpoint_weights_filename, interval=MODEL_CHECKPOINT_STEPS)]\n",
        "#callbacks += [FileLogger(log_filename, interval=100)] # Gives some errors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BSoqLO65ISF",
        "outputId": "e9df2221-2c03-4c5e-b807-e46f2eff1727",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training for 4000000 steps ...\n",
            "Interval 1 (0 steps performed)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "x:\\08_MIAR\\actividades\\proyecto_practico\\venv_rl\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:2426: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
            "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 67s 6ms/step - reward: 0.0510\n",
            "63 episodes - episode_reward: 8.095 [0.000, 18.000] - ale.lives: 2.103\n",
            "\n",
            "Interval 2 (10000 steps performed)\n",
            "10000/10000 [==============================] - 59s 6ms/step - reward: 0.0568\n",
            "56 episodes - episode_reward: 9.982 [2.000, 23.000] - ale.lives: 2.032\n",
            "\n",
            "Interval 3 (20000 steps performed)\n",
            " 9994/10000 [============================>.] - ETA: 0s - reward: 0.0529\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_30000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 60s 6ms/step - reward: 0.0529\n",
            "56 episodes - episode_reward: 9.536 [3.000, 21.000] - ale.lives: 2.089\n",
            "\n",
            "Interval 4 (30000 steps performed)\n",
            "10000/10000 [==============================] - 59s 6ms/step - reward: 0.0487\n",
            "59 episodes - episode_reward: 8.186 [2.000, 25.000] - ale.lives: 2.059\n",
            "\n",
            "Interval 5 (40000 steps performed)\n",
            "10000/10000 [==============================] - 59s 6ms/step - reward: 0.0588\n",
            "56 episodes - episode_reward: 10.643 [3.000, 29.000] - ale.lives: 2.011\n",
            "\n",
            "Interval 6 (50000 steps performed)\n",
            " 9998/10000 [============================>.] - ETA: 0s - reward: 0.0579\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_60000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 64s 6ms/step - reward: 0.0580\n",
            "59 episodes - episode_reward: 9.746 [2.000, 23.000] - ale.lives: 2.070\n",
            "\n",
            "Interval 7 (60000 steps performed)\n",
            "10000/10000 [==============================] - 60s 6ms/step - reward: 0.0553\n",
            "58 episodes - episode_reward: 9.466 [3.000, 23.000] - ale.lives: 2.027\n",
            "\n",
            "Interval 8 (70000 steps performed)\n",
            "10000/10000 [==============================] - 59s 6ms/step - reward: 0.0567\n",
            "58 episodes - episode_reward: 9.931 [1.000, 25.000] - ale.lives: 2.120\n",
            "\n",
            "Interval 9 (80000 steps performed)\n",
            " 9998/10000 [============================>.] - ETA: 0s - reward: 0.0545\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_90000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 61s 6ms/step - reward: 0.0545\n",
            "57 episodes - episode_reward: 9.561 [2.000, 26.000] - ale.lives: 2.061\n",
            "\n",
            "Interval 10 (90000 steps performed)\n",
            "10000/10000 [==============================] - 61s 6ms/step - reward: 0.0539\n",
            "61 episodes - episode_reward: 8.820 [1.000, 32.000] - ale.lives: 2.011\n",
            "\n",
            "Interval 11 (100000 steps performed)\n",
            "10000/10000 [==============================] - 290s 29ms/step - reward: 0.0590\n",
            "58 episodes - episode_reward: 9.810 [2.000, 26.000] - loss: 0.024 - mae: 0.129 - mean_q: 0.188 - mean_eps: 0.965 - ale.lives: 2.064\n",
            "\n",
            "Interval 12 (110000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0615\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_120000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 291s 29ms/step - reward: 0.0615\n",
            "55 episodes - episode_reward: 11.564 [2.000, 25.000] - loss: 0.021 - mae: 0.153 - mean_q: 0.190 - mean_eps: 0.962 - ale.lives: 2.099\n",
            "\n",
            "Interval 13 (120000 steps performed)\n",
            "10000/10000 [==============================] - 289s 29ms/step - reward: 0.0543\n",
            "56 episodes - episode_reward: 9.607 [2.000, 22.000] - loss: 0.021 - mae: 0.163 - mean_q: 0.196 - mean_eps: 0.959 - ale.lives: 2.019\n",
            "\n",
            "Interval 14 (130000 steps performed)\n",
            "10000/10000 [==============================] - 289s 29ms/step - reward: 0.0527\n",
            "56 episodes - episode_reward: 9.411 [2.000, 22.000] - loss: 0.022 - mae: 0.433 - mean_q: 0.524 - mean_eps: 0.955 - ale.lives: 2.012\n",
            "\n",
            "Interval 15 (140000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0588\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_150000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 294s 29ms/step - reward: 0.0588\n",
            "54 episodes - episode_reward: 10.796 [3.000, 25.000] - loss: 0.022 - mae: 0.532 - mean_q: 0.642 - mean_eps: 0.952 - ale.lives: 2.040\n",
            "\n",
            "Interval 16 (150000 steps performed)\n",
            "10000/10000 [==============================] - 291s 29ms/step - reward: 0.0557\n",
            "56 episodes - episode_reward: 10.071 [2.000, 27.000] - loss: 0.021 - mae: 0.443 - mean_q: 0.532 - mean_eps: 0.949 - ale.lives: 2.006\n",
            "\n",
            "Interval 17 (160000 steps performed)\n",
            "10000/10000 [==============================] - 292s 29ms/step - reward: 0.0573\n",
            "58 episodes - episode_reward: 9.741 [3.000, 23.000] - loss: 0.021 - mae: 0.389 - mean_q: 0.466 - mean_eps: 0.946 - ale.lives: 2.017\n",
            "\n",
            "Interval 18 (170000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0524\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_180000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 298s 30ms/step - reward: 0.0524\n",
            "60 episodes - episode_reward: 8.683 [1.000, 22.000] - loss: 0.021 - mae: 0.463 - mean_q: 0.555 - mean_eps: 0.942 - ale.lives: 2.113\n",
            "\n",
            "Interval 19 (180000 steps performed)\n",
            "10000/10000 [==============================] - 295s 29ms/step - reward: 0.0608\n",
            "53 episodes - episode_reward: 11.660 [2.000, 29.000] - loss: 0.022 - mae: 0.474 - mean_q: 0.568 - mean_eps: 0.939 - ale.lives: 1.996\n",
            "\n",
            "Interval 20 (190000 steps performed)\n",
            "10000/10000 [==============================] - 296s 30ms/step - reward: 0.0556\n",
            "58 episodes - episode_reward: 9.293 [3.000, 27.000] - loss: 0.021 - mae: 0.480 - mean_q: 0.574 - mean_eps: 0.936 - ale.lives: 2.031\n",
            "\n",
            "Interval 21 (200000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0546\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_210000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 302s 30ms/step - reward: 0.0547\n",
            "62 episodes - episode_reward: 9.081 [1.000, 25.000] - loss: 0.021 - mae: 0.378 - mean_q: 0.449 - mean_eps: 0.932 - ale.lives: 2.095\n",
            "\n",
            "Interval 22 (210000 steps performed)\n",
            "10000/10000 [==============================] - 298s 30ms/step - reward: 0.0537\n",
            "57 episodes - episode_reward: 9.140 [2.000, 21.000] - loss: 0.021 - mae: 0.314 - mean_q: 0.371 - mean_eps: 0.929 - ale.lives: 2.029\n",
            "\n",
            "Interval 23 (220000 steps performed)\n",
            "10000/10000 [==============================] - 300s 30ms/step - reward: 0.0541\n",
            "62 episodes - episode_reward: 9.016 [2.000, 25.000] - loss: 0.021 - mae: 0.291 - mean_q: 0.341 - mean_eps: 0.926 - ale.lives: 2.070\n",
            "\n",
            "Interval 24 (230000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0576\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_240000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 307s 31ms/step - reward: 0.0576\n",
            "58 episodes - episode_reward: 9.983 [3.000, 26.000] - loss: 0.021 - mae: 0.301 - mean_q: 0.354 - mean_eps: 0.922 - ale.lives: 2.103\n",
            "\n",
            "Interval 25 (240000 steps performed)\n",
            "10000/10000 [==============================] - 303s 30ms/step - reward: 0.0596\n",
            "55 episodes - episode_reward: 10.855 [2.000, 22.000] - loss: 0.021 - mae: 0.321 - mean_q: 0.378 - mean_eps: 0.919 - ale.lives: 2.018\n",
            "\n",
            "Interval 26 (250000 steps performed)\n",
            "10000/10000 [==============================] - 302s 30ms/step - reward: 0.0542\n",
            "55 episodes - episode_reward: 9.818 [3.000, 28.000] - loss: 0.021 - mae: 0.352 - mean_q: 0.414 - mean_eps: 0.916 - ale.lives: 2.099\n",
            "\n",
            "Interval 27 (260000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0546\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_270000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 311s 31ms/step - reward: 0.0546\n",
            "57 episodes - episode_reward: 9.614 [0.000, 23.000] - loss: 0.021 - mae: 0.379 - mean_q: 0.446 - mean_eps: 0.913 - ale.lives: 1.958\n",
            "\n",
            "Interval 28 (270000 steps performed)\n",
            "10000/10000 [==============================] - 307s 31ms/step - reward: 0.0570\n",
            "56 episodes - episode_reward: 10.179 [2.000, 29.000] - loss: 0.021 - mae: 0.408 - mean_q: 0.482 - mean_eps: 0.909 - ale.lives: 2.030\n",
            "\n",
            "Interval 29 (280000 steps performed)\n",
            "10000/10000 [==============================] - 309s 31ms/step - reward: 0.0577\n",
            "55 episodes - episode_reward: 10.309 [2.000, 23.000] - loss: 0.021 - mae: 0.424 - mean_q: 0.499 - mean_eps: 0.906 - ale.lives: 2.072\n",
            "\n",
            "Interval 30 (290000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0540\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_300000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 317s 32ms/step - reward: 0.0540\n",
            "62 episodes - episode_reward: 8.806 [3.000, 23.000] - loss: 0.022 - mae: 0.435 - mean_q: 0.514 - mean_eps: 0.903 - ale.lives: 2.039\n",
            "\n",
            "Interval 31 (300000 steps performed)\n",
            "10000/10000 [==============================] - 309s 31ms/step - reward: 0.0535\n",
            "59 episodes - episode_reward: 9.136 [3.000, 21.000] - loss: 0.021 - mae: 0.445 - mean_q: 0.525 - mean_eps: 0.899 - ale.lives: 2.036\n",
            "\n",
            "Interval 32 (310000 steps performed)\n",
            "10000/10000 [==============================] - 310s 31ms/step - reward: 0.0531\n",
            "60 episodes - episode_reward: 8.850 [2.000, 29.000] - loss: 0.022 - mae: 0.450 - mean_q: 0.532 - mean_eps: 0.896 - ale.lives: 2.071\n",
            "\n",
            "Interval 33 (320000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0551\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_330000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 321s 32ms/step - reward: 0.0552\n",
            "56 episodes - episode_reward: 9.714 [3.000, 30.000] - loss: 0.021 - mae: 0.459 - mean_q: 0.542 - mean_eps: 0.893 - ale.lives: 2.049\n",
            "\n",
            "Interval 34 (330000 steps performed)\n",
            "10000/10000 [==============================] - 314s 31ms/step - reward: 0.0563\n",
            "63 episodes - episode_reward: 8.984 [3.000, 34.000] - loss: 0.021 - mae: 0.478 - mean_q: 0.566 - mean_eps: 0.889 - ale.lives: 1.983\n",
            "\n",
            "Interval 35 (340000 steps performed)\n",
            "10000/10000 [==============================] - 315s 31ms/step - reward: 0.0550\n",
            "56 episodes - episode_reward: 9.821 [3.000, 31.000] - loss: 0.022 - mae: 0.484 - mean_q: 0.572 - mean_eps: 0.886 - ale.lives: 2.081\n",
            "\n",
            "Interval 36 (350000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0534\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_360000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 328s 33ms/step - reward: 0.0534\n",
            "57 episodes - episode_reward: 9.456 [2.000, 29.000] - loss: 0.022 - mae: 0.494 - mean_q: 0.584 - mean_eps: 0.883 - ale.lives: 2.049\n",
            "\n",
            "Interval 37 (360000 steps performed)\n",
            "10000/10000 [==============================] - 320s 32ms/step - reward: 0.0531\n",
            "57 episodes - episode_reward: 9.316 [2.000, 24.000] - loss: 0.021 - mae: 0.502 - mean_q: 0.593 - mean_eps: 0.880 - ale.lives: 2.100\n",
            "\n",
            "Interval 38 (370000 steps performed)\n",
            "10000/10000 [==============================] - 320s 32ms/step - reward: 0.0566\n",
            "55 episodes - episode_reward: 10.218 [3.000, 23.000] - loss: 0.022 - mae: 0.517 - mean_q: 0.611 - mean_eps: 0.876 - ale.lives: 2.023\n",
            "\n",
            "Interval 39 (380000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0564\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_390000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 335s 34ms/step - reward: 0.0564\n",
            "58 episodes - episode_reward: 9.793 [1.000, 27.000] - loss: 0.022 - mae: 0.530 - mean_q: 0.628 - mean_eps: 0.873 - ale.lives: 1.993\n",
            "\n",
            "Interval 40 (390000 steps performed)\n",
            "10000/10000 [==============================] - 324s 32ms/step - reward: 0.0540\n",
            "61 episodes - episode_reward: 8.852 [1.000, 25.000] - loss: 0.021 - mae: 0.541 - mean_q: 0.642 - mean_eps: 0.870 - ale.lives: 2.043\n",
            "\n",
            "Interval 41 (400000 steps performed)\n",
            "10000/10000 [==============================] - 324s 32ms/step - reward: 0.0557\n",
            "56 episodes - episode_reward: 9.482 [2.000, 27.000] - loss: 0.022 - mae: 0.553 - mean_q: 0.655 - mean_eps: 0.866 - ale.lives: 2.061\n",
            "\n",
            "Interval 42 (410000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0552\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_420000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 337s 34ms/step - reward: 0.0553\n",
            "54 episodes - episode_reward: 10.630 [1.000, 30.000] - loss: 0.021 - mae: 0.546 - mean_q: 0.646 - mean_eps: 0.863 - ale.lives: 2.030\n",
            "\n",
            "Interval 43 (420000 steps performed)\n",
            "10000/10000 [==============================] - 332s 33ms/step - reward: 0.0572\n",
            "57 episodes - episode_reward: 10.070 [1.000, 26.000] - loss: 0.022 - mae: 0.546 - mean_q: 0.646 - mean_eps: 0.860 - ale.lives: 2.008\n",
            "\n",
            "Interval 44 (430000 steps performed)\n",
            "10000/10000 [==============================] - 333s 33ms/step - reward: 0.0565\n",
            "54 episodes - episode_reward: 10.426 [2.000, 29.000] - loss: 0.021 - mae: 0.567 - mean_q: 0.672 - mean_eps: 0.856 - ale.lives: 2.116\n",
            "\n",
            "Interval 45 (440000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0605\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_450000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 349s 35ms/step - reward: 0.0605\n",
            "55 episodes - episode_reward: 11.091 [2.000, 28.000] - loss: 0.021 - mae: 0.566 - mean_q: 0.671 - mean_eps: 0.853 - ale.lives: 2.055\n",
            "\n",
            "Interval 46 (450000 steps performed)\n",
            "10000/10000 [==============================] - 347s 35ms/step - reward: 0.0553\n",
            "56 episodes - episode_reward: 9.857 [1.000, 26.000] - loss: 0.022 - mae: 0.568 - mean_q: 0.673 - mean_eps: 0.850 - ale.lives: 2.035\n",
            "\n",
            "Interval 47 (460000 steps performed)\n",
            "10000/10000 [==============================] - 347s 35ms/step - reward: 0.0553\n",
            "57 episodes - episode_reward: 9.667 [1.000, 27.000] - loss: 0.022 - mae: 0.564 - mean_q: 0.669 - mean_eps: 0.847 - ale.lives: 2.008\n",
            "\n",
            "Interval 48 (470000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0562\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_480000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 367s 37ms/step - reward: 0.0562\n",
            "58 episodes - episode_reward: 9.603 [4.000, 20.000] - loss: 0.022 - mae: 0.568 - mean_q: 0.673 - mean_eps: 0.843 - ale.lives: 2.066\n",
            "\n",
            "Interval 49 (480000 steps performed)\n",
            "10000/10000 [==============================] - 355s 35ms/step - reward: 0.0527\n",
            "55 episodes - episode_reward: 9.655 [0.000, 23.000] - loss: 0.022 - mae: 0.576 - mean_q: 0.682 - mean_eps: 0.840 - ale.lives: 1.990\n",
            "\n",
            "Interval 50 (490000 steps performed)\n",
            "10000/10000 [==============================] - 354s 35ms/step - reward: 0.0560\n",
            "55 episodes - episode_reward: 10.218 [3.000, 26.000] - loss: 0.022 - mae: 0.582 - mean_q: 0.689 - mean_eps: 0.837 - ale.lives: 1.988\n",
            "\n",
            "Interval 51 (500000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0543\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_510000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 373s 37ms/step - reward: 0.0543\n",
            "62 episodes - episode_reward: 8.645 [2.000, 22.000] - loss: 0.021 - mae: 0.584 - mean_q: 0.693 - mean_eps: 0.833 - ale.lives: 2.040\n",
            "\n",
            "Interval 52 (510000 steps performed)\n",
            "10000/10000 [==============================] - 354s 35ms/step - reward: 0.0562\n",
            "56 episodes - episode_reward: 10.125 [2.000, 23.000] - loss: 0.021 - mae: 0.580 - mean_q: 0.688 - mean_eps: 0.830 - ale.lives: 2.004\n",
            "\n",
            "Interval 53 (520000 steps performed)\n",
            "10000/10000 [==============================] - 355s 36ms/step - reward: 0.0542\n",
            "53 episodes - episode_reward: 10.094 [2.000, 22.000] - loss: 0.021 - mae: 0.576 - mean_q: 0.683 - mean_eps: 0.827 - ale.lives: 2.061\n",
            "\n",
            "Interval 54 (530000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0600\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_540000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 374s 37ms/step - reward: 0.0600\n",
            "59 episodes - episode_reward: 10.356 [2.000, 27.000] - loss: 0.022 - mae: 0.583 - mean_q: 0.692 - mean_eps: 0.823 - ale.lives: 2.047\n",
            "\n",
            "Interval 55 (540000 steps performed)\n",
            "10000/10000 [==============================] - 364s 36ms/step - reward: 0.0559\n",
            "58 episodes - episode_reward: 9.500 [0.000, 30.000] - loss: 0.021 - mae: 0.583 - mean_q: 0.691 - mean_eps: 0.820 - ale.lives: 2.065\n",
            "\n",
            "Interval 56 (550000 steps performed)\n",
            "10000/10000 [==============================] - 358s 36ms/step - reward: 0.0528\n",
            "62 episodes - episode_reward: 8.516 [2.000, 19.000] - loss: 0.022 - mae: 0.579 - mean_q: 0.685 - mean_eps: 0.817 - ale.lives: 2.032\n",
            "\n",
            "Interval 57 (560000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0556\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_570000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0556\n",
            "55 episodes - episode_reward: 10.164 [3.000, 28.000] - loss: 0.022 - mae: 0.570 - mean_q: 0.674 - mean_eps: 0.814 - ale.lives: 2.101\n",
            "\n",
            "Interval 58 (570000 steps performed)\n",
            "10000/10000 [==============================] - 359s 36ms/step - reward: 0.0518\n",
            "58 episodes - episode_reward: 8.914 [2.000, 19.000] - loss: 0.022 - mae: 0.579 - mean_q: 0.686 - mean_eps: 0.810 - ale.lives: 2.055\n",
            "\n",
            "Interval 59 (580000 steps performed)\n",
            "10000/10000 [==============================] - 360s 36ms/step - reward: 0.0520\n",
            "57 episodes - episode_reward: 9.088 [1.000, 23.000] - loss: 0.021 - mae: 0.582 - mean_q: 0.690 - mean_eps: 0.807 - ale.lives: 2.122\n",
            "\n",
            "Interval 60 (590000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0532\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_600000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 377s 38ms/step - reward: 0.0532\n",
            "55 episodes - episode_reward: 9.709 [1.000, 25.000] - loss: 0.021 - mae: 0.587 - mean_q: 0.695 - mean_eps: 0.804 - ale.lives: 2.068\n",
            "\n",
            "Interval 61 (600000 steps performed)\n",
            "10000/10000 [==============================] - 359s 36ms/step - reward: 0.0516\n",
            "62 episodes - episode_reward: 8.339 [3.000, 22.000] - loss: 0.022 - mae: 0.592 - mean_q: 0.701 - mean_eps: 0.800 - ale.lives: 2.035\n",
            "\n",
            "Interval 62 (610000 steps performed)\n",
            "10000/10000 [==============================] - 361s 36ms/step - reward: 0.0553\n",
            "59 episodes - episode_reward: 9.356 [2.000, 27.000] - loss: 0.021 - mae: 0.581 - mean_q: 0.688 - mean_eps: 0.797 - ale.lives: 2.071\n",
            "\n",
            "Interval 63 (620000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0520\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_630000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 380s 38ms/step - reward: 0.0521\n",
            "58 episodes - episode_reward: 9.069 [2.000, 21.000] - loss: 0.022 - mae: 0.579 - mean_q: 0.685 - mean_eps: 0.794 - ale.lives: 2.054\n",
            "\n",
            "Interval 64 (630000 steps performed)\n",
            "10000/10000 [==============================] - 360s 36ms/step - reward: 0.0562\n",
            "55 episodes - episode_reward: 10.091 [1.000, 25.000] - loss: 0.022 - mae: 0.581 - mean_q: 0.688 - mean_eps: 0.790 - ale.lives: 2.075\n",
            "\n",
            "Interval 65 (640000 steps performed)\n",
            "10000/10000 [==============================] - 362s 36ms/step - reward: 0.0524\n",
            "57 episodes - episode_reward: 9.333 [2.000, 23.000] - loss: 0.022 - mae: 0.586 - mean_q: 0.694 - mean_eps: 0.787 - ale.lives: 2.039\n",
            "\n",
            "Interval 66 (650000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0542\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_660000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 382s 38ms/step - reward: 0.0542\n",
            "61 episodes - episode_reward: 8.820 [1.000, 27.000] - loss: 0.021 - mae: 0.596 - mean_q: 0.709 - mean_eps: 0.784 - ale.lives: 2.038\n",
            "\n",
            "Interval 67 (660000 steps performed)\n",
            "10000/10000 [==============================] - 364s 36ms/step - reward: 0.0599\n",
            "55 episodes - episode_reward: 10.891 [3.000, 29.000] - loss: 0.022 - mae: 0.608 - mean_q: 0.722 - mean_eps: 0.781 - ale.lives: 2.040\n",
            "\n",
            "Interval 68 (670000 steps performed)\n",
            "10000/10000 [==============================] - 363s 36ms/step - reward: 0.0557\n",
            "58 episodes - episode_reward: 9.672 [2.000, 25.000] - loss: 0.022 - mae: 0.615 - mean_q: 0.730 - mean_eps: 0.777 - ale.lives: 2.047\n",
            "\n",
            "Interval 69 (680000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0545\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_690000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 383s 38ms/step - reward: 0.0545\n",
            "53 episodes - episode_reward: 10.094 [1.000, 22.000] - loss: 0.022 - mae: 0.631 - mean_q: 0.748 - mean_eps: 0.774 - ale.lives: 1.972\n",
            "\n",
            "Interval 70 (690000 steps performed)\n",
            "10000/10000 [==============================] - 364s 36ms/step - reward: 0.0559\n",
            "60 episodes - episode_reward: 9.433 [1.000, 25.000] - loss: 0.022 - mae: 0.618 - mean_q: 0.733 - mean_eps: 0.771 - ale.lives: 1.984\n",
            "\n",
            "Interval 71 (700000 steps performed)\n",
            "10000/10000 [==============================] - 362s 36ms/step - reward: 0.0509\n",
            "55 episodes - episode_reward: 9.091 [2.000, 21.000] - loss: 0.021 - mae: 0.611 - mean_q: 0.726 - mean_eps: 0.767 - ale.lives: 2.040\n",
            "\n",
            "Interval 72 (710000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0548\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_720000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 383s 38ms/step - reward: 0.0548\n",
            "56 episodes - episode_reward: 9.750 [3.000, 27.000] - loss: 0.021 - mae: 0.611 - mean_q: 0.725 - mean_eps: 0.764 - ale.lives: 1.998\n",
            "\n",
            "Interval 73 (720000 steps performed)\n",
            "10000/10000 [==============================] - 362s 36ms/step - reward: 0.0502\n",
            "55 episodes - episode_reward: 9.309 [1.000, 22.000] - loss: 0.021 - mae: 0.609 - mean_q: 0.722 - mean_eps: 0.761 - ale.lives: 2.011\n",
            "\n",
            "Interval 74 (730000 steps performed)\n",
            "10000/10000 [==============================] - 363s 36ms/step - reward: 0.0558\n",
            "55 episodes - episode_reward: 10.145 [3.000, 27.000] - loss: 0.021 - mae: 0.617 - mean_q: 0.732 - mean_eps: 0.757 - ale.lives: 2.025\n",
            "\n",
            "Interval 75 (740000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0520\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_750000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 383s 38ms/step - reward: 0.0520\n",
            "55 episodes - episode_reward: 9.455 [3.000, 24.000] - loss: 0.021 - mae: 0.620 - mean_q: 0.734 - mean_eps: 0.754 - ale.lives: 2.055\n",
            "\n",
            "Interval 76 (750000 steps performed)\n",
            "10000/10000 [==============================] - 362s 36ms/step - reward: 0.0543\n",
            "57 episodes - episode_reward: 9.491 [1.000, 21.000] - loss: 0.022 - mae: 0.627 - mean_q: 0.744 - mean_eps: 0.751 - ale.lives: 2.076\n",
            "\n",
            "Interval 77 (760000 steps performed)\n",
            "10000/10000 [==============================] - 362s 36ms/step - reward: 0.0582\n",
            "58 episodes - episode_reward: 10.017 [2.000, 23.000] - loss: 0.021 - mae: 0.626 - mean_q: 0.743 - mean_eps: 0.748 - ale.lives: 2.016\n",
            "\n",
            "Interval 78 (770000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0551\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_780000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 384s 38ms/step - reward: 0.0551\n",
            "53 episodes - episode_reward: 10.189 [2.000, 25.000] - loss: 0.022 - mae: 0.612 - mean_q: 0.726 - mean_eps: 0.744 - ale.lives: 2.029\n",
            "\n",
            "Interval 79 (780000 steps performed)\n",
            "10000/10000 [==============================] - 366s 37ms/step - reward: 0.0514\n",
            "59 episodes - episode_reward: 8.949 [2.000, 21.000] - loss: 0.021 - mae: 0.604 - mean_q: 0.716 - mean_eps: 0.741 - ale.lives: 2.018\n",
            "\n",
            "Interval 80 (790000 steps performed)\n",
            "10000/10000 [==============================] - 367s 37ms/step - reward: 0.0591\n",
            "60 episodes - episode_reward: 9.917 [1.000, 30.000] - loss: 0.022 - mae: 0.609 - mean_q: 0.723 - mean_eps: 0.738 - ale.lives: 2.095\n",
            "\n",
            "Interval 81 (800000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0585\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_810000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 396s 40ms/step - reward: 0.0585\n",
            "59 episodes - episode_reward: 9.915 [2.000, 26.000] - loss: 0.022 - mae: 0.616 - mean_q: 0.729 - mean_eps: 0.734 - ale.lives: 2.107\n",
            "\n",
            "Interval 82 (810000 steps performed)\n",
            "10000/10000 [==============================] - 372s 37ms/step - reward: 0.0541\n",
            "56 episodes - episode_reward: 9.232 [3.000, 33.000] - loss: 0.022 - mae: 0.617 - mean_q: 0.731 - mean_eps: 0.731 - ale.lives: 2.072\n",
            "\n",
            "Interval 83 (820000 steps performed)\n",
            "10000/10000 [==============================] - 373s 37ms/step - reward: 0.0608\n",
            "55 episodes - episode_reward: 11.400 [3.000, 30.000] - loss: 0.021 - mae: 0.620 - mean_q: 0.736 - mean_eps: 0.728 - ale.lives: 2.007\n",
            "\n",
            "Interval 84 (830000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0634\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_840000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 396s 40ms/step - reward: 0.0634\n",
            "59 episodes - episode_reward: 10.831 [1.000, 26.000] - loss: 0.022 - mae: 0.616 - mean_q: 0.730 - mean_eps: 0.724 - ale.lives: 2.091\n",
            "\n",
            "Interval 85 (840000 steps performed)\n",
            "10000/10000 [==============================] - 366s 37ms/step - reward: 0.0623\n",
            "52 episodes - episode_reward: 11.962 [2.000, 25.000] - loss: 0.021 - mae: 0.618 - mean_q: 0.733 - mean_eps: 0.721 - ale.lives: 2.042\n",
            "\n",
            "Interval 86 (850000 steps performed)\n",
            "10000/10000 [==============================] - 371s 37ms/step - reward: 0.0603\n",
            "56 episodes - episode_reward: 10.786 [2.000, 23.000] - loss: 0.021 - mae: 0.611 - mean_q: 0.725 - mean_eps: 0.718 - ale.lives: 2.036\n",
            "\n",
            "Interval 87 (860000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0537\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_870000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 397s 40ms/step - reward: 0.0537\n",
            "60 episodes - episode_reward: 8.783 [2.000, 24.000] - loss: 0.021 - mae: 0.605 - mean_q: 0.718 - mean_eps: 0.715 - ale.lives: 2.024\n",
            "\n",
            "Interval 88 (870000 steps performed)\n",
            "10000/10000 [==============================] - 371s 37ms/step - reward: 0.0560\n",
            "56 episodes - episode_reward: 10.179 [2.000, 33.000] - loss: 0.021 - mae: 0.598 - mean_q: 0.708 - mean_eps: 0.711 - ale.lives: 2.022\n",
            "\n",
            "Interval 89 (880000 steps performed)\n",
            "10000/10000 [==============================] - 374s 37ms/step - reward: 0.0628\n",
            "55 episodes - episode_reward: 11.309 [3.000, 25.000] - loss: 0.022 - mae: 0.600 - mean_q: 0.711 - mean_eps: 0.708 - ale.lives: 2.025\n",
            "\n",
            "Interval 90 (890000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0573\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_900000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 396s 40ms/step - reward: 0.0573\n",
            "56 episodes - episode_reward: 10.089 [2.000, 23.000] - loss: 0.021 - mae: 0.604 - mean_q: 0.716 - mean_eps: 0.705 - ale.lives: 2.023\n",
            "\n",
            "Interval 91 (900000 steps performed)\n",
            "10000/10000 [==============================] - 372s 37ms/step - reward: 0.0561\n",
            "59 episodes - episode_reward: 9.593 [1.000, 23.000] - loss: 0.022 - mae: 0.598 - mean_q: 0.709 - mean_eps: 0.701 - ale.lives: 2.035\n",
            "\n",
            "Interval 92 (910000 steps performed)\n",
            "10000/10000 [==============================] - 376s 38ms/step - reward: 0.0575\n",
            "54 episodes - episode_reward: 10.704 [2.000, 32.000] - loss: 0.021 - mae: 0.580 - mean_q: 0.686 - mean_eps: 0.698 - ale.lives: 1.964\n",
            "\n",
            "Interval 93 (920000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0544\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_930000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 400s 40ms/step - reward: 0.0544\n",
            "55 episodes - episode_reward: 9.927 [1.000, 26.000] - loss: 0.022 - mae: 0.579 - mean_q: 0.685 - mean_eps: 0.695 - ale.lives: 2.041\n",
            "\n",
            "Interval 94 (930000 steps performed)\n",
            "10000/10000 [==============================] - 379s 38ms/step - reward: 0.0561\n",
            "55 episodes - episode_reward: 10.273 [4.000, 24.000] - loss: 0.021 - mae: 0.578 - mean_q: 0.685 - mean_eps: 0.691 - ale.lives: 2.042\n",
            "\n",
            "Interval 95 (940000 steps performed)\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0603\n",
            "53 episodes - episode_reward: 11.226 [4.000, 24.000] - loss: 0.022 - mae: 0.566 - mean_q: 0.671 - mean_eps: 0.688 - ale.lives: 2.012\n",
            "\n",
            "Interval 96 (950000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0581\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_960000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 401s 40ms/step - reward: 0.0581\n",
            "56 episodes - episode_reward: 10.482 [1.000, 28.000] - loss: 0.022 - mae: 0.572 - mean_q: 0.679 - mean_eps: 0.685 - ale.lives: 2.007\n",
            "\n",
            "Interval 97 (960000 steps performed)\n",
            "10000/10000 [==============================] - 379s 38ms/step - reward: 0.0514\n",
            "54 episodes - episode_reward: 9.556 [3.000, 20.000] - loss: 0.021 - mae: 0.572 - mean_q: 0.677 - mean_eps: 0.682 - ale.lives: 1.991\n",
            "\n",
            "Interval 98 (970000 steps performed)\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0579\n",
            "52 episodes - episode_reward: 11.038 [3.000, 24.000] - loss: 0.021 - mae: 0.580 - mean_q: 0.687 - mean_eps: 0.678 - ale.lives: 2.019\n",
            "\n",
            "Interval 99 (980000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0617\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_990000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 403s 40ms/step - reward: 0.0617\n",
            "55 episodes - episode_reward: 11.309 [3.000, 24.000] - loss: 0.022 - mae: 0.585 - mean_q: 0.693 - mean_eps: 0.675 - ale.lives: 1.900\n",
            "\n",
            "Interval 100 (990000 steps performed)\n",
            "10000/10000 [==============================] - 377s 38ms/step - reward: 0.0546\n",
            "52 episodes - episode_reward: 10.385 [2.000, 20.000] - loss: 0.022 - mae: 0.589 - mean_q: 0.697 - mean_eps: 0.672 - ale.lives: 2.000\n",
            "\n",
            "Interval 101 (1000000 steps performed)\n",
            "10000/10000 [==============================] - 376s 38ms/step - reward: 0.0579\n",
            "60 episodes - episode_reward: 9.500 [1.000, 28.000] - loss: 0.022 - mae: 0.601 - mean_q: 0.712 - mean_eps: 0.668 - ale.lives: 2.086\n",
            "\n",
            "Interval 102 (1010000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0616\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1020000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 398s 40ms/step - reward: 0.0616\n",
            "53 episodes - episode_reward: 11.830 [2.000, 21.000] - loss: 0.022 - mae: 0.603 - mean_q: 0.714 - mean_eps: 0.665 - ale.lives: 2.095\n",
            "\n",
            "Interval 103 (1020000 steps performed)\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0630\n",
            "54 episodes - episode_reward: 11.630 [3.000, 27.000] - loss: 0.022 - mae: 0.603 - mean_q: 0.715 - mean_eps: 0.662 - ale.lives: 2.035\n",
            "\n",
            "Interval 104 (1030000 steps performed)\n",
            "10000/10000 [==============================] - 379s 38ms/step - reward: 0.0617\n",
            "51 episodes - episode_reward: 12.078 [3.000, 30.000] - loss: 0.022 - mae: 0.620 - mean_q: 0.736 - mean_eps: 0.658 - ale.lives: 2.074\n",
            "\n",
            "Interval 105 (1040000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0551\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1050000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 402s 40ms/step - reward: 0.0551\n",
            "54 episodes - episode_reward: 10.204 [2.000, 30.000] - loss: 0.022 - mae: 0.611 - mean_q: 0.724 - mean_eps: 0.655 - ale.lives: 2.037\n",
            "\n",
            "Interval 106 (1050000 steps performed)\n",
            "10000/10000 [==============================] - 373s 37ms/step - reward: 0.0573\n",
            "53 episodes - episode_reward: 10.868 [3.000, 27.000] - loss: 0.022 - mae: 0.604 - mean_q: 0.715 - mean_eps: 0.652 - ale.lives: 1.991\n",
            "\n",
            "Interval 107 (1060000 steps performed)\n",
            "10000/10000 [==============================] - 375s 38ms/step - reward: 0.0585\n",
            "52 episodes - episode_reward: 11.327 [4.000, 28.000] - loss: 0.022 - mae: 0.596 - mean_q: 0.707 - mean_eps: 0.649 - ale.lives: 1.989\n",
            "\n",
            "Interval 108 (1070000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0586\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1080000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 401s 40ms/step - reward: 0.0586\n",
            "51 episodes - episode_reward: 11.392 [2.000, 31.000] - loss: 0.022 - mae: 0.603 - mean_q: 0.715 - mean_eps: 0.645 - ale.lives: 1.984\n",
            "\n",
            "Interval 109 (1080000 steps performed)\n",
            "10000/10000 [==============================] - 377s 38ms/step - reward: 0.0646\n",
            "52 episodes - episode_reward: 12.250 [2.000, 29.000] - loss: 0.022 - mae: 0.609 - mean_q: 0.722 - mean_eps: 0.642 - ale.lives: 2.041\n",
            "\n",
            "Interval 110 (1090000 steps performed)\n",
            "10000/10000 [==============================] - 379s 38ms/step - reward: 0.0532\n",
            "52 episodes - episode_reward: 10.404 [0.000, 20.000] - loss: 0.023 - mae: 0.609 - mean_q: 0.721 - mean_eps: 0.639 - ale.lives: 2.066\n",
            "\n",
            "Interval 111 (1100000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0538\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1110000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 402s 40ms/step - reward: 0.0539\n",
            "53 episodes - episode_reward: 10.208 [2.000, 26.000] - loss: 0.022 - mae: 0.613 - mean_q: 0.726 - mean_eps: 0.635 - ale.lives: 2.043\n",
            "\n",
            "Interval 112 (1110000 steps performed)\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0627\n",
            "53 episodes - episode_reward: 11.774 [4.000, 26.000] - loss: 0.022 - mae: 0.632 - mean_q: 0.749 - mean_eps: 0.632 - ale.lives: 1.993\n",
            "\n",
            "Interval 113 (1120000 steps performed)\n",
            "10000/10000 [==============================] - 376s 38ms/step - reward: 0.0631\n",
            "53 episodes - episode_reward: 12.019 [2.000, 26.000] - loss: 0.022 - mae: 0.623 - mean_q: 0.739 - mean_eps: 0.629 - ale.lives: 1.990\n",
            "\n",
            "Interval 114 (1130000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0549\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1140000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 402s 40ms/step - reward: 0.0549\n",
            "54 episodes - episode_reward: 10.074 [2.000, 25.000] - loss: 0.022 - mae: 0.610 - mean_q: 0.722 - mean_eps: 0.625 - ale.lives: 2.057\n",
            "\n",
            "Interval 115 (1140000 steps performed)\n",
            "10000/10000 [==============================] - 380s 38ms/step - reward: 0.0638\n",
            "47 episodes - episode_reward: 13.106 [3.000, 27.000] - loss: 0.022 - mae: 0.608 - mean_q: 0.721 - mean_eps: 0.622 - ale.lives: 1.964\n",
            "\n",
            "Interval 116 (1150000 steps performed)\n",
            "10000/10000 [==============================] - 382s 38ms/step - reward: 0.0620\n",
            "55 episodes - episode_reward: 11.618 [2.000, 30.000] - loss: 0.022 - mae: 0.616 - mean_q: 0.730 - mean_eps: 0.619 - ale.lives: 2.042\n",
            "\n",
            "Interval 117 (1160000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0574\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1170000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 407s 41ms/step - reward: 0.0574\n",
            "52 episodes - episode_reward: 11.115 [3.000, 35.000] - loss: 0.023 - mae: 0.623 - mean_q: 0.739 - mean_eps: 0.616 - ale.lives: 1.946\n",
            "\n",
            "Interval 118 (1170000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0584\n",
            "52 episodes - episode_reward: 11.115 [2.000, 23.000] - loss: 0.023 - mae: 0.620 - mean_q: 0.735 - mean_eps: 0.612 - ale.lives: 1.986\n",
            "\n",
            "Interval 119 (1180000 steps performed)\n",
            "10000/10000 [==============================] - 385s 39ms/step - reward: 0.0520\n",
            "60 episodes - episode_reward: 8.833 [0.000, 21.000] - loss: 0.023 - mae: 0.616 - mean_q: 0.731 - mean_eps: 0.609 - ale.lives: 2.044\n",
            "\n",
            "Interval 120 (1190000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0624\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1200000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0624\n",
            "54 episodes - episode_reward: 11.093 [1.000, 27.000] - loss: 0.022 - mae: 0.614 - mean_q: 0.729 - mean_eps: 0.606 - ale.lives: 1.935\n",
            "\n",
            "Interval 121 (1200000 steps performed)\n",
            "10000/10000 [==============================] - 380s 38ms/step - reward: 0.0648\n",
            "55 episodes - episode_reward: 11.927 [1.000, 27.000] - loss: 0.022 - mae: 0.626 - mean_q: 0.742 - mean_eps: 0.602 - ale.lives: 1.960\n",
            "\n",
            "Interval 122 (1210000 steps performed)\n",
            "10000/10000 [==============================] - 385s 38ms/step - reward: 0.0583\n",
            "51 episodes - episode_reward: 11.667 [2.000, 30.000] - loss: 0.022 - mae: 0.618 - mean_q: 0.731 - mean_eps: 0.599 - ale.lives: 2.034\n",
            "\n",
            "Interval 123 (1220000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0606\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1230000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0606\n",
            "53 episodes - episode_reward: 11.283 [1.000, 26.000] - loss: 0.022 - mae: 0.613 - mean_q: 0.726 - mean_eps: 0.596 - ale.lives: 2.084\n",
            "\n",
            "Interval 124 (1230000 steps performed)\n",
            "10000/10000 [==============================] - 378s 38ms/step - reward: 0.0607\n",
            "55 episodes - episode_reward: 11.127 [2.000, 28.000] - loss: 0.023 - mae: 0.611 - mean_q: 0.723 - mean_eps: 0.592 - ale.lives: 1.982\n",
            "\n",
            "Interval 125 (1240000 steps performed)\n",
            "10000/10000 [==============================] - 385s 38ms/step - reward: 0.0548\n",
            "59 episodes - episode_reward: 9.390 [1.000, 27.000] - loss: 0.023 - mae: 0.614 - mean_q: 0.728 - mean_eps: 0.589 - ale.lives: 2.012\n",
            "\n",
            "Interval 126 (1250000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0587\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1260000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0587\n",
            "53 episodes - episode_reward: 10.981 [1.000, 23.000] - loss: 0.023 - mae: 0.629 - mean_q: 0.745 - mean_eps: 0.586 - ale.lives: 2.015\n",
            "\n",
            "Interval 127 (1260000 steps performed)\n",
            "10000/10000 [==============================] - 384s 38ms/step - reward: 0.0630\n",
            "53 episodes - episode_reward: 12.019 [3.000, 24.000] - loss: 0.023 - mae: 0.647 - mean_q: 0.767 - mean_eps: 0.583 - ale.lives: 2.004\n",
            "\n",
            "Interval 128 (1270000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0618\n",
            "55 episodes - episode_reward: 11.218 [3.000, 30.000] - loss: 0.022 - mae: 0.657 - mean_q: 0.779 - mean_eps: 0.579 - ale.lives: 1.951\n",
            "\n",
            "Interval 129 (1280000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0624\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1290000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0624\n",
            "54 episodes - episode_reward: 11.481 [2.000, 23.000] - loss: 0.023 - mae: 0.668 - mean_q: 0.792 - mean_eps: 0.576 - ale.lives: 1.941\n",
            "\n",
            "Interval 130 (1290000 steps performed)\n",
            "10000/10000 [==============================] - 381s 38ms/step - reward: 0.0621\n",
            "52 episodes - episode_reward: 12.038 [2.000, 34.000] - loss: 0.023 - mae: 0.667 - mean_q: 0.790 - mean_eps: 0.573 - ale.lives: 2.003\n",
            "\n",
            "Interval 131 (1300000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0597\n",
            "55 episodes - episode_reward: 10.782 [0.000, 23.000] - loss: 0.023 - mae: 0.657 - mean_q: 0.778 - mean_eps: 0.569 - ale.lives: 1.981\n",
            "\n",
            "Interval 132 (1310000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0633\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1320000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0633\n",
            "54 episodes - episode_reward: 11.537 [3.000, 26.000] - loss: 0.023 - mae: 0.653 - mean_q: 0.774 - mean_eps: 0.566 - ale.lives: 2.035\n",
            "\n",
            "Interval 133 (1320000 steps performed)\n",
            "10000/10000 [==============================] - 387s 39ms/step - reward: 0.0611\n",
            "54 episodes - episode_reward: 11.537 [2.000, 27.000] - loss: 0.023 - mae: 0.649 - mean_q: 0.769 - mean_eps: 0.563 - ale.lives: 2.040\n",
            "\n",
            "Interval 134 (1330000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0566\n",
            "53 episodes - episode_reward: 10.717 [1.000, 28.000] - loss: 0.023 - mae: 0.647 - mean_q: 0.767 - mean_eps: 0.559 - ale.lives: 1.949\n",
            "\n",
            "Interval 135 (1340000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0582\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1350000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0582\n",
            "52 episodes - episode_reward: 11.019 [2.000, 30.000] - loss: 0.023 - mae: 0.641 - mean_q: 0.759 - mean_eps: 0.556 - ale.lives: 2.034\n",
            "\n",
            "Interval 136 (1350000 steps performed)\n",
            "10000/10000 [==============================] - 376s 38ms/step - reward: 0.0635\n",
            "55 episodes - episode_reward: 11.655 [1.000, 26.000] - loss: 0.023 - mae: 0.643 - mean_q: 0.762 - mean_eps: 0.553 - ale.lives: 2.054\n",
            "\n",
            "Interval 137 (1360000 steps performed)\n",
            "10000/10000 [==============================] - 388s 39ms/step - reward: 0.0605\n",
            "56 episodes - episode_reward: 10.643 [2.000, 27.000] - loss: 0.023 - mae: 0.636 - mean_q: 0.754 - mean_eps: 0.550 - ale.lives: 1.993\n",
            "\n",
            "Interval 138 (1370000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0592\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1380000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 415s 41ms/step - reward: 0.0593\n",
            "49 episodes - episode_reward: 12.327 [3.000, 28.000] - loss: 0.024 - mae: 0.646 - mean_q: 0.766 - mean_eps: 0.546 - ale.lives: 2.021\n",
            "\n",
            "Interval 139 (1380000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0594\n",
            "52 episodes - episode_reward: 11.327 [2.000, 24.000] - loss: 0.023 - mae: 0.645 - mean_q: 0.765 - mean_eps: 0.543 - ale.lives: 1.980\n",
            "\n",
            "Interval 140 (1390000 steps performed)\n",
            "10000/10000 [==============================] - 387s 39ms/step - reward: 0.0594\n",
            "52 episodes - episode_reward: 11.327 [1.000, 24.000] - loss: 0.023 - mae: 0.643 - mean_q: 0.763 - mean_eps: 0.540 - ale.lives: 2.064\n",
            "\n",
            "Interval 141 (1400000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0628\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1410000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0628\n",
            "54 episodes - episode_reward: 11.833 [2.000, 25.000] - loss: 0.023 - mae: 0.645 - mean_q: 0.765 - mean_eps: 0.536 - ale.lives: 2.037\n",
            "\n",
            "Interval 142 (1410000 steps performed)\n",
            "10000/10000 [==============================] - 383s 38ms/step - reward: 0.0611\n",
            "53 episodes - episode_reward: 11.189 [0.000, 23.000] - loss: 0.023 - mae: 0.654 - mean_q: 0.777 - mean_eps: 0.533 - ale.lives: 2.014\n",
            "\n",
            "Interval 143 (1420000 steps performed)\n",
            "10000/10000 [==============================] - 388s 39ms/step - reward: 0.0660\n",
            "53 episodes - episode_reward: 12.774 [2.000, 25.000] - loss: 0.023 - mae: 0.650 - mean_q: 0.772 - mean_eps: 0.530 - ale.lives: 1.957\n",
            "\n",
            "Interval 144 (1430000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0661\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1440000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0661\n",
            "55 episodes - episode_reward: 11.982 [3.000, 22.000] - loss: 0.023 - mae: 0.655 - mean_q: 0.776 - mean_eps: 0.526 - ale.lives: 2.047\n",
            "\n",
            "Interval 145 (1440000 steps performed)\n",
            "10000/10000 [==============================] - 390s 39ms/step - reward: 0.0707\n",
            "54 episodes - episode_reward: 13.019 [3.000, 32.000] - loss: 0.023 - mae: 0.656 - mean_q: 0.779 - mean_eps: 0.523 - ale.lives: 1.962\n",
            "\n",
            "Interval 146 (1450000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0619\n",
            "55 episodes - episode_reward: 11.364 [3.000, 23.000] - loss: 0.024 - mae: 0.656 - mean_q: 0.777 - mean_eps: 0.520 - ale.lives: 1.949\n",
            "\n",
            "Interval 147 (1460000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0659\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1470000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0660\n",
            "56 episodes - episode_reward: 11.643 [2.000, 22.000] - loss: 0.024 - mae: 0.679 - mean_q: 0.806 - mean_eps: 0.517 - ale.lives: 1.988\n",
            "\n",
            "Interval 148 (1470000 steps performed)\n",
            "10000/10000 [==============================] - 380s 38ms/step - reward: 0.0636\n",
            "50 episodes - episode_reward: 12.900 [1.000, 24.000] - loss: 0.024 - mae: 0.692 - mean_q: 0.821 - mean_eps: 0.513 - ale.lives: 1.995\n",
            "\n",
            "Interval 149 (1480000 steps performed)\n",
            "10000/10000 [==============================] - 388s 39ms/step - reward: 0.0611\n",
            "57 episodes - episode_reward: 10.509 [3.000, 25.000] - loss: 0.024 - mae: 0.694 - mean_q: 0.824 - mean_eps: 0.510 - ale.lives: 1.945\n",
            "\n",
            "Interval 150 (1490000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0604\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1500000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0604\n",
            "56 episodes - episode_reward: 10.732 [2.000, 21.000] - loss: 0.023 - mae: 0.668 - mean_q: 0.792 - mean_eps: 0.507 - ale.lives: 2.014\n",
            "\n",
            "Interval 151 (1500000 steps performed)\n",
            "10000/10000 [==============================] - 380s 38ms/step - reward: 0.0631\n",
            "49 episodes - episode_reward: 13.020 [2.000, 27.000] - loss: 0.024 - mae: 0.665 - mean_q: 0.789 - mean_eps: 0.503 - ale.lives: 1.962\n",
            "\n",
            "Interval 152 (1510000 steps performed)\n",
            "10000/10000 [==============================] - 385s 39ms/step - reward: 0.0625\n",
            "51 episodes - episode_reward: 12.216 [1.000, 22.000] - loss: 0.023 - mae: 0.675 - mean_q: 0.801 - mean_eps: 0.500 - ale.lives: 1.986\n",
            "\n",
            "Interval 153 (1520000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0640\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1530000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 411s 41ms/step - reward: 0.0641\n",
            "49 episodes - episode_reward: 13.245 [3.000, 28.000] - loss: 0.023 - mae: 0.666 - mean_q: 0.790 - mean_eps: 0.497 - ale.lives: 1.945\n",
            "\n",
            "Interval 154 (1530000 steps performed)\n",
            "10000/10000 [==============================] - 382s 38ms/step - reward: 0.0509\n",
            "51 episodes - episode_reward: 9.941 [1.000, 26.000] - loss: 0.023 - mae: 0.659 - mean_q: 0.781 - mean_eps: 0.493 - ale.lives: 1.902\n",
            "\n",
            "Interval 155 (1540000 steps performed)\n",
            "10000/10000 [==============================] - 387s 39ms/step - reward: 0.0630\n",
            "53 episodes - episode_reward: 11.736 [0.000, 28.000] - loss: 0.023 - mae: 0.652 - mean_q: 0.773 - mean_eps: 0.490 - ale.lives: 2.057\n",
            "\n",
            "Interval 156 (1550000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0611\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1560000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0612\n",
            "53 episodes - episode_reward: 11.585 [1.000, 24.000] - loss: 0.024 - mae: 0.645 - mean_q: 0.764 - mean_eps: 0.487 - ale.lives: 2.017\n",
            "\n",
            "Interval 157 (1560000 steps performed)\n",
            "10000/10000 [==============================] - 372s 37ms/step - reward: 0.0610\n",
            "56 episodes - episode_reward: 11.071 [3.000, 21.000] - loss: 0.024 - mae: 0.636 - mean_q: 0.753 - mean_eps: 0.484 - ale.lives: 1.949\n",
            "\n",
            "Interval 158 (1570000 steps performed)\n",
            "10000/10000 [==============================] - 379s 38ms/step - reward: 0.0556\n",
            "50 episodes - episode_reward: 11.080 [3.000, 25.000] - loss: 0.023 - mae: 0.638 - mean_q: 0.756 - mean_eps: 0.480 - ale.lives: 2.020\n",
            "\n",
            "Interval 159 (1580000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0597\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1590000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0597\n",
            "54 episodes - episode_reward: 11.093 [0.000, 22.000] - loss: 0.024 - mae: 0.626 - mean_q: 0.743 - mean_eps: 0.477 - ale.lives: 1.941\n",
            "\n",
            "Interval 160 (1590000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0585\n",
            "51 episodes - episode_reward: 11.235 [3.000, 26.000] - loss: 0.023 - mae: 0.616 - mean_q: 0.729 - mean_eps: 0.474 - ale.lives: 2.013\n",
            "\n",
            "Interval 161 (1600000 steps performed)\n",
            "10000/10000 [==============================] - 382s 38ms/step - reward: 0.0599\n",
            "54 episodes - episode_reward: 11.315 [2.000, 24.000] - loss: 0.024 - mae: 0.605 - mean_q: 0.716 - mean_eps: 0.470 - ale.lives: 2.007\n",
            "\n",
            "Interval 162 (1610000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0628\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1620000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0628\n",
            "52 episodes - episode_reward: 11.865 [1.000, 30.000] - loss: 0.024 - mae: 0.591 - mean_q: 0.700 - mean_eps: 0.467 - ale.lives: 1.976\n",
            "\n",
            "Interval 163 (1620000 steps performed)\n",
            "10000/10000 [==============================] - 387s 39ms/step - reward: 0.0583\n",
            "51 episodes - episode_reward: 11.392 [3.000, 21.000] - loss: 0.024 - mae: 0.579 - mean_q: 0.685 - mean_eps: 0.464 - ale.lives: 2.018\n",
            "\n",
            "Interval 164 (1630000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0618\n",
            "48 episodes - episode_reward: 12.875 [2.000, 33.000] - loss: 0.024 - mae: 0.591 - mean_q: 0.700 - mean_eps: 0.460 - ale.lives: 1.992\n",
            "\n",
            "Interval 165 (1640000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0646\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1650000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0646\n",
            "53 episodes - episode_reward: 12.226 [1.000, 35.000] - loss: 0.023 - mae: 0.594 - mean_q: 0.704 - mean_eps: 0.457 - ale.lives: 1.943\n",
            "\n",
            "Interval 166 (1650000 steps performed)\n",
            "10000/10000 [==============================] - 387s 39ms/step - reward: 0.0658\n",
            "51 episodes - episode_reward: 12.902 [2.000, 25.000] - loss: 0.023 - mae: 0.589 - mean_q: 0.698 - mean_eps: 0.454 - ale.lives: 1.971\n",
            "\n",
            "Interval 167 (1660000 steps performed)\n",
            "10000/10000 [==============================] - 388s 39ms/step - reward: 0.0590\n",
            "53 episodes - episode_reward: 11.321 [2.000, 25.000] - loss: 0.023 - mae: 0.594 - mean_q: 0.704 - mean_eps: 0.451 - ale.lives: 2.042\n",
            "\n",
            "Interval 168 (1670000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0648\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1680000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0648\n",
            "51 episodes - episode_reward: 12.569 [2.000, 23.000] - loss: 0.024 - mae: 0.610 - mean_q: 0.723 - mean_eps: 0.447 - ale.lives: 1.968\n",
            "\n",
            "Interval 169 (1680000 steps performed)\n",
            "10000/10000 [==============================] - 389s 39ms/step - reward: 0.0636\n",
            "50 episodes - episode_reward: 12.820 [2.000, 31.000] - loss: 0.024 - mae: 0.639 - mean_q: 0.758 - mean_eps: 0.444 - ale.lives: 1.907\n",
            "\n",
            "Interval 170 (1690000 steps performed)\n",
            "10000/10000 [==============================] - 385s 39ms/step - reward: 0.0617\n",
            "52 episodes - episode_reward: 11.769 [3.000, 32.000] - loss: 0.023 - mae: 0.652 - mean_q: 0.774 - mean_eps: 0.441 - ale.lives: 1.968\n",
            "\n",
            "Interval 171 (1700000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0544\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1710000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0544\n",
            "51 episodes - episode_reward: 10.686 [2.000, 24.000] - loss: 0.023 - mae: 0.648 - mean_q: 0.769 - mean_eps: 0.437 - ale.lives: 1.998\n",
            "\n",
            "Interval 172 (1710000 steps performed)\n",
            "10000/10000 [==============================] - 388s 39ms/step - reward: 0.0652\n",
            "55 episodes - episode_reward: 11.982 [3.000, 28.000] - loss: 0.024 - mae: 0.645 - mean_q: 0.767 - mean_eps: 0.434 - ale.lives: 1.965\n",
            "\n",
            "Interval 173 (1720000 steps performed)\n",
            "10000/10000 [==============================] - 389s 39ms/step - reward: 0.0604\n",
            "52 episodes - episode_reward: 11.577 [3.000, 25.000] - loss: 0.024 - mae: 0.643 - mean_q: 0.763 - mean_eps: 0.431 - ale.lives: 2.088\n",
            "\n",
            "Interval 174 (1730000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0648\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1740000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0648\n",
            "51 episodes - episode_reward: 12.608 [2.000, 22.000] - loss: 0.024 - mae: 0.643 - mean_q: 0.763 - mean_eps: 0.427 - ale.lives: 1.978\n",
            "\n",
            "Interval 175 (1740000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0603\n",
            "49 episodes - episode_reward: 12.429 [1.000, 29.000] - loss: 0.024 - mae: 0.635 - mean_q: 0.753 - mean_eps: 0.424 - ale.lives: 2.021\n",
            "\n",
            "Interval 176 (1750000 steps performed)\n",
            "10000/10000 [==============================] - 386s 39ms/step - reward: 0.0567\n",
            "47 episodes - episode_reward: 12.021 [3.000, 20.000] - loss: 0.023 - mae: 0.615 - mean_q: 0.729 - mean_eps: 0.421 - ale.lives: 1.913\n",
            "\n",
            "Interval 177 (1760000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0633\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1770000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0633\n",
            "47 episodes - episode_reward: 13.064 [3.000, 22.000] - loss: 0.024 - mae: 0.601 - mean_q: 0.712 - mean_eps: 0.418 - ale.lives: 2.020\n",
            "\n",
            "Interval 178 (1770000 steps performed)\n",
            "10000/10000 [==============================] - 403s 40ms/step - reward: 0.0622\n",
            "57 episodes - episode_reward: 11.211 [1.000, 28.000] - loss: 0.023 - mae: 0.595 - mean_q: 0.705 - mean_eps: 0.414 - ale.lives: 2.010\n",
            "\n",
            "Interval 179 (1780000 steps performed)\n",
            "10000/10000 [==============================] - 404s 40ms/step - reward: 0.0585\n",
            "54 episodes - episode_reward: 10.870 [2.000, 22.000] - loss: 0.023 - mae: 0.615 - mean_q: 0.729 - mean_eps: 0.411 - ale.lives: 2.009\n",
            "\n",
            "Interval 180 (1790000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0639\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1800000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0639\n",
            "48 episodes - episode_reward: 13.188 [2.000, 26.000] - loss: 0.023 - mae: 0.599 - mean_q: 0.710 - mean_eps: 0.408 - ale.lives: 1.944\n",
            "\n",
            "Interval 181 (1800000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0647\n",
            "49 episodes - episode_reward: 13.286 [2.000, 29.000] - loss: 0.024 - mae: 0.584 - mean_q: 0.693 - mean_eps: 0.404 - ale.lives: 1.928\n",
            "\n",
            "Interval 182 (1810000 steps performed)\n",
            "10000/10000 [==============================] - 417s 42ms/step - reward: 0.0635\n",
            "50 episodes - episode_reward: 12.800 [4.000, 30.000] - loss: 0.023 - mae: 0.577 - mean_q: 0.685 - mean_eps: 0.401 - ale.lives: 1.976\n",
            "\n",
            "Interval 183 (1820000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0649\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1830000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 436s 44ms/step - reward: 0.0649\n",
            "53 episodes - episode_reward: 11.962 [3.000, 23.000] - loss: 0.023 - mae: 0.565 - mean_q: 0.669 - mean_eps: 0.398 - ale.lives: 2.000\n",
            "\n",
            "Interval 184 (1830000 steps performed)\n",
            "10000/10000 [==============================] - 405s 40ms/step - reward: 0.0670\n",
            "47 episodes - episode_reward: 14.319 [4.000, 29.000] - loss: 0.023 - mae: 0.575 - mean_q: 0.681 - mean_eps: 0.394 - ale.lives: 1.939\n",
            "\n",
            "Interval 185 (1840000 steps performed)\n",
            "10000/10000 [==============================] - 402s 40ms/step - reward: 0.0677\n",
            "47 episodes - episode_reward: 14.468 [3.000, 30.000] - loss: 0.024 - mae: 0.578 - mean_q: 0.685 - mean_eps: 0.391 - ale.lives: 1.937\n",
            "\n",
            "Interval 186 (1850000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0657\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1860000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0657\n",
            "51 episodes - episode_reward: 13.039 [3.000, 33.000] - loss: 0.024 - mae: 0.571 - mean_q: 0.676 - mean_eps: 0.388 - ale.lives: 1.966\n",
            "\n",
            "Interval 187 (1860000 steps performed)\n",
            "10000/10000 [==============================] - 401s 40ms/step - reward: 0.0583\n",
            "47 episodes - episode_reward: 12.128 [2.000, 26.000] - loss: 0.024 - mae: 0.576 - mean_q: 0.682 - mean_eps: 0.385 - ale.lives: 1.952\n",
            "\n",
            "Interval 188 (1870000 steps performed)\n",
            "10000/10000 [==============================] - 400s 40ms/step - reward: 0.0609\n",
            "46 episodes - episode_reward: 13.261 [2.000, 25.000] - loss: 0.023 - mae: 0.573 - mean_q: 0.679 - mean_eps: 0.381 - ale.lives: 1.989\n",
            "\n",
            "Interval 189 (1880000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0629\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1890000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 429s 43ms/step - reward: 0.0630\n",
            "49 episodes - episode_reward: 12.816 [0.000, 29.000] - loss: 0.023 - mae: 0.561 - mean_q: 0.665 - mean_eps: 0.378 - ale.lives: 1.929\n",
            "\n",
            "Interval 190 (1890000 steps performed)\n",
            "10000/10000 [==============================] - 404s 40ms/step - reward: 0.0694\n",
            "50 episodes - episode_reward: 14.180 [5.000, 26.000] - loss: 0.024 - mae: 0.550 - mean_q: 0.651 - mean_eps: 0.375 - ale.lives: 2.029\n",
            "\n",
            "Interval 191 (1900000 steps performed)\n",
            "10000/10000 [==============================] - 402s 40ms/step - reward: 0.0610\n",
            "48 episodes - episode_reward: 12.458 [1.000, 34.000] - loss: 0.024 - mae: 0.539 - mean_q: 0.638 - mean_eps: 0.371 - ale.lives: 1.982\n",
            "\n",
            "Interval 192 (1910000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0612\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1920000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0612\n",
            "55 episodes - episode_reward: 11.345 [2.000, 28.000] - loss: 0.023 - mae: 0.537 - mean_q: 0.636 - mean_eps: 0.368 - ale.lives: 1.961\n",
            "\n",
            "Interval 193 (1920000 steps performed)\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0590\n",
            "52 episodes - episode_reward: 11.308 [1.000, 24.000] - loss: 0.024 - mae: 0.525 - mean_q: 0.622 - mean_eps: 0.365 - ale.lives: 2.002\n",
            "\n",
            "Interval 194 (1930000 steps performed)\n",
            "10000/10000 [==============================] - 405s 41ms/step - reward: 0.0607\n",
            "45 episodes - episode_reward: 13.311 [3.000, 23.000] - loss: 0.024 - mae: 0.516 - mean_q: 0.612 - mean_eps: 0.361 - ale.lives: 1.950\n",
            "\n",
            "Interval 195 (1940000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0637\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1950000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 435s 43ms/step - reward: 0.0637\n",
            "46 episodes - episode_reward: 13.913 [3.000, 29.000] - loss: 0.024 - mae: 0.512 - mean_q: 0.606 - mean_eps: 0.358 - ale.lives: 1.907\n",
            "\n",
            "Interval 196 (1950000 steps performed)\n",
            "10000/10000 [==============================] - 408s 41ms/step - reward: 0.0666\n",
            "44 episodes - episode_reward: 14.909 [5.000, 24.000] - loss: 0.024 - mae: 0.513 - mean_q: 0.608 - mean_eps: 0.355 - ale.lives: 2.043\n",
            "\n",
            "Interval 197 (1960000 steps performed)\n",
            "10000/10000 [==============================] - 404s 40ms/step - reward: 0.0688\n",
            "44 episodes - episode_reward: 15.591 [5.000, 24.000] - loss: 0.024 - mae: 0.493 - mean_q: 0.584 - mean_eps: 0.352 - ale.lives: 1.953\n",
            "\n",
            "Interval 198 (1970000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0607\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_1980000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 434s 43ms/step - reward: 0.0607\n",
            "53 episodes - episode_reward: 11.698 [2.000, 22.000] - loss: 0.023 - mae: 0.493 - mean_q: 0.583 - mean_eps: 0.348 - ale.lives: 2.025\n",
            "\n",
            "Interval 199 (1980000 steps performed)\n",
            "10000/10000 [==============================] - 407s 41ms/step - reward: 0.0668\n",
            "49 episodes - episode_reward: 13.490 [1.000, 24.000] - loss: 0.024 - mae: 0.479 - mean_q: 0.566 - mean_eps: 0.345 - ale.lives: 1.996\n",
            "\n",
            "Interval 200 (1990000 steps performed)\n",
            "10000/10000 [==============================] - 406s 41ms/step - reward: 0.0721\n",
            "45 episodes - episode_reward: 16.089 [3.000, 31.000] - loss: 0.024 - mae: 0.483 - mean_q: 0.571 - mean_eps: 0.342 - ale.lives: 1.917\n",
            "\n",
            "Interval 201 (2000000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0672\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2010000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 435s 43ms/step - reward: 0.0673\n",
            "53 episodes - episode_reward: 12.868 [3.000, 23.000] - loss: 0.023 - mae: 0.495 - mean_q: 0.587 - mean_eps: 0.338 - ale.lives: 1.987\n",
            "\n",
            "Interval 202 (2010000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0650\n",
            "51 episodes - episode_reward: 12.725 [2.000, 25.000] - loss: 0.024 - mae: 0.488 - mean_q: 0.577 - mean_eps: 0.335 - ale.lives: 2.010\n",
            "\n",
            "Interval 203 (2020000 steps performed)\n",
            "10000/10000 [==============================] - 408s 41ms/step - reward: 0.0647\n",
            "49 episodes - episode_reward: 13.204 [3.000, 22.000] - loss: 0.023 - mae: 0.459 - mean_q: 0.543 - mean_eps: 0.332 - ale.lives: 1.939\n",
            "\n",
            "Interval 204 (2030000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0617\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2040000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 436s 44ms/step - reward: 0.0617\n",
            "50 episodes - episode_reward: 12.360 [1.000, 26.000] - loss: 0.024 - mae: 0.444 - mean_q: 0.525 - mean_eps: 0.328 - ale.lives: 1.965\n",
            "\n",
            "Interval 205 (2040000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0594\n",
            "50 episodes - episode_reward: 11.720 [1.000, 27.000] - loss: 0.024 - mae: 0.430 - mean_q: 0.507 - mean_eps: 0.325 - ale.lives: 1.966\n",
            "\n",
            "Interval 206 (2050000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0565\n",
            "51 episodes - episode_reward: 11.235 [1.000, 30.000] - loss: 0.023 - mae: 0.430 - mean_q: 0.508 - mean_eps: 0.322 - ale.lives: 1.985\n",
            "\n",
            "Interval 207 (2060000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0709\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2070000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 436s 44ms/step - reward: 0.0709\n",
            "50 episodes - episode_reward: 14.000 [3.000, 26.000] - loss: 0.024 - mae: 0.446 - mean_q: 0.527 - mean_eps: 0.319 - ale.lives: 2.002\n",
            "\n",
            "Interval 208 (2070000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0593\n",
            "48 episodes - episode_reward: 12.208 [2.000, 26.000] - loss: 0.024 - mae: 0.459 - mean_q: 0.542 - mean_eps: 0.315 - ale.lives: 2.022\n",
            "\n",
            "Interval 209 (2080000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0579\n",
            "46 episodes - episode_reward: 12.804 [1.000, 25.000] - loss: 0.024 - mae: 0.449 - mean_q: 0.531 - mean_eps: 0.312 - ale.lives: 1.920\n",
            "\n",
            "Interval 210 (2090000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0618\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2100000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 439s 44ms/step - reward: 0.0618\n",
            "52 episodes - episode_reward: 11.827 [3.000, 28.000] - loss: 0.023 - mae: 0.447 - mean_q: 0.529 - mean_eps: 0.309 - ale.lives: 1.931\n",
            "\n",
            "Interval 211 (2100000 steps performed)\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0654\n",
            "45 episodes - episode_reward: 14.178 [5.000, 26.000] - loss: 0.024 - mae: 0.452 - mean_q: 0.535 - mean_eps: 0.305 - ale.lives: 1.961\n",
            "\n",
            "Interval 212 (2110000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0658\n",
            "50 episodes - episode_reward: 13.680 [0.000, 33.000] - loss: 0.024 - mae: 0.438 - mean_q: 0.517 - mean_eps: 0.302 - ale.lives: 1.952\n",
            "\n",
            "Interval 213 (2120000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0653\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2130000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 439s 44ms/step - reward: 0.0654\n",
            "42 episodes - episode_reward: 15.429 [3.000, 29.000] - loss: 0.024 - mae: 0.426 - mean_q: 0.505 - mean_eps: 0.299 - ale.lives: 1.929\n",
            "\n",
            "Interval 214 (2130000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0626\n",
            "46 episodes - episode_reward: 13.457 [4.000, 25.000] - loss: 0.024 - mae: 0.411 - mean_q: 0.485 - mean_eps: 0.295 - ale.lives: 1.874\n",
            "\n",
            "Interval 215 (2140000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0690\n",
            "49 episodes - episode_reward: 14.204 [1.000, 22.000] - loss: 0.023 - mae: 0.409 - mean_q: 0.482 - mean_eps: 0.292 - ale.lives: 1.961\n",
            "\n",
            "Interval 216 (2150000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0661\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2160000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 437s 44ms/step - reward: 0.0661\n",
            "51 episodes - episode_reward: 12.922 [5.000, 23.000] - loss: 0.023 - mae: 0.397 - mean_q: 0.468 - mean_eps: 0.289 - ale.lives: 1.997\n",
            "\n",
            "Interval 217 (2160000 steps performed)\n",
            "10000/10000 [==============================] - 408s 41ms/step - reward: 0.0708\n",
            "46 episodes - episode_reward: 15.283 [2.000, 30.000] - loss: 0.024 - mae: 0.402 - mean_q: 0.475 - mean_eps: 0.286 - ale.lives: 1.931\n",
            "\n",
            "Interval 218 (2170000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0648\n",
            "48 episodes - episode_reward: 13.333 [3.000, 27.000] - loss: 0.024 - mae: 0.399 - mean_q: 0.471 - mean_eps: 0.282 - ale.lives: 2.010\n",
            "\n",
            "Interval 219 (2180000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0653\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2190000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 437s 44ms/step - reward: 0.0654\n",
            "51 episodes - episode_reward: 13.098 [5.000, 22.000] - loss: 0.024 - mae: 0.407 - mean_q: 0.481 - mean_eps: 0.279 - ale.lives: 2.029\n",
            "\n",
            "Interval 220 (2190000 steps performed)\n",
            "10000/10000 [==============================] - 411s 41ms/step - reward: 0.0668\n",
            "51 episodes - episode_reward: 13.098 [3.000, 27.000] - loss: 0.023 - mae: 0.413 - mean_q: 0.488 - mean_eps: 0.276 - ale.lives: 2.005\n",
            "\n",
            "Interval 221 (2200000 steps performed)\n",
            "10000/10000 [==============================] - 409s 41ms/step - reward: 0.0727\n",
            "48 episodes - episode_reward: 15.167 [3.000, 29.000] - loss: 0.024 - mae: 0.423 - mean_q: 0.500 - mean_eps: 0.272 - ale.lives: 2.021\n",
            "\n",
            "Interval 222 (2210000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0683\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2220000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 435s 44ms/step - reward: 0.0683\n",
            "45 episodes - episode_reward: 15.178 [6.000, 25.000] - loss: 0.024 - mae: 0.414 - mean_q: 0.490 - mean_eps: 0.269 - ale.lives: 2.050\n",
            "\n",
            "Interval 223 (2220000 steps performed)\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0693\n",
            "48 episodes - episode_reward: 14.417 [3.000, 27.000] - loss: 0.023 - mae: 0.399 - mean_q: 0.471 - mean_eps: 0.266 - ale.lives: 2.055\n",
            "\n",
            "Interval 224 (2230000 steps performed)\n",
            "10000/10000 [==============================] - 408s 41ms/step - reward: 0.0701\n",
            "46 episodes - episode_reward: 15.283 [2.000, 33.000] - loss: 0.023 - mae: 0.400 - mean_q: 0.472 - mean_eps: 0.262 - ale.lives: 1.922\n",
            "\n",
            "Interval 225 (2240000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0702\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2250000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 438s 44ms/step - reward: 0.0702\n",
            "47 episodes - episode_reward: 15.043 [4.000, 31.000] - loss: 0.024 - mae: 0.414 - mean_q: 0.489 - mean_eps: 0.259 - ale.lives: 1.952\n",
            "\n",
            "Interval 226 (2250000 steps performed)\n",
            "10000/10000 [==============================] - 415s 41ms/step - reward: 0.0692\n",
            "51 episodes - episode_reward: 13.549 [3.000, 31.000] - loss: 0.024 - mae: 0.437 - mean_q: 0.518 - mean_eps: 0.256 - ale.lives: 1.984\n",
            "\n",
            "Interval 227 (2260000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0680\n",
            "47 episodes - episode_reward: 14.043 [4.000, 35.000] - loss: 0.024 - mae: 0.443 - mean_q: 0.524 - mean_eps: 0.253 - ale.lives: 1.992\n",
            "\n",
            "Interval 228 (2270000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0717\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2280000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 441s 44ms/step - reward: 0.0717\n",
            "50 episodes - episode_reward: 14.760 [6.000, 24.000] - loss: 0.025 - mae: 0.446 - mean_q: 0.527 - mean_eps: 0.249 - ale.lives: 2.006\n",
            "\n",
            "Interval 229 (2280000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0733\n",
            "50 episodes - episode_reward: 14.540 [4.000, 29.000] - loss: 0.024 - mae: 0.438 - mean_q: 0.517 - mean_eps: 0.246 - ale.lives: 2.008\n",
            "\n",
            "Interval 230 (2290000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0739\n",
            "44 episodes - episode_reward: 16.955 [6.000, 33.000] - loss: 0.025 - mae: 0.430 - mean_q: 0.508 - mean_eps: 0.243 - ale.lives: 2.040\n",
            "\n",
            "Interval 231 (2300000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0708\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2310000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 440s 44ms/step - reward: 0.0709\n",
            "45 episodes - episode_reward: 15.711 [5.000, 30.000] - loss: 0.025 - mae: 0.421 - mean_q: 0.499 - mean_eps: 0.239 - ale.lives: 1.970\n",
            "\n",
            "Interval 232 (2310000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0749\n",
            "46 episodes - episode_reward: 16.326 [3.000, 28.000] - loss: 0.025 - mae: 0.436 - mean_q: 0.517 - mean_eps: 0.236 - ale.lives: 1.988\n",
            "\n",
            "Interval 233 (2320000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0733\n",
            "44 episodes - episode_reward: 16.318 [3.000, 27.000] - loss: 0.025 - mae: 0.449 - mean_q: 0.532 - mean_eps: 0.233 - ale.lives: 1.971\n",
            "\n",
            "Interval 234 (2330000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0758\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2340000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 439s 44ms/step - reward: 0.0758\n",
            "49 episodes - episode_reward: 15.429 [3.000, 26.000] - loss: 0.025 - mae: 0.450 - mean_q: 0.533 - mean_eps: 0.229 - ale.lives: 1.945\n",
            "\n",
            "Interval 235 (2340000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0797\n",
            "50 episodes - episode_reward: 16.040 [5.000, 32.000] - loss: 0.025 - mae: 0.435 - mean_q: 0.515 - mean_eps: 0.226 - ale.lives: 1.960\n",
            "\n",
            "Interval 236 (2350000 steps performed)\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0801\n",
            "43 episodes - episode_reward: 18.442 [7.000, 33.000] - loss: 0.025 - mae: 0.421 - mean_q: 0.498 - mean_eps: 0.223 - ale.lives: 1.981\n",
            "\n",
            "Interval 237 (2360000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0813\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2370000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 437s 44ms/step - reward: 0.0813\n",
            "49 episodes - episode_reward: 16.776 [7.000, 27.000] - loss: 0.026 - mae: 0.410 - mean_q: 0.485 - mean_eps: 0.220 - ale.lives: 2.005\n",
            "\n",
            "Interval 238 (2370000 steps performed)\n",
            "10000/10000 [==============================] - 399s 40ms/step - reward: 0.0830\n",
            "51 episodes - episode_reward: 16.451 [5.000, 47.000] - loss: 0.025 - mae: 0.399 - mean_q: 0.473 - mean_eps: 0.216 - ale.lives: 1.986\n",
            "\n",
            "Interval 239 (2380000 steps performed)\n",
            "10000/10000 [==============================] - 392s 39ms/step - reward: 0.0776\n",
            "47 episodes - episode_reward: 16.319 [4.000, 33.000] - loss: 0.026 - mae: 0.385 - mean_q: 0.454 - mean_eps: 0.213 - ale.lives: 1.972\n",
            "\n",
            "Interval 240 (2390000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0781\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2400000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0781\n",
            "46 episodes - episode_reward: 16.957 [4.000, 30.000] - loss: 0.025 - mae: 0.391 - mean_q: 0.464 - mean_eps: 0.210 - ale.lives: 1.946\n",
            "\n",
            "Interval 241 (2400000 steps performed)\n",
            "10000/10000 [==============================] - 391s 39ms/step - reward: 0.0810\n",
            "48 episodes - episode_reward: 16.979 [6.000, 27.000] - loss: 0.026 - mae: 0.405 - mean_q: 0.479 - mean_eps: 0.206 - ale.lives: 1.937\n",
            "\n",
            "Interval 242 (2410000 steps performed)\n",
            "10000/10000 [==============================] - 392s 39ms/step - reward: 0.0732\n",
            "51 episodes - episode_reward: 14.353 [4.000, 29.000] - loss: 0.026 - mae: 0.416 - mean_q: 0.492 - mean_eps: 0.203 - ale.lives: 1.982\n",
            "\n",
            "Interval 243 (2420000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0786\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2430000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0786\n",
            "47 episodes - episode_reward: 16.809 [2.000, 29.000] - loss: 0.026 - mae: 0.417 - mean_q: 0.493 - mean_eps: 0.200 - ale.lives: 2.010\n",
            "\n",
            "Interval 244 (2430000 steps performed)\n",
            "10000/10000 [==============================] - 389s 39ms/step - reward: 0.0750\n",
            "49 episodes - episode_reward: 15.245 [3.000, 31.000] - loss: 0.026 - mae: 0.432 - mean_q: 0.512 - mean_eps: 0.196 - ale.lives: 1.997\n",
            "\n",
            "Interval 245 (2440000 steps performed)\n",
            "10000/10000 [==============================] - 389s 39ms/step - reward: 0.0869\n",
            "46 episodes - episode_reward: 18.674 [10.000, 36.000] - loss: 0.027 - mae: 0.438 - mean_q: 0.522 - mean_eps: 0.193 - ale.lives: 1.952\n",
            "\n",
            "Interval 246 (2450000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0819\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2460000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 419s 42ms/step - reward: 0.0820\n",
            "50 episodes - episode_reward: 16.540 [5.000, 32.000] - loss: 0.026 - mae: 0.410 - mean_q: 0.486 - mean_eps: 0.190 - ale.lives: 2.058\n",
            "\n",
            "Interval 247 (2460000 steps performed)\n",
            "10000/10000 [==============================] - 432s 43ms/step - reward: 0.0800\n",
            "50 episodes - episode_reward: 16.180 [1.000, 32.000] - loss: 0.027 - mae: 0.396 - mean_q: 0.469 - mean_eps: 0.187 - ale.lives: 2.036\n",
            "\n",
            "Interval 248 (2470000 steps performed)\n",
            "10000/10000 [==============================] - 410s 41ms/step - reward: 0.0848\n",
            "45 episodes - episode_reward: 18.267 [9.000, 33.000] - loss: 0.027 - mae: 0.390 - mean_q: 0.461 - mean_eps: 0.183 - ale.lives: 1.898\n",
            "\n",
            "Interval 249 (2480000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0846\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2490000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 446s 45ms/step - reward: 0.0846\n",
            "47 episodes - episode_reward: 18.340 [8.000, 30.000] - loss: 0.027 - mae: 0.389 - mean_q: 0.460 - mean_eps: 0.180 - ale.lives: 2.002\n",
            "\n",
            "Interval 250 (2490000 steps performed)\n",
            "10000/10000 [==============================] - 421s 42ms/step - reward: 0.0828\n",
            "49 episodes - episode_reward: 17.102 [7.000, 33.000] - loss: 0.026 - mae: 0.385 - mean_q: 0.456 - mean_eps: 0.177 - ale.lives: 1.947\n",
            "\n",
            "Interval 251 (2500000 steps performed)\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0813\n",
            "45 episodes - episode_reward: 17.800 [1.000, 30.000] - loss: 0.027 - mae: 0.395 - mean_q: 0.469 - mean_eps: 0.173 - ale.lives: 2.000\n",
            "\n",
            "Interval 252 (2510000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0849\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2520000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 444s 44ms/step - reward: 0.0849\n",
            "47 episodes - episode_reward: 18.234 [4.000, 34.000] - loss: 0.027 - mae: 0.397 - mean_q: 0.472 - mean_eps: 0.170 - ale.lives: 2.012\n",
            "\n",
            "Interval 253 (2520000 steps performed)\n",
            "10000/10000 [==============================] - 415s 42ms/step - reward: 0.0877\n",
            "48 episodes - episode_reward: 17.875 [4.000, 28.000] - loss: 0.026 - mae: 0.401 - mean_q: 0.477 - mean_eps: 0.167 - ale.lives: 1.974\n",
            "\n",
            "Interval 254 (2530000 steps performed)\n",
            "10000/10000 [==============================] - 414s 41ms/step - reward: 0.0790\n",
            "49 episodes - episode_reward: 16.490 [7.000, 32.000] - loss: 0.027 - mae: 0.392 - mean_q: 0.465 - mean_eps: 0.163 - ale.lives: 2.029\n",
            "\n",
            "Interval 255 (2540000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0837\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2550000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 443s 44ms/step - reward: 0.0838\n",
            "48 episodes - episode_reward: 17.229 [7.000, 27.000] - loss: 0.027 - mae: 0.390 - mean_q: 0.463 - mean_eps: 0.160 - ale.lives: 1.914\n",
            "\n",
            "Interval 256 (2550000 steps performed)\n",
            "10000/10000 [==============================] - 418s 42ms/step - reward: 0.0783\n",
            "48 episodes - episode_reward: 16.375 [4.000, 31.000] - loss: 0.028 - mae: 0.401 - mean_q: 0.474 - mean_eps: 0.157 - ale.lives: 2.057\n",
            "\n",
            "Interval 257 (2560000 steps performed)\n",
            "10000/10000 [==============================] - 420s 42ms/step - reward: 0.0836\n",
            "48 episodes - episode_reward: 17.583 [8.000, 31.000] - loss: 0.027 - mae: 0.418 - mean_q: 0.497 - mean_eps: 0.154 - ale.lives: 1.963\n",
            "\n",
            "Interval 258 (2570000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0850\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2580000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 450s 45ms/step - reward: 0.0850\n",
            "50 episodes - episode_reward: 16.800 [5.000, 30.000] - loss: 0.028 - mae: 0.425 - mean_q: 0.505 - mean_eps: 0.150 - ale.lives: 1.956\n",
            "\n",
            "Interval 259 (2580000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0857\n",
            "50 episodes - episode_reward: 16.960 [0.000, 28.000] - loss: 0.028 - mae: 0.428 - mean_q: 0.509 - mean_eps: 0.147 - ale.lives: 1.970\n",
            "\n",
            "Interval 260 (2590000 steps performed)\n",
            "10000/10000 [==============================] - 421s 42ms/step - reward: 0.0849\n",
            "49 episodes - episode_reward: 17.551 [7.000, 31.000] - loss: 0.028 - mae: 0.434 - mean_q: 0.515 - mean_eps: 0.144 - ale.lives: 2.025\n",
            "\n",
            "Interval 261 (2600000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0838\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2610000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 451s 45ms/step - reward: 0.0838\n",
            "47 episodes - episode_reward: 18.106 [9.000, 35.000] - loss: 0.029 - mae: 0.436 - mean_q: 0.518 - mean_eps: 0.140 - ale.lives: 1.979\n",
            "\n",
            "Interval 262 (2610000 steps performed)\n",
            "10000/10000 [==============================] - 437s 44ms/step - reward: 0.0858\n",
            "46 episodes - episode_reward: 18.283 [5.000, 27.000] - loss: 0.029 - mae: 0.442 - mean_q: 0.525 - mean_eps: 0.137 - ale.lives: 1.908\n",
            "\n",
            "Interval 263 (2620000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0849\n",
            "52 episodes - episode_reward: 16.385 [3.000, 27.000] - loss: 0.030 - mae: 0.450 - mean_q: 0.535 - mean_eps: 0.134 - ale.lives: 2.074\n",
            "\n",
            "Interval 264 (2630000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0939\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2640000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 459s 46ms/step - reward: 0.0939\n",
            "50 episodes - episode_reward: 18.980 [7.000, 34.000] - loss: 0.029 - mae: 0.457 - mean_q: 0.547 - mean_eps: 0.130 - ale.lives: 2.036\n",
            "\n",
            "Interval 265 (2640000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0908\n",
            "46 episodes - episode_reward: 19.565 [12.000, 29.000] - loss: 0.029 - mae: 0.495 - mean_q: 0.592 - mean_eps: 0.127 - ale.lives: 1.948\n",
            "\n",
            "Interval 266 (2650000 steps performed)\n",
            "10000/10000 [==============================] - 424s 42ms/step - reward: 0.0933\n",
            "47 episodes - episode_reward: 20.043 [6.000, 40.000] - loss: 0.029 - mae: 0.527 - mean_q: 0.630 - mean_eps: 0.124 - ale.lives: 1.953\n",
            "\n",
            "Interval 267 (2660000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0905\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2670000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 454s 45ms/step - reward: 0.0905\n",
            "47 episodes - episode_reward: 19.213 [10.000, 37.000] - loss: 0.030 - mae: 0.545 - mean_q: 0.653 - mean_eps: 0.121 - ale.lives: 1.970\n",
            "\n",
            "Interval 268 (2670000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0799\n",
            "41 episodes - episode_reward: 19.610 [8.000, 31.000] - loss: 0.031 - mae: 0.554 - mean_q: 0.665 - mean_eps: 0.117 - ale.lives: 2.072\n",
            "\n",
            "Interval 269 (2680000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0811\n",
            "49 episodes - episode_reward: 16.286 [2.000, 30.000] - loss: 0.031 - mae: 0.582 - mean_q: 0.699 - mean_eps: 0.114 - ale.lives: 2.057\n",
            "\n",
            "Interval 270 (2690000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0908\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2700000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 463s 46ms/step - reward: 0.0908\n",
            "47 episodes - episode_reward: 19.298 [4.000, 33.000] - loss: 0.032 - mae: 0.597 - mean_q: 0.717 - mean_eps: 0.111 - ale.lives: 2.022\n",
            "\n",
            "Interval 271 (2700000 steps performed)\n",
            "10000/10000 [==============================] - 429s 43ms/step - reward: 0.0873\n",
            "44 episodes - episode_reward: 20.045 [6.000, 33.000] - loss: 0.032 - mae: 0.615 - mean_q: 0.742 - mean_eps: 0.107 - ale.lives: 1.953\n",
            "\n",
            "Interval 272 (2710000 steps performed)\n",
            "10000/10000 [==============================] - 422s 42ms/step - reward: 0.0848\n",
            "41 episodes - episode_reward: 20.268 [8.000, 35.000] - loss: 0.032 - mae: 0.633 - mean_q: 0.763 - mean_eps: 0.104 - ale.lives: 2.067\n",
            "\n",
            "Interval 273 (2720000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0864\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2730000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 450s 45ms/step - reward: 0.0865\n",
            "43 episodes - episode_reward: 20.279 [5.000, 35.000] - loss: 0.032 - mae: 0.663 - mean_q: 0.799 - mean_eps: 0.101 - ale.lives: 2.151\n",
            "\n",
            "Interval 274 (2730000 steps performed)\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0831\n",
            "50 episodes - episode_reward: 16.660 [2.000, 34.000] - loss: 0.033 - mae: 0.687 - mean_q: 0.828 - mean_eps: 0.097 - ale.lives: 2.047\n",
            "\n",
            "Interval 275 (2740000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0855\n",
            "53 episodes - episode_reward: 16.358 [5.000, 33.000] - loss: 0.033 - mae: 0.709 - mean_q: 0.855 - mean_eps: 0.094 - ale.lives: 2.045\n",
            "\n",
            "Interval 276 (2750000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0865\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2760000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 459s 46ms/step - reward: 0.0866\n",
            "50 episodes - episode_reward: 17.020 [6.000, 32.000] - loss: 0.033 - mae: 0.705 - mean_q: 0.851 - mean_eps: 0.091 - ale.lives: 2.027\n",
            "\n",
            "Interval 277 (2760000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0818\n",
            "52 episodes - episode_reward: 15.865 [4.000, 29.000] - loss: 0.035 - mae: 0.701 - mean_q: 0.844 - mean_eps: 0.088 - ale.lives: 1.939\n",
            "\n",
            "Interval 278 (2770000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0918\n",
            "47 episodes - episode_reward: 19.128 [6.000, 37.000] - loss: 0.035 - mae: 0.722 - mean_q: 0.873 - mean_eps: 0.084 - ale.lives: 2.000\n",
            "\n",
            "Interval 279 (2780000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0895\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2790000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 453s 45ms/step - reward: 0.0895\n",
            "48 episodes - episode_reward: 18.938 [6.000, 36.000] - loss: 0.037 - mae: 0.737 - mean_q: 0.892 - mean_eps: 0.081 - ale.lives: 1.929\n",
            "\n",
            "Interval 280 (2790000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0918\n",
            "52 episodes - episode_reward: 17.558 [5.000, 33.000] - loss: 0.037 - mae: 0.753 - mean_q: 0.908 - mean_eps: 0.078 - ale.lives: 2.003\n",
            "\n",
            "Interval 281 (2800000 steps performed)\n",
            "10000/10000 [==============================] - 418s 42ms/step - reward: 0.0915\n",
            "45 episodes - episode_reward: 20.311 [6.000, 33.000] - loss: 0.037 - mae: 0.785 - mean_q: 0.947 - mean_eps: 0.074 - ale.lives: 1.911\n",
            "\n",
            "Interval 282 (2810000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0895\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2820000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 448s 45ms/step - reward: 0.0895\n",
            "49 episodes - episode_reward: 18.673 [5.000, 35.000] - loss: 0.037 - mae: 0.793 - mean_q: 0.956 - mean_eps: 0.071 - ale.lives: 2.026\n",
            "\n",
            "Interval 283 (2820000 steps performed)\n",
            "10000/10000 [==============================] - 425s 42ms/step - reward: 0.0831\n",
            "47 episodes - episode_reward: 17.468 [4.000, 41.000] - loss: 0.037 - mae: 0.790 - mean_q: 0.952 - mean_eps: 0.068 - ale.lives: 1.950\n",
            "\n",
            "Interval 284 (2830000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0710\n",
            "51 episodes - episode_reward: 14.059 [5.000, 27.000] - loss: 0.037 - mae: 0.841 - mean_q: 1.012 - mean_eps: 0.064 - ale.lives: 2.010\n",
            "\n",
            "Interval 285 (2840000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0827\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2850000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 452s 45ms/step - reward: 0.0828\n",
            "52 episodes - episode_reward: 15.769 [4.000, 30.000] - loss: 0.038 - mae: 0.879 - mean_q: 1.055 - mean_eps: 0.061 - ale.lives: 1.952\n",
            "\n",
            "Interval 286 (2850000 steps performed)\n",
            "10000/10000 [==============================] - 425s 42ms/step - reward: 0.0782\n",
            "53 episodes - episode_reward: 14.453 [5.000, 31.000] - loss: 0.036 - mae: 0.900 - mean_q: 1.081 - mean_eps: 0.058 - ale.lives: 2.023\n",
            "\n",
            "Interval 287 (2860000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0764\n",
            "52 episodes - episode_reward: 15.038 [3.000, 33.000] - loss: 0.036 - mae: 0.895 - mean_q: 1.076 - mean_eps: 0.055 - ale.lives: 2.003\n",
            "\n",
            "Interval 288 (2870000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0825\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2880000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 451s 45ms/step - reward: 0.0825\n",
            "45 episodes - episode_reward: 18.400 [6.000, 33.000] - loss: 0.037 - mae: 0.919 - mean_q: 1.106 - mean_eps: 0.051 - ale.lives: 2.048\n",
            "\n",
            "Interval 289 (2880000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0730\n",
            "45 episodes - episode_reward: 16.333 [9.000, 36.000] - loss: 0.037 - mae: 0.943 - mean_q: 1.133 - mean_eps: 0.048 - ale.lives: 1.992\n",
            "\n",
            "Interval 290 (2890000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0812\n",
            "47 episodes - episode_reward: 17.298 [6.000, 35.000] - loss: 0.037 - mae: 0.958 - mean_q: 1.154 - mean_eps: 0.045 - ale.lives: 2.009\n",
            "\n",
            "Interval 291 (2900000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0826\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2910000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 454s 45ms/step - reward: 0.0826\n",
            "47 episodes - episode_reward: 17.489 [6.000, 34.000] - loss: 0.038 - mae: 0.977 - mean_q: 1.174 - mean_eps: 0.041 - ale.lives: 1.996\n",
            "\n",
            "Interval 292 (2910000 steps performed)\n",
            "10000/10000 [==============================] - 432s 43ms/step - reward: 0.0794\n",
            "47 episodes - episode_reward: 16.872 [3.000, 33.000] - loss: 0.037 - mae: 0.980 - mean_q: 1.180 - mean_eps: 0.038 - ale.lives: 1.896\n",
            "\n",
            "Interval 293 (2920000 steps performed)\n",
            "10000/10000 [==============================] - 425s 43ms/step - reward: 0.0736\n",
            "48 episodes - episode_reward: 15.188 [7.000, 29.000] - loss: 0.038 - mae: 0.989 - mean_q: 1.186 - mean_eps: 0.035 - ale.lives: 2.036\n",
            "\n",
            "Interval 294 (2930000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0731\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2940000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 452s 45ms/step - reward: 0.0731\n",
            "48 episodes - episode_reward: 15.312 [5.000, 32.000] - loss: 0.037 - mae: 1.015 - mean_q: 1.219 - mean_eps: 0.031 - ale.lives: 2.038\n",
            "\n",
            "Interval 295 (2940000 steps performed)\n",
            "10000/10000 [==============================] - 436s 43ms/step - reward: 0.0787\n",
            "45 episodes - episode_reward: 17.200 [5.000, 36.000] - loss: 0.038 - mae: 1.019 - mean_q: 1.223 - mean_eps: 0.028 - ale.lives: 2.084\n",
            "\n",
            "Interval 296 (2950000 steps performed)\n",
            "10000/10000 [==============================] - 424s 42ms/step - reward: 0.0795\n",
            "44 episodes - episode_reward: 18.409 [3.000, 34.000] - loss: 0.037 - mae: 1.016 - mean_q: 1.219 - mean_eps: 0.025 - ale.lives: 1.958\n",
            "\n",
            "Interval 297 (2960000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0808\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_2970000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 451s 45ms/step - reward: 0.0808\n",
            "45 episodes - episode_reward: 17.844 [5.000, 29.000] - loss: 0.038 - mae: 1.027 - mean_q: 1.231 - mean_eps: 0.022 - ale.lives: 2.015\n",
            "\n",
            "Interval 298 (2970000 steps performed)\n",
            "10000/10000 [==============================] - 425s 43ms/step - reward: 0.0758\n",
            "46 episodes - episode_reward: 16.196 [5.000, 33.000] - loss: 0.040 - mae: 1.041 - mean_q: 1.248 - mean_eps: 0.018 - ale.lives: 2.093\n",
            "\n",
            "Interval 299 (2980000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0827\n",
            "45 episodes - episode_reward: 18.867 [5.000, 34.000] - loss: 0.040 - mae: 1.080 - mean_q: 1.296 - mean_eps: 0.015 - ale.lives: 1.920\n",
            "\n",
            "Interval 300 (2990000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0908\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3000000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 452s 45ms/step - reward: 0.0908\n",
            "42 episodes - episode_reward: 20.952 [13.000, 34.000] - loss: 0.041 - mae: 1.091 - mean_q: 1.310 - mean_eps: 0.012 - ale.lives: 1.981\n",
            "\n",
            "Interval 301 (3000000 steps performed)\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0904\n",
            "48 episodes - episode_reward: 19.208 [5.000, 35.000] - loss: 0.042 - mae: 1.112 - mean_q: 1.334 - mean_eps: 0.010 - ale.lives: 2.086\n",
            "\n",
            "Interval 302 (3010000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0863\n",
            "46 episodes - episode_reward: 18.761 [6.000, 31.000] - loss: 0.043 - mae: 1.148 - mean_q: 1.377 - mean_eps: 0.010 - ale.lives: 1.995\n",
            "\n",
            "Interval 303 (3020000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0838\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3030000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 456s 46ms/step - reward: 0.0839\n",
            "46 episodes - episode_reward: 18.283 [3.000, 35.000] - loss: 0.044 - mae: 1.182 - mean_q: 1.417 - mean_eps: 0.010 - ale.lives: 2.016\n",
            "\n",
            "Interval 304 (3030000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0898\n",
            "45 episodes - episode_reward: 20.044 [7.000, 30.000] - loss: 0.045 - mae: 1.199 - mean_q: 1.437 - mean_eps: 0.010 - ale.lives: 1.928\n",
            "\n",
            "Interval 305 (3040000 steps performed)\n",
            "10000/10000 [==============================] - 424s 42ms/step - reward: 0.0896\n",
            "46 episodes - episode_reward: 19.609 [8.000, 32.000] - loss: 0.043 - mae: 1.167 - mean_q: 1.396 - mean_eps: 0.010 - ale.lives: 1.967\n",
            "\n",
            "Interval 306 (3050000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0817\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3060000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 455s 45ms/step - reward: 0.0817\n",
            "44 episodes - episode_reward: 18.500 [6.000, 31.000] - loss: 0.044 - mae: 1.199 - mean_q: 1.440 - mean_eps: 0.010 - ale.lives: 1.960\n",
            "\n",
            "Interval 307 (3060000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0755\n",
            "47 episodes - episode_reward: 16.085 [8.000, 28.000] - loss: 0.045 - mae: 1.207 - mean_q: 1.448 - mean_eps: 0.010 - ale.lives: 1.979\n",
            "\n",
            "Interval 308 (3070000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0729\n",
            "48 episodes - episode_reward: 15.125 [6.000, 29.000] - loss: 0.044 - mae: 1.175 - mean_q: 1.411 - mean_eps: 0.010 - ale.lives: 1.917\n",
            "\n",
            "Interval 309 (3080000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0698\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3090000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 455s 45ms/step - reward: 0.0699\n",
            "48 episodes - episode_reward: 14.625 [6.000, 31.000] - loss: 0.045 - mae: 1.161 - mean_q: 1.394 - mean_eps: 0.010 - ale.lives: 1.887\n",
            "\n",
            "Interval 310 (3090000 steps performed)\n",
            "10000/10000 [==============================] - 427s 43ms/step - reward: 0.0714\n",
            "45 episodes - episode_reward: 15.622 [6.000, 33.000] - loss: 0.045 - mae: 1.180 - mean_q: 1.415 - mean_eps: 0.010 - ale.lives: 1.975\n",
            "\n",
            "Interval 311 (3100000 steps performed)\n",
            "10000/10000 [==============================] - 422s 42ms/step - reward: 0.0719\n",
            "50 episodes - episode_reward: 14.520 [4.000, 27.000] - loss: 0.045 - mae: 1.185 - mean_q: 1.424 - mean_eps: 0.010 - ale.lives: 1.929\n",
            "\n",
            "Interval 312 (3110000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0786\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3120000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 452s 45ms/step - reward: 0.0787\n",
            "48 episodes - episode_reward: 16.396 [4.000, 34.000] - loss: 0.045 - mae: 1.171 - mean_q: 1.406 - mean_eps: 0.010 - ale.lives: 1.893\n",
            "\n",
            "Interval 313 (3120000 steps performed)\n",
            "10000/10000 [==============================] - 424s 42ms/step - reward: 0.0707\n",
            "45 episodes - episode_reward: 15.556 [6.000, 32.000] - loss: 0.045 - mae: 1.152 - mean_q: 1.384 - mean_eps: 0.010 - ale.lives: 1.901\n",
            "\n",
            "Interval 314 (3130000 steps performed)\n",
            "10000/10000 [==============================] - 421s 42ms/step - reward: 0.0740\n",
            "49 episodes - episode_reward: 15.367 [4.000, 54.000] - loss: 0.045 - mae: 1.150 - mean_q: 1.381 - mean_eps: 0.010 - ale.lives: 1.924\n",
            "\n",
            "Interval 315 (3140000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0805\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3150000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 451s 45ms/step - reward: 0.0805\n",
            "43 episodes - episode_reward: 18.581 [5.000, 35.000] - loss: 0.045 - mae: 1.153 - mean_q: 1.391 - mean_eps: 0.010 - ale.lives: 1.901\n",
            "\n",
            "Interval 316 (3150000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0767\n",
            "45 episodes - episode_reward: 17.000 [7.000, 35.000] - loss: 0.045 - mae: 1.145 - mean_q: 1.378 - mean_eps: 0.010 - ale.lives: 2.006\n",
            "\n",
            "Interval 317 (3160000 steps performed)\n",
            "10000/10000 [==============================] - 429s 43ms/step - reward: 0.0755\n",
            "46 episodes - episode_reward: 16.478 [2.000, 32.000] - loss: 0.044 - mae: 1.130 - mean_q: 1.357 - mean_eps: 0.010 - ale.lives: 1.931\n",
            "\n",
            "Interval 318 (3170000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0705\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3180000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 458s 46ms/step - reward: 0.0705\n",
            "45 episodes - episode_reward: 15.622 [4.000, 32.000] - loss: 0.043 - mae: 1.098 - mean_q: 1.322 - mean_eps: 0.010 - ale.lives: 2.014\n",
            "\n",
            "Interval 319 (3180000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0802\n",
            "46 episodes - episode_reward: 16.717 [1.000, 38.000] - loss: 0.043 - mae: 1.072 - mean_q: 1.291 - mean_eps: 0.010 - ale.lives: 2.028\n",
            "\n",
            "Interval 320 (3190000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0797\n",
            "50 episodes - episode_reward: 16.660 [6.000, 41.000] - loss: 0.045 - mae: 1.085 - mean_q: 1.309 - mean_eps: 0.010 - ale.lives: 1.950\n",
            "\n",
            "Interval 321 (3200000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0807\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3210000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 457s 46ms/step - reward: 0.0807\n",
            "49 episodes - episode_reward: 16.510 [6.000, 31.000] - loss: 0.046 - mae: 1.109 - mean_q: 1.336 - mean_eps: 0.010 - ale.lives: 2.001\n",
            "\n",
            "Interval 322 (3210000 steps performed)\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0736\n",
            "47 episodes - episode_reward: 15.511 [5.000, 29.000] - loss: 0.045 - mae: 1.107 - mean_q: 1.333 - mean_eps: 0.010 - ale.lives: 1.986\n",
            "\n",
            "Interval 323 (3220000 steps performed)\n",
            "10000/10000 [==============================] - 433s 43ms/step - reward: 0.0650\n",
            "44 episodes - episode_reward: 14.977 [6.000, 28.000] - loss: 0.046 - mae: 1.098 - mean_q: 1.323 - mean_eps: 0.010 - ale.lives: 1.931\n",
            "\n",
            "Interval 324 (3230000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0760\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3240000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 461s 46ms/step - reward: 0.0760\n",
            "45 episodes - episode_reward: 16.600 [5.000, 31.000] - loss: 0.046 - mae: 1.085 - mean_q: 1.308 - mean_eps: 0.010 - ale.lives: 2.032\n",
            "\n",
            "Interval 325 (3240000 steps performed)\n",
            "10000/10000 [==============================] - 437s 44ms/step - reward: 0.0725\n",
            "44 episodes - episode_reward: 16.614 [3.000, 31.000] - loss: 0.046 - mae: 1.068 - mean_q: 1.290 - mean_eps: 0.010 - ale.lives: 1.930\n",
            "\n",
            "Interval 326 (3250000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0796\n",
            "46 episodes - episode_reward: 17.391 [5.000, 33.000] - loss: 0.046 - mae: 1.064 - mean_q: 1.284 - mean_eps: 0.010 - ale.lives: 1.918\n",
            "\n",
            "Interval 327 (3260000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0836\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3270000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 460s 46ms/step - reward: 0.0836\n",
            "43 episodes - episode_reward: 19.326 [5.000, 53.000] - loss: 0.046 - mae: 1.078 - mean_q: 1.302 - mean_eps: 0.010 - ale.lives: 2.021\n",
            "\n",
            "Interval 328 (3270000 steps performed)\n",
            "10000/10000 [==============================] - 427s 43ms/step - reward: 0.0770\n",
            "44 episodes - episode_reward: 17.432 [6.000, 33.000] - loss: 0.047 - mae: 1.096 - mean_q: 1.326 - mean_eps: 0.010 - ale.lives: 2.018\n",
            "\n",
            "Interval 329 (3280000 steps performed)\n",
            "10000/10000 [==============================] - 425s 42ms/step - reward: 0.0755\n",
            "46 episodes - episode_reward: 16.522 [5.000, 27.000] - loss: 0.048 - mae: 1.136 - mean_q: 1.379 - mean_eps: 0.010 - ale.lives: 1.880\n",
            "\n",
            "Interval 330 (3290000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0762\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3300000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 453s 45ms/step - reward: 0.0762\n",
            "47 episodes - episode_reward: 16.234 [5.000, 37.000] - loss: 0.048 - mae: 1.168 - mean_q: 1.415 - mean_eps: 0.010 - ale.lives: 1.984\n",
            "\n",
            "Interval 331 (3300000 steps performed)\n",
            "10000/10000 [==============================] - 417s 42ms/step - reward: 0.0756\n",
            "44 episodes - episode_reward: 17.295 [5.000, 34.000] - loss: 0.049 - mae: 1.204 - mean_q: 1.457 - mean_eps: 0.010 - ale.lives: 1.997\n",
            "\n",
            "Interval 332 (3310000 steps performed)\n",
            "10000/10000 [==============================] - 418s 42ms/step - reward: 0.0814\n",
            "45 episodes - episode_reward: 17.778 [8.000, 32.000] - loss: 0.048 - mae: 1.212 - mean_q: 1.467 - mean_eps: 0.010 - ale.lives: 2.039\n",
            "\n",
            "Interval 333 (3320000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0733\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3330000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 451s 45ms/step - reward: 0.0734\n",
            "44 episodes - episode_reward: 16.727 [2.000, 32.000] - loss: 0.049 - mae: 1.191 - mean_q: 1.444 - mean_eps: 0.010 - ale.lives: 2.071\n",
            "\n",
            "Interval 334 (3330000 steps performed)\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0737\n",
            "45 episodes - episode_reward: 16.356 [4.000, 32.000] - loss: 0.049 - mae: 1.192 - mean_q: 1.447 - mean_eps: 0.010 - ale.lives: 1.924\n",
            "\n",
            "Interval 335 (3340000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0803\n",
            "46 episodes - episode_reward: 17.630 [5.000, 29.000] - loss: 0.051 - mae: 1.193 - mean_q: 1.450 - mean_eps: 0.010 - ale.lives: 2.026\n",
            "\n",
            "Interval 336 (3350000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0835\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3360000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 455s 46ms/step - reward: 0.0836\n",
            "41 episodes - episode_reward: 20.415 [7.000, 38.000] - loss: 0.051 - mae: 1.203 - mean_q: 1.462 - mean_eps: 0.010 - ale.lives: 2.134\n",
            "\n",
            "Interval 337 (3360000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0735\n",
            "46 episodes - episode_reward: 15.717 [5.000, 25.000] - loss: 0.051 - mae: 1.206 - mean_q: 1.465 - mean_eps: 0.010 - ale.lives: 2.054\n",
            "\n",
            "Interval 338 (3370000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0824\n",
            "48 episodes - episode_reward: 16.979 [3.000, 33.000] - loss: 0.050 - mae: 1.161 - mean_q: 1.413 - mean_eps: 0.010 - ale.lives: 2.061\n",
            "\n",
            "Interval 339 (3380000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0820\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3390000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 442s 44ms/step - reward: 0.0820\n",
            "48 episodes - episode_reward: 17.542 [5.000, 34.000] - loss: 0.052 - mae: 1.186 - mean_q: 1.448 - mean_eps: 0.010 - ale.lives: 1.961\n",
            "\n",
            "Interval 340 (3390000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0808\n",
            "46 episodes - episode_reward: 17.348 [5.000, 30.000] - loss: 0.055 - mae: 1.222 - mean_q: 1.494 - mean_eps: 0.010 - ale.lives: 2.064\n",
            "\n",
            "Interval 341 (3400000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0836\n",
            "46 episodes - episode_reward: 18.304 [6.000, 28.000] - loss: 0.056 - mae: 1.239 - mean_q: 1.512 - mean_eps: 0.010 - ale.lives: 2.077\n",
            "\n",
            "Interval 342 (3410000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0774\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3420000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 456s 46ms/step - reward: 0.0774\n",
            "41 episodes - episode_reward: 18.585 [4.000, 35.000] - loss: 0.054 - mae: 1.227 - mean_q: 1.498 - mean_eps: 0.010 - ale.lives: 1.963\n",
            "\n",
            "Interval 343 (3420000 steps performed)\n",
            "10000/10000 [==============================] - 418s 42ms/step - reward: 0.0859\n",
            "43 episodes - episode_reward: 20.302 [4.000, 34.000] - loss: 0.055 - mae: 1.232 - mean_q: 1.506 - mean_eps: 0.010 - ale.lives: 2.010\n",
            "\n",
            "Interval 344 (3430000 steps performed)\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0857\n",
            "44 episodes - episode_reward: 18.909 [2.000, 32.000] - loss: 0.055 - mae: 1.238 - mean_q: 1.514 - mean_eps: 0.010 - ale.lives: 1.970\n",
            "\n",
            "Interval 345 (3440000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0827\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3450000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 449s 45ms/step - reward: 0.0827\n",
            "42 episodes - episode_reward: 20.262 [6.000, 35.000] - loss: 0.055 - mae: 1.244 - mean_q: 1.521 - mean_eps: 0.010 - ale.lives: 2.042\n",
            "\n",
            "Interval 346 (3450000 steps performed)\n",
            "10000/10000 [==============================] - 430s 43ms/step - reward: 0.0853\n",
            "47 episodes - episode_reward: 17.936 [7.000, 30.000] - loss: 0.054 - mae: 1.225 - mean_q: 1.498 - mean_eps: 0.010 - ale.lives: 2.049\n",
            "\n",
            "Interval 347 (3460000 steps performed)\n",
            "10000/10000 [==============================] - 425s 42ms/step - reward: 0.0839\n",
            "45 episodes - episode_reward: 18.600 [3.000, 32.000] - loss: 0.054 - mae: 1.237 - mean_q: 1.512 - mean_eps: 0.010 - ale.lives: 2.088\n",
            "\n",
            "Interval 348 (3470000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0836\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3480000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 463s 46ms/step - reward: 0.0836\n",
            "48 episodes - episode_reward: 17.771 [3.000, 29.000] - loss: 0.055 - mae: 1.237 - mean_q: 1.514 - mean_eps: 0.010 - ale.lives: 2.070\n",
            "\n",
            "Interval 349 (3480000 steps performed)\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0895\n",
            "44 episodes - episode_reward: 20.341 [8.000, 36.000] - loss: 0.054 - mae: 1.224 - mean_q: 1.498 - mean_eps: 0.010 - ale.lives: 1.989\n",
            "\n",
            "Interval 350 (3490000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0841\n",
            "45 episodes - episode_reward: 18.578 [3.000, 34.000] - loss: 0.054 - mae: 1.214 - mean_q: 1.486 - mean_eps: 0.010 - ale.lives: 2.084\n",
            "\n",
            "Interval 351 (3500000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0834\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3510000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 455s 45ms/step - reward: 0.0834\n",
            "46 episodes - episode_reward: 18.043 [6.000, 41.000] - loss: 0.054 - mae: 1.212 - mean_q: 1.480 - mean_eps: 0.010 - ale.lives: 2.166\n",
            "\n",
            "Interval 352 (3510000 steps performed)\n",
            "10000/10000 [==============================] - 433s 43ms/step - reward: 0.0861\n",
            "43 episodes - episode_reward: 19.814 [6.000, 37.000] - loss: 0.053 - mae: 1.221 - mean_q: 1.492 - mean_eps: 0.010 - ale.lives: 2.111\n",
            "\n",
            "Interval 353 (3520000 steps performed)\n",
            "10000/10000 [==============================] - 416s 42ms/step - reward: 0.0880\n",
            "46 episodes - episode_reward: 19.543 [5.000, 35.000] - loss: 0.057 - mae: 1.238 - mean_q: 1.515 - mean_eps: 0.010 - ale.lives: 2.108\n",
            "\n",
            "Interval 354 (3530000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0893\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3540000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 459s 46ms/step - reward: 0.0894\n",
            "42 episodes - episode_reward: 21.143 [5.000, 35.000] - loss: 0.055 - mae: 1.247 - mean_q: 1.523 - mean_eps: 0.010 - ale.lives: 2.035\n",
            "\n",
            "Interval 355 (3540000 steps performed)\n",
            "10000/10000 [==============================] - 420s 42ms/step - reward: 0.0893\n",
            "45 episodes - episode_reward: 19.956 [5.000, 31.000] - loss: 0.056 - mae: 1.258 - mean_q: 1.541 - mean_eps: 0.010 - ale.lives: 2.132\n",
            "\n",
            "Interval 356 (3550000 steps performed)\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0877\n",
            "45 episodes - episode_reward: 19.289 [9.000, 34.000] - loss: 0.057 - mae: 1.271 - mean_q: 1.559 - mean_eps: 0.010 - ale.lives: 2.137\n",
            "\n",
            "Interval 357 (3560000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0882\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3570000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 449s 45ms/step - reward: 0.0882\n",
            "48 episodes - episode_reward: 18.417 [4.000, 30.000] - loss: 0.057 - mae: 1.278 - mean_q: 1.570 - mean_eps: 0.010 - ale.lives: 2.057\n",
            "\n",
            "Interval 358 (3570000 steps performed)\n",
            "10000/10000 [==============================] - 440s 44ms/step - reward: 0.0916\n",
            "46 episodes - episode_reward: 19.652 [7.000, 33.000] - loss: 0.057 - mae: 1.257 - mean_q: 1.542 - mean_eps: 0.010 - ale.lives: 2.069\n",
            "\n",
            "Interval 359 (3580000 steps performed)\n",
            "10000/10000 [==============================] - 403s 40ms/step - reward: 0.0865\n",
            "50 episodes - episode_reward: 17.620 [7.000, 29.000] - loss: 0.059 - mae: 1.281 - mean_q: 1.575 - mean_eps: 0.010 - ale.lives: 2.102\n",
            "\n",
            "Interval 360 (3590000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0842\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3600000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 442s 44ms/step - reward: 0.0842\n",
            "47 episodes - episode_reward: 17.489 [5.000, 34.000] - loss: 0.060 - mae: 1.296 - mean_q: 1.595 - mean_eps: 0.010 - ale.lives: 2.113\n",
            "\n",
            "Interval 361 (3600000 steps performed)\n",
            "10000/10000 [==============================] - 441s 44ms/step - reward: 0.0886\n",
            "42 episodes - episode_reward: 21.214 [5.000, 53.000] - loss: 0.062 - mae: 1.295 - mean_q: 1.596 - mean_eps: 0.010 - ale.lives: 2.042\n",
            "\n",
            "Interval 362 (3610000 steps performed)\n",
            "10000/10000 [==============================] - 433s 43ms/step - reward: 0.0885\n",
            "45 episodes - episode_reward: 19.733 [9.000, 31.000] - loss: 0.060 - mae: 1.294 - mean_q: 1.593 - mean_eps: 0.010 - ale.lives: 2.054\n",
            "\n",
            "Interval 363 (3620000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0873\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3630000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 464s 46ms/step - reward: 0.0873\n",
            "43 episodes - episode_reward: 20.093 [5.000, 35.000] - loss: 0.060 - mae: 1.307 - mean_q: 1.607 - mean_eps: 0.010 - ale.lives: 2.118\n",
            "\n",
            "Interval 364 (3630000 steps performed)\n",
            "10000/10000 [==============================] - 440s 44ms/step - reward: 0.0866\n",
            "43 episodes - episode_reward: 20.186 [6.000, 42.000] - loss: 0.059 - mae: 1.274 - mean_q: 1.566 - mean_eps: 0.010 - ale.lives: 2.086\n",
            "\n",
            "Interval 365 (3640000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0886\n",
            "43 episodes - episode_reward: 20.651 [6.000, 43.000] - loss: 0.059 - mae: 1.273 - mean_q: 1.567 - mean_eps: 0.010 - ale.lives: 2.112\n",
            "\n",
            "Interval 366 (3650000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0875\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3660000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 450s 45ms/step - reward: 0.0876\n",
            "47 episodes - episode_reward: 19.064 [6.000, 38.000] - loss: 0.058 - mae: 1.234 - mean_q: 1.518 - mean_eps: 0.010 - ale.lives: 2.031\n",
            "\n",
            "Interval 367 (3660000 steps performed)\n",
            "10000/10000 [==============================] - 447s 45ms/step - reward: 0.0830\n",
            "50 episodes - episode_reward: 16.620 [3.000, 34.000] - loss: 0.059 - mae: 1.245 - mean_q: 1.530 - mean_eps: 0.010 - ale.lives: 2.061\n",
            "\n",
            "Interval 368 (3670000 steps performed)\n",
            "10000/10000 [==============================] - 417s 42ms/step - reward: 0.0811\n",
            "49 episodes - episode_reward: 16.551 [5.000, 34.000] - loss: 0.058 - mae: 1.245 - mean_q: 1.538 - mean_eps: 0.010 - ale.lives: 2.000\n",
            "\n",
            "Interval 369 (3680000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0843\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3690000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 431s 43ms/step - reward: 0.0843\n",
            "50 episodes - episode_reward: 16.740 [3.000, 51.000] - loss: 0.060 - mae: 1.254 - mean_q: 1.548 - mean_eps: 0.010 - ale.lives: 2.061\n",
            "\n",
            "Interval 370 (3690000 steps performed)\n",
            "10000/10000 [==============================] - 426s 43ms/step - reward: 0.0848\n",
            "50 episodes - episode_reward: 16.640 [4.000, 29.000] - loss: 0.060 - mae: 1.241 - mean_q: 1.534 - mean_eps: 0.010 - ale.lives: 2.084\n",
            "\n",
            "Interval 371 (3700000 steps performed)\n",
            "10000/10000 [==============================] - 381s 38ms/step - reward: 0.0804\n",
            "46 episodes - episode_reward: 17.783 [5.000, 52.000] - loss: 0.060 - mae: 1.261 - mean_q: 1.554 - mean_eps: 0.010 - ale.lives: 2.068\n",
            "\n",
            "Interval 372 (3710000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0864\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3720000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 436s 44ms/step - reward: 0.0864\n",
            "44 episodes - episode_reward: 19.591 [5.000, 36.000] - loss: 0.059 - mae: 1.268 - mean_q: 1.564 - mean_eps: 0.010 - ale.lives: 2.159\n",
            "\n",
            "Interval 373 (3720000 steps performed)\n",
            "10000/10000 [==============================] - 423s 42ms/step - reward: 0.0848\n",
            "43 episodes - episode_reward: 19.814 [5.000, 29.000] - loss: 0.061 - mae: 1.290 - mean_q: 1.589 - mean_eps: 0.010 - ale.lives: 2.077\n",
            "\n",
            "Interval 374 (3730000 steps performed)\n",
            "10000/10000 [==============================] - 422s 42ms/step - reward: 0.0834\n",
            "41 episodes - episode_reward: 20.146 [8.000, 33.000] - loss: 0.060 - mae: 1.276 - mean_q: 1.571 - mean_eps: 0.010 - ale.lives: 2.135\n",
            "\n",
            "Interval 375 (3740000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0833\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3750000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 469s 47ms/step - reward: 0.0833\n",
            "47 episodes - episode_reward: 17.830 [3.000, 32.000] - loss: 0.061 - mae: 1.296 - mean_q: 1.600 - mean_eps: 0.010 - ale.lives: 2.076\n",
            "\n",
            "Interval 376 (3750000 steps performed)\n",
            "10000/10000 [==============================] - 417s 42ms/step - reward: 0.0806\n",
            "48 episodes - episode_reward: 16.833 [6.000, 35.000] - loss: 0.060 - mae: 1.280 - mean_q: 1.579 - mean_eps: 0.010 - ale.lives: 2.103\n",
            "\n",
            "Interval 377 (3760000 steps performed)\n",
            "10000/10000 [==============================] - 406s 41ms/step - reward: 0.0811\n",
            "46 episodes - episode_reward: 17.457 [4.000, 30.000] - loss: 0.060 - mae: 1.282 - mean_q: 1.581 - mean_eps: 0.010 - ale.lives: 2.065\n",
            "\n",
            "Interval 378 (3770000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0821\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3780000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 450s 45ms/step - reward: 0.0821\n",
            "44 episodes - episode_reward: 19.000 [4.000, 44.000] - loss: 0.061 - mae: 1.270 - mean_q: 1.573 - mean_eps: 0.010 - ale.lives: 2.075\n",
            "\n",
            "Interval 379 (3780000 steps performed)\n",
            "10000/10000 [==============================] - 411s 41ms/step - reward: 0.0843\n",
            "48 episodes - episode_reward: 17.521 [6.000, 31.000] - loss: 0.063 - mae: 1.292 - mean_q: 1.599 - mean_eps: 0.010 - ale.lives: 2.101\n",
            "\n",
            "Interval 380 (3790000 steps performed)\n",
            "10000/10000 [==============================] - 412s 41ms/step - reward: 0.0824\n",
            "46 episodes - episode_reward: 17.435 [4.000, 32.000] - loss: 0.062 - mae: 1.289 - mean_q: 1.587 - mean_eps: 0.010 - ale.lives: 2.100\n",
            "\n",
            "Interval 381 (3800000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0828\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3810000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 469s 47ms/step - reward: 0.0829\n",
            "51 episodes - episode_reward: 16.588 [6.000, 33.000] - loss: 0.062 - mae: 1.282 - mean_q: 1.578 - mean_eps: 0.010 - ale.lives: 2.098\n",
            "\n",
            "Interval 382 (3810000 steps performed)\n",
            "10000/10000 [==============================] - 442s 44ms/step - reward: 0.0757\n",
            "46 episodes - episode_reward: 16.348 [5.000, 29.000] - loss: 0.062 - mae: 1.258 - mean_q: 1.557 - mean_eps: 0.010 - ale.lives: 2.145\n",
            "\n",
            "Interval 383 (3820000 steps performed)\n",
            "10000/10000 [==============================] - 436s 44ms/step - reward: 0.0803\n",
            "47 episodes - episode_reward: 17.106 [2.000, 32.000] - loss: 0.063 - mae: 1.246 - mean_q: 1.537 - mean_eps: 0.010 - ale.lives: 2.095\n",
            "\n",
            "Interval 384 (3830000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0760\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3840000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 483s 48ms/step - reward: 0.0760\n",
            "45 episodes - episode_reward: 17.133 [5.000, 31.000] - loss: 0.061 - mae: 1.238 - mean_q: 1.529 - mean_eps: 0.010 - ale.lives: 1.968\n",
            "\n",
            "Interval 385 (3840000 steps performed)\n",
            "10000/10000 [==============================] - 453s 45ms/step - reward: 0.0717\n",
            "48 episodes - episode_reward: 14.688 [2.000, 29.000] - loss: 0.060 - mae: 1.235 - mean_q: 1.522 - mean_eps: 0.010 - ale.lives: 2.034\n",
            "\n",
            "Interval 386 (3850000 steps performed)\n",
            "10000/10000 [==============================] - 438s 44ms/step - reward: 0.0800\n",
            "48 episodes - episode_reward: 16.729 [5.000, 30.000] - loss: 0.061 - mae: 1.238 - mean_q: 1.526 - mean_eps: 0.010 - ale.lives: 2.078\n",
            "\n",
            "Interval 387 (3860000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0740\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3870000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 468s 47ms/step - reward: 0.0741\n",
            "47 episodes - episode_reward: 15.872 [4.000, 29.000] - loss: 0.060 - mae: 1.236 - mean_q: 1.518 - mean_eps: 0.010 - ale.lives: 2.040\n",
            "\n",
            "Interval 388 (3870000 steps performed)\n",
            "10000/10000 [==============================] - 405s 40ms/step - reward: 0.0696\n",
            "46 episodes - episode_reward: 15.087 [6.000, 29.000] - loss: 0.062 - mae: 1.259 - mean_q: 1.551 - mean_eps: 0.010 - ale.lives: 2.080\n",
            "\n",
            "Interval 389 (3880000 steps performed)\n",
            "10000/10000 [==============================] - 422s 42ms/step - reward: 0.0643\n",
            "49 episodes - episode_reward: 13.020 [2.000, 22.000] - loss: 0.061 - mae: 1.253 - mean_q: 1.547 - mean_eps: 0.010 - ale.lives: 1.959\n",
            "\n",
            "Interval 390 (3890000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0657\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3900000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 461s 46ms/step - reward: 0.0658\n",
            "45 episodes - episode_reward: 14.600 [3.000, 27.000] - loss: 0.061 - mae: 1.249 - mean_q: 1.540 - mean_eps: 0.010 - ale.lives: 2.062\n",
            "\n",
            "Interval 391 (3900000 steps performed)\n",
            "10000/10000 [==============================] - 460s 46ms/step - reward: 0.0773\n",
            "47 episodes - episode_reward: 16.340 [4.000, 34.000] - loss: 0.062 - mae: 1.264 - mean_q: 1.556 - mean_eps: 0.010 - ale.lives: 2.045\n",
            "\n",
            "Interval 392 (3910000 steps performed)\n",
            "10000/10000 [==============================] - 428s 43ms/step - reward: 0.0731\n",
            "42 episodes - episode_reward: 17.619 [6.000, 32.000] - loss: 0.061 - mae: 1.276 - mean_q: 1.572 - mean_eps: 0.010 - ale.lives: 2.131\n",
            "\n",
            "Interval 393 (3920000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0757\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3930000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 466s 47ms/step - reward: 0.0758\n",
            "48 episodes - episode_reward: 15.812 [3.000, 34.000] - loss: 0.060 - mae: 1.258 - mean_q: 1.549 - mean_eps: 0.010 - ale.lives: 2.097\n",
            "\n",
            "Interval 394 (3930000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0755\n",
            "45 episodes - episode_reward: 16.533 [3.000, 35.000] - loss: 0.061 - mae: 1.273 - mean_q: 1.567 - mean_eps: 0.010 - ale.lives: 2.039\n",
            "\n",
            "Interval 395 (3940000 steps performed)\n",
            "10000/10000 [==============================] - 396s 40ms/step - reward: 0.0765\n",
            "51 episodes - episode_reward: 15.235 [3.000, 29.000] - loss: 0.062 - mae: 1.288 - mean_q: 1.589 - mean_eps: 0.010 - ale.lives: 2.062\n",
            "\n",
            "Interval 396 (3950000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0776\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3960000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 432s 43ms/step - reward: 0.0777\n",
            "48 episodes - episode_reward: 16.271 [5.000, 31.000] - loss: 0.063 - mae: 1.281 - mean_q: 1.580 - mean_eps: 0.010 - ale.lives: 2.072\n",
            "\n",
            "Interval 397 (3960000 steps performed)\n",
            "10000/10000 [==============================] - 433s 43ms/step - reward: 0.0723\n",
            "48 episodes - episode_reward: 14.917 [4.000, 33.000] - loss: 0.063 - mae: 1.277 - mean_q: 1.582 - mean_eps: 0.010 - ale.lives: 2.066\n",
            "\n",
            "Interval 398 (3970000 steps performed)\n",
            "10000/10000 [==============================] - 413s 41ms/step - reward: 0.0765\n",
            "41 episodes - episode_reward: 18.488 [5.000, 30.000] - loss: 0.061 - mae: 1.288 - mean_q: 1.589 - mean_eps: 0.010 - ale.lives: 2.091\n",
            "\n",
            "Interval 399 (3980000 steps performed)\n",
            " 9997/10000 [============================>.] - ETA: 0s - reward: 0.0725\n",
            "[Checkpoint] Pesos guardados en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\dqn_SpaceInvaders-v0_weights_3990000.h5f\n",
            "\n",
            "[Checkpoint] Memoria guardada de forma segura en: ./models\\modelo_D1_Attention_enhancedhyperparams\\checkpoints\\memory.pkl\n",
            "10000/10000 [==============================] - 439s 44ms/step - reward: 0.0725\n",
            "46 episodes - episode_reward: 15.761 [0.000, 34.000] - loss: 0.061 - mae: 1.297 - mean_q: 1.595 - mean_eps: 0.010 - ale.lives: 2.092\n",
            "\n",
            "Interval 400 (3990000 steps performed)\n",
            "10000/10000 [==============================] - 406s 41ms/step - reward: 0.0747\n",
            "done, took 157652.805 seconds\n"
          ]
        }
      ],
      "source": [
        "# ENTRENAR DQN\n",
        "if TRAIN_STEPS>0:\n",
        "  dqn.fit(env, callbacks=callbacks, nb_steps=TRAIN_STEPS-last_checkpoint_steps, log_interval=LOG_INTERVAL, visualize=False)\n",
        "  dqn.save_weights(weights_filename, overwrite=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHYryKd1Gb2b",
        "outputId": "cf7d86ae-ab74-4723-8367-ffadc582e464",
        "tags": []
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 10.000, steps: 515\n",
            "Episode 2: reward: 10.000, steps: 623\n",
            "Episode 3: reward: 16.000, steps: 649\n",
            "Episode 4: reward: 12.000, steps: 611\n",
            "Episode 5: reward: 15.000, steps: 676\n",
            "Episode 6: reward: 9.000, steps: 588\n",
            "Episode 7: reward: 15.000, steps: 628\n",
            "Episode 8: reward: 9.000, steps: 521\n",
            "Episode 9: reward: 8.000, steps: 575\n",
            "Episode 10: reward: 14.000, steps: 709\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x151d0973308>"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "env_test = gym.make('SpaceInvaders-v0')\n",
        "\n",
        "# Testing part to calculate the mean reward\n",
        "weights_filename =os.path.join(WEIGHTS_DIR, 'dqn_{}_weights_{}.h5f'.format(env_name, model_name))\n",
        "#weights_filename=latest_checkpoint\n",
        "#print(weights_filename)\n",
        "dqn.load_weights(weights_filename)\n",
        "dqn.test(env_test, nb_episodes=10, visualize=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 25.000, steps: 1040\n",
            "Episode 2: reward: 31.000, steps: 1320\n",
            "Episode 3: reward: 19.000, steps: 774\n",
            "Episode 4: reward: 21.000, steps: 854\n",
            "Episode 5: reward: 16.000, steps: 634\n",
            "Episode 6: reward: 25.000, steps: 1034\n",
            "Episode 7: reward: 21.000, steps: 863\n",
            "Episode 8: reward: 25.000, steps: 1043\n",
            "Episode 9: reward: 23.000, steps: 909\n",
            "Episode 10: reward: 17.000, steps: 700\n",
            "Mean reward: 22.3\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, 'dqn_SpaceInvaders-v0_weights_2670000.h5f')\n",
        "dqn.load_weights(checkpoint_path)\n",
        "history = dqn.test(env_test, nb_episodes=10, visualize=False)\n",
        "scores = history.history['episode_reward']\n",
        "print(f\"Mean reward: {np.mean(scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 20.000, steps: 858\n",
            "Episode 2: reward: 20.000, steps: 941\n",
            "Episode 3: reward: 32.000, steps: 1596\n",
            "Episode 4: reward: 20.000, steps: 841\n",
            "Episode 5: reward: 20.000, steps: 851\n",
            "Episode 6: reward: 52.000, steps: 2616\n",
            "Episode 7: reward: 19.000, steps: 740\n",
            "Episode 8: reward: 17.000, steps: 668\n",
            "Episode 9: reward: 22.000, steps: 1038\n",
            "Episode 10: reward: 20.000, steps: 845\n",
            "Mean reward: 24.2\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, 'dqn_SpaceInvaders-v0_weights_2670000.h5f')\n",
        "dqn.load_weights(checkpoint_path)\n",
        "history = dqn.test(env_test, nb_episodes=10, visualize=False)\n",
        "scores = history.history['episode_reward']\n",
        "print(f\"Mean reward: {np.mean(scores)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing for 10 episodes ...\n",
            "Episode 1: reward: 19.000, steps: 877\n",
            "Episode 2: reward: 29.000, steps: 1250\n",
            "Episode 3: reward: 29.000, steps: 1047\n",
            "Episode 4: reward: 25.000, steps: 1048\n",
            "Episode 5: reward: 20.000, steps: 876\n",
            "Episode 6: reward: 19.000, steps: 780\n",
            "Episode 7: reward: 15.000, steps: 654\n",
            "Episode 8: reward: 20.000, steps: 858\n",
            "Episode 9: reward: 15.000, steps: 664\n",
            "Episode 10: reward: 19.000, steps: 766\n",
            "Mean reward: 21.0\n"
          ]
        }
      ],
      "source": [
        "checkpoint_path = os.path.join(CHECKPOINTS_DIR, 'dqn_SpaceInvaders-v0_weights_2670000.h5f')\n",
        "dqn.load_weights(checkpoint_path)\n",
        "history = dqn.test(env_test, nb_episodes=10, visualize=False)\n",
        "scores = history.history['episode_reward']\n",
        "print(f\"Mean reward: {np.mean(scores)}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv_rl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
