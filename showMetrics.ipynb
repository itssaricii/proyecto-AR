{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import seaborn as sns\n",
    "import time"
   ],
   "id": "c1e8228e819d9838"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Funciones auxiliares\n",
    "def graph_training_csv(csv_path, model_dir, model_name, variable='episode_reward'):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    if variable not in df.columns:\n",
    "        print(f\" La variable '{variable}' no está en el CSV. Columnas disponibles: {list(df.columns)}\")\n",
    "        return\n",
    "\n",
    "    df[variable].plot(title=f\"{model_name}: Evolución - {variable}\", legend=False)\n",
    "    plt.xlabel('Episodio')\n",
    "    plt.ylabel(variable)\n",
    "    plt.grid(True)\n",
    "    plt.savefig(os.path.join(model_dir, f\"{model_name}_{variable}.png\"))\n",
    "    plt.show()\n",
    "\n",
    "def graph_training(log_path, model_dir, model_name, variable='mean_q'):\n",
    "  with open(log_path) as f:\n",
    "    data = json.load(f)\n",
    "    print(len(data[variable]))\n",
    "    pd.DataFrame(data[variable]).plot(title=f\"{model_name}: Evolución - {variable}\", legend=False)\n",
    "    plt.xlabel('Steps')\n",
    "    plt.ylabel(str(variable))\n",
    "    plt.savefig(model_dir+\"/\"+ model_name + '_' + variable + '.png')\n",
    "\n",
    "def graph_model(model_name):\n",
    "    MODEL_DIR = \"./models/\" + model_name\n",
    "    log_csv_path = os.path.join(MODEL_DIR, f'{model_name}_training_log.csv')\n",
    "    graph_training_csv(log_csv_path, MODEL_DIR, model_name, 'episode_reward')\n",
    "\n",
    "def _plot_metrics(df, model_name, window_size, model_dir):\n",
    "    sns.set(style=\"darkgrid\", font_scale=1.2)\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "\n",
    "    plots_info = [\n",
    "        ('episode_reward', 'reward_smooth', 'Recompensa por episodio', 'Recompensa', axes[0, 0]),\n",
    "        ('loss', 'loss_smooth', 'Pérdida (loss) por episodio', 'Loss', axes[0, 1]),\n",
    "        ('mean_q', 'q_smooth', 'Q medio por episodio', 'Mean Q', axes[1, 0]),\n",
    "        ('mean_eps', 'eps_smooth', 'Epsilon medio por episodio', 'Mean Eps', axes[1, 1]),\n",
    "    ]\n",
    "\n",
    "    for orig_col, smooth_col, title, ylabel, ax in plots_info:\n",
    "        sns.lineplot(x='episode', y=orig_col, data=df, marker='o', markersize=4, label='Original', ax=ax)\n",
    "        sns.lineplot(x='episode', y=smooth_col, data=df, color='red', linewidth=2, label=f'Media móvil ({window_size})', ax=ax)\n",
    "        ax.set_title(title)\n",
    "        ax.set_xlabel('Episodio')\n",
    "        ax.set_ylabel(ylabel)\n",
    "        ax.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "        unique = dict(zip(labels, handles))\n",
    "        ax.legend(unique.values(), unique.keys(), loc='best')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    graphs_dir = os.path.join(model_dir, \"graphs\")\n",
    "    os.makedirs(graphs_dir, exist_ok=True)\n",
    "\n",
    "    datetime_stamp = pd.to_datetime('today').strftime('%Y%m%d%H%M%S')\n",
    "    graph_path = os.path.join(graphs_dir, f'{datetime_stamp}_{model_name}_training_analyze_graph.png')\n",
    "    csv_path = os.path.join(graphs_dir, f'{datetime_stamp}_{model_name}_training_analyze_log.csv')\n",
    "\n",
    "    plt.savefig(graph_path, dpi=300)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Gráfico guardado en: {graph_path}\")\n",
    "    print(f\"CSV de informe guardado en: {csv_path}\")\n",
    "\n",
    "def _print_report(df):\n",
    "    print(f\"Episodios totales: {df['episode'].max()}\")\n",
    "    print(f\"Recompensa media: {df['episode_reward'].mean():.2f}\")\n",
    "    print(f\"Recompensa máxima: {df['episode_reward'].max()}\")\n",
    "    print(f\"Recompensa mínima: {df['episode_reward'].min()}\")\n",
    "    print(f\"Loss medio: {df['loss'].mean(skipna=True):.6f}\")\n",
    "    print(f\"Mean Q medio: {df['mean_q'].mean(skipna=True):.6f}\")\n",
    "    print(f\"Epsilon medio: {df['mean_eps'].mean(skipna=True):.6f}\")\n",
    "    print(f\"Pasos medios por episodio: {df['nb_steps'].mean():.2f}\")\n",
    "\n",
    "    if len(df) > 1:\n",
    "        reward_diff = df['episode_reward'].iloc[-1] - df['episode_reward'].iloc[0]\n",
    "        if reward_diff > 0:\n",
    "            print(f\"La recompensa final ({df['episode_reward'].iloc[-1]:.2f}) es mayor que la inicial ({df['episode_reward'].iloc[0]:.2f}), indicando una mejora.\")\n",
    "        else:\n",
    "            print(f\"La recompensa final ({df['episode_reward'].iloc[-1]:.2f}) no ha mejorado significativamente respecto a la inicial ({df['episode_reward'].iloc[0]:.2f}).\")\n",
    "    else:\n",
    "        print(\"No hay suficientes episodios para evaluar la evolución de la recompensa global.\")\n",
    "\n",
    "def _analyze_training_last(df_full, model_name, window_size, model_dir):\n",
    "    latest_log_path = _get_latest_log_file(model_dir, model_name)\n",
    "    if not latest_log_path:\n",
    "        print(\"No se encontró un CSV de análisis previo para los últimos episodios.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(latest_log_path)\n",
    "    if df.empty:\n",
    "        print(\"El DataFrame de los últimos episodios está vacío.\")\n",
    "        return\n",
    "\n",
    "    df = df.tail(window_size + 1).iloc[:-1]\n",
    "\n",
    "    print(f\"\\nINFORME DEL TRAINING (últimos {window_size} episodios completados {df['episode'].min()} al {df['episode'].max()})\\n\" + \"-\" * 40)\n",
    "    _print_report(df)\n",
    "\n",
    "def _get_latest_log_file(model_dir, model_name):\n",
    "    pattern = os.path.join(model_dir, \"graphs\", f'*_{model_name}_training_analyze_log.csv')\n",
    "    files = glob.glob(pattern)\n",
    "    if not files:\n",
    "        return None\n",
    "    return max(files, key=os.path.basename)"
   ],
   "id": "87880284cfa94aa9"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# FUNCION DE ANALISIS DEL ENTRENAMIENTO ACTUAL\n",
    "def analyze_training(model_name, window_size):\n",
    "    \"\"\"\n",
    "    Analiza el log de entrenamiento de un modelo de RL, genera gráficos de evolución\n",
    "    de métricas y un informe textual. Incluye un informe de métricas globales y otro\n",
    "    centrado en las métricas después del periodo de warmup.\n",
    "\n",
    "    Args:\n",
    "        model_name (str): El nombre del modelo.\n",
    "        window_size (int): Tamaño de la ventana para la media móvil.\n",
    "    \"\"\"\n",
    "    MODEL_DIR = os.path.join(\"./models\", model_name)\n",
    "    log_csv_path = os.path.join(MODEL_DIR, f'{model_name}_training_log.csv')\n",
    "\n",
    "    if not os.path.exists(log_csv_path):\n",
    "        print(f\"Error: El archivo de log '{log_csv_path}' no se encontró.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(log_csv_path)\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"El DataFrame está vacío, no se puede continuar.\")\n",
    "        return\n",
    "\n",
    "    # Calcular medias móviles\n",
    "    df['reward_smooth'] = df['episode_reward'].rolling(window=window_size).mean()\n",
    "    df['loss_smooth'] = df['loss'].rolling(window=window_size).mean()\n",
    "    df['q_smooth'] = df['mean_q'].rolling(window=window_size).mean()\n",
    "    df['eps_smooth'] = df['mean_eps'].rolling(window=window_size).mean()\n",
    "\n",
    "    # Generar gráficos\n",
    "    _plot_metrics(df, model_name, window_size, MODEL_DIR)\n",
    "\n",
    "    # Informe global\n",
    "    print(\"\\nINFORME DEL TRAINING (Todas las métricas)\\n\" + \"-\" * 40)\n",
    "    _print_report(df)\n",
    "\n",
    "    # Informe últimos episodios\n",
    "    _analyze_training_last(df, model_name, window_size, MODEL_DIR)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "while True:\n",
    "    model_name = \"ddqn.v1.0\"\n",
    "    analyze_training(model_name,10)\n",
    "    analyze_training(model_name, 100)\n",
    "\t# EJECUTO CADA 15 minutos y guardo las grapsh y data\n",
    "    time.sleep(900)"
   ],
   "id": "867ac174cc713e2e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
